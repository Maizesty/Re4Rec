{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace success!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.fx import subgraph_rewriter, symbolic_trace\n",
    "import utils\n",
    "from torch.fx import Proxy, Graph, GraphModule\n",
    "from torch.fx.passes.utils.matcher_utils import SubgraphMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import afm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "afm_model = afm.AttentionalFactorizationMachineModel([100 for i in range(22)],8,8,[0.1,0.1])\n",
    "afm_traced = symbolic_trace(afm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class AttentionalFactorizationMachineModel(torch.nn.Module):\n",
      "    def forward(self, x):\n",
      "        # No stacktrace found for following nodes\n",
      "        linear_offsets = self.linear.offsets\n",
      "        add = x + linear_offsets;  linear_offsets = None\n",
      "        linear_fc = self.linear.fc(add);  add = None\n",
      "        sum_1 = torch.sum(linear_fc, dim = 1);  linear_fc = None\n",
      "        linear_bias = self.linear.bias\n",
      "        add_1 = sum_1 + linear_bias;  sum_1 = linear_bias = None\n",
      "        embedding_offsets = self.embedding.offsets\n",
      "        add_2 = x + embedding_offsets;  x = embedding_offsets = None\n",
      "        embedding_embedding = self.embedding.embedding(add_2);  add_2 = None\n",
      "        getitem = embedding_embedding[(slice(None, None, None), [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 19, 19, 20])]\n",
      "        getitem_1 = embedding_embedding[(slice(None, None, None), [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 13, 14, 15, 16, 17, 18, 19, 20, 21, 14, 15, 16, 17, 18, 19, 20, 21, 15, 16, 17, 18, 19, 20, 21, 16, 17, 18, 19, 20, 21, 17, 18, 19, 20, 21, 18, 19, 20, 21, 19, 20, 21, 20, 21, 21])];  embedding_embedding = None\n",
      "        mul = getitem * getitem_1;  getitem = getitem_1 = None\n",
      "        afm_attention = self.afm.attention(mul)\n",
      "        relu = torch.nn.functional.relu(afm_attention, inplace = False);  afm_attention = None\n",
      "        afm_projection = self.afm.projection(relu);  relu = None\n",
      "        softmax = torch.nn.functional.softmax(afm_projection, dim = 1, _stacklevel = 3, dtype = None);  afm_projection = None\n",
      "        mul_1 = softmax * mul;  softmax = mul = None\n",
      "        sum_2 = torch.sum(mul_1, dim = 1);  mul_1 = None\n",
      "        afm_fc = self.afm.fc(sum_2);  sum_2 = None\n",
      "        add_3 = add_1 + afm_fc;  add_1 = afm_fc = None\n",
      "        squeeze = add_3.squeeze(1);  add_3 = None\n",
      "        sigmoid = torch.sigmoid(squeeze);  squeeze = None\n",
      "        return sigmoid\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'class AttentionalFactorizationMachineModel(torch.nn.Module):\\n    def forward(self, x):\\n        # No stacktrace found for following nodes\\n        linear_offsets = self.linear.offsets\\n        add = x + linear_offsets;  linear_offsets = None\\n        linear_fc = self.linear.fc(add);  add = None\\n        sum_1 = torch.sum(linear_fc, dim = 1);  linear_fc = None\\n        linear_bias = self.linear.bias\\n        add_1 = sum_1 + linear_bias;  sum_1 = linear_bias = None\\n        embedding_offsets = self.embedding.offsets\\n        add_2 = x + embedding_offsets;  x = embedding_offsets = None\\n        embedding_embedding = self.embedding.embedding(add_2);  add_2 = None\\n        getitem = embedding_embedding[(slice(None, None, None), [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 19, 19, 20])]\\n        getitem_1 = embedding_embedding[(slice(None, None, None), [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 13, 14, 15, 16, 17, 18, 19, 20, 21, 14, 15, 16, 17, 18, 19, 20, 21, 15, 16, 17, 18, 19, 20, 21, 16, 17, 18, 19, 20, 21, 17, 18, 19, 20, 21, 18, 19, 20, 21, 19, 20, 21, 20, 21, 21])];  embedding_embedding = None\\n        mul = getitem * getitem_1;  getitem = getitem_1 = None\\n        afm_attention = self.afm.attention(mul)\\n        relu = torch.nn.functional.relu(afm_attention, inplace = False);  afm_attention = None\\n        afm_projection = self.afm.projection(relu);  relu = None\\n        softmax = torch.nn.functional.softmax(afm_projection, dim = 1, _stacklevel = 3, dtype = None);  afm_projection = None\\n        mul_1 = softmax * mul;  softmax = mul = None\\n        sum_2 = torch.sum(mul_1, dim = 1);  mul_1 = None\\n        afm_fc = self.afm.fc(sum_2);  sum_2 = None\\n        add_3 = add_1 + afm_fc;  add_1 = afm_fc = None\\n        squeeze = add_3.squeeze(1);  add_3 = None\\n        sigmoid = torch.sigmoid(squeeze);  squeeze = None\\n        return sigmoid\\n        '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afm_traced.print_readable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name                 target                                                      args                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               kwargs\n",
      "-------------  -------------------  ----------------------------------------------------------  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  -------------------------------------------\n",
      "placeholder    x                    x                                                           ()                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 {}\n",
      "get_attr       linear_offsets       linear.offsets                                              ()                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 {}\n",
      "call_function  add                  <built-in function add>                                     (x, linear_offsets)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                {}\n",
      "call_module    linear_fc            linear.fc                                                   (add,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             {}\n",
      "call_function  sum_1                <built-in method sum of type object at 0x7f843076c760>      (linear_fc,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       {'dim': 1}\n",
      "get_attr       linear_bias          linear.bias                                                 ()                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 {}\n",
      "call_function  add_1                <built-in function add>                                     (sum_1, linear_bias)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               {}\n",
      "get_attr       embedding_offsets    embedding.offsets                                           ()                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 {}\n",
      "call_function  add_2                <built-in function add>                                     (x, embedding_offsets)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             {}\n",
      "call_module    embedding_embedding  embedding.embedding                                         (add_2,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           {}\n",
      "call_function  getitem              <built-in function getitem>                                 (embedding_embedding, (slice(None, None, None), [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 19, 19, 20]))                                                                                                                          {}\n",
      "call_function  getitem_1            <built-in function getitem>                                 (embedding_embedding, (slice(None, None, None), [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 13, 14, 15, 16, 17, 18, 19, 20, 21, 14, 15, 16, 17, 18, 19, 20, 21, 15, 16, 17, 18, 19, 20, 21, 16, 17, 18, 19, 20, 21, 17, 18, 19, 20, 21, 18, 19, 20, 21, 19, 20, 21, 20, 21, 21]))  {}\n",
      "call_function  mul                  <built-in function mul>                                     (getitem, getitem_1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               {}\n",
      "call_module    afm_attention        afm.attention                                               (mul,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             {}\n",
      "call_function  relu                 <function relu at 0x7f838367d1f0>                           (afm_attention,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   {'inplace': False}\n",
      "call_module    afm_projection       afm.projection                                              (relu,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            {}\n",
      "call_function  softmax              <function softmax at 0x7f838367d940>                        (afm_projection,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  {'dim': 1, '_stacklevel': 3, 'dtype': None}\n",
      "call_function  mul_1                <built-in function mul>                                     (softmax, mul)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     {}\n",
      "call_function  sum_2                <built-in method sum of type object at 0x7f843076c760>      (mul_1,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           {'dim': 1}\n",
      "call_module    afm_fc               afm.fc                                                      (sum_2,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           {}\n",
      "call_function  add_3                <built-in function add>                                     (add_1, afm_fc)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    {}\n",
      "call_method    squeeze              squeeze                                                     (add_3, 1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         {}\n",
      "call_function  sigmoid              <built-in method sigmoid of type object at 0x7f843076c760>  (squeeze,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         {}\n",
      "output         output               output                                                      (sigmoid,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         {}\n"
     ]
    }
   ],
   "source": [
    "afm_traced.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PatternClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = torch.nn.Embedding(1, 1)\n",
    "        self.offsets = torch.as_tensor(np.array((0, *np.cumsum([10,10])[:-1]), dtype=np.int64))\n",
    "        self.embed_output_dim = 176\n",
    "        self.atten = nn.Linear(1,1)\n",
    "        self.projection = torch.nn.Linear(1, 1)\n",
    "        self.fc = torch.nn.Linear(1, 1)\n",
    "        self.num_fields = 22\n",
    "\n",
    "    def inner_product(self,x):\n",
    "        num_fields = self.num_fields\n",
    "        row, col = list(), list()\n",
    "        for i in range(num_fields - 1):\n",
    "            for j in range(i + 1, num_fields):\n",
    "                row.append(i), col.append(j)\n",
    "        p, q = x[:, row], x[:, col]\n",
    "        return p * q\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.embed(x + self.offsets)\n",
    "        inner_product = self.inner_product(x)\n",
    "        # return inner_product\n",
    "        attn_scores = F.relu(self.atten(inner_product))\n",
    "        attn_scores = F.softmax(self.projection(attn_scores), dim=1)\n",
    "        return self.fc(torch.sum(attn_scores * inner_product, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn = symbolic_trace(PatternClass())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name        target                                                  args                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 kwargs\n",
      "-------------  ----------  ------------------------------------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  -------------------------------------------\n",
      "placeholder    x           x                                                       ()                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   {}\n",
      "get_attr       offsets     offsets                                                 ()                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   {}\n",
      "call_function  add         <built-in function add>                                 (x, offsets)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         {}\n",
      "call_module    embed       embed                                                   (add,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               {}\n",
      "call_function  getitem     <built-in function getitem>                             (embed, (slice(None, None, None), [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 19, 19, 20]))                                                                                                                          {}\n",
      "call_function  getitem_1   <built-in function getitem>                             (embed, (slice(None, None, None), [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 13, 14, 15, 16, 17, 18, 19, 20, 21, 14, 15, 16, 17, 18, 19, 20, 21, 15, 16, 17, 18, 19, 20, 21, 16, 17, 18, 19, 20, 21, 17, 18, 19, 20, 21, 18, 19, 20, 21, 19, 20, 21, 20, 21, 21]))  {}\n",
      "call_function  mul         <built-in function mul>                                 (getitem, getitem_1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 {}\n",
      "call_module    atten       atten                                                   (mul,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               {}\n",
      "call_function  relu        <function relu at 0x7f838367d1f0>                       (atten,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             {'inplace': False}\n",
      "call_module    projection  projection                                              (relu,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              {}\n",
      "call_function  softmax     <function softmax at 0x7f838367d940>                    (projection,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        {'dim': 1, '_stacklevel': 3, 'dtype': None}\n",
      "call_function  mul_1       <built-in function mul>                                 (softmax, mul)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       {}\n",
      "call_function  sum_1       <built-in method sum of type object at 0x7f843076c760>  (mul_1,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             {'dim': 1}\n",
      "call_module    fc          fc                                                      (sum_1,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             {}\n",
      "output         output      output                                                  (fc,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                {}\n"
     ]
    }
   ],
   "source": [
    "pn.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name                 target                                                      args                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               kwargs\n",
      "-------------  -------------------  ----------------------------------------------------------  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  -------------------------------------------\n",
      "placeholder    x                    x                                                           ()                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 {}\n",
      "get_attr       linear_offsets       linear.offsets                                              ()                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 {}\n",
      "call_function  add                  <built-in function add>                                     (x, linear_offsets)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                {}\n",
      "call_module    linear_fc            linear.fc                                                   (add,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             {}\n",
      "call_function  sum_1                <built-in method sum of type object at 0x7f843076c760>      (linear_fc,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       {'dim': 1}\n",
      "get_attr       linear_bias          linear.bias                                                 ()                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 {}\n",
      "call_function  add_1                <built-in function add>                                     (sum_1, linear_bias)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               {}\n",
      "get_attr       embedding_offsets    embedding.offsets                                           ()                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 {}\n",
      "call_function  add_2                <built-in function add>                                     (x, embedding_offsets)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             {}\n",
      "call_module    embedding_embedding  embedding.embedding                                         (add_2,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           {}\n",
      "call_function  getitem              <built-in function getitem>                                 (embedding_embedding, (slice(None, None, None), [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 19, 19, 20]))                                                                                                                          {}\n",
      "call_function  getitem_1            <built-in function getitem>                                 (embedding_embedding, (slice(None, None, None), [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 13, 14, 15, 16, 17, 18, 19, 20, 21, 14, 15, 16, 17, 18, 19, 20, 21, 15, 16, 17, 18, 19, 20, 21, 16, 17, 18, 19, 20, 21, 17, 18, 19, 20, 21, 18, 19, 20, 21, 19, 20, 21, 20, 21, 21]))  {}\n",
      "call_function  mul                  <built-in function mul>                                     (getitem, getitem_1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               {}\n",
      "call_module    afm_attention        afm.attention                                               (mul,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             {}\n",
      "call_function  relu                 <function relu at 0x7f838367d1f0>                           (afm_attention,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   {'inplace': False}\n",
      "call_module    afm_projection       afm.projection                                              (relu,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            {}\n",
      "call_function  softmax              <function softmax at 0x7f838367d940>                        (afm_projection,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  {'dim': 1, '_stacklevel': 3, 'dtype': None}\n",
      "call_function  mul_1                <built-in function mul>                                     (softmax, mul)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     {}\n",
      "call_function  sum_2                <built-in method sum of type object at 0x7f843076c760>      (mul_1,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           {'dim': 1}\n",
      "call_module    afm_fc               afm.fc                                                      (sum_2,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           {}\n",
      "call_function  add_3                <built-in function add>                                     (add_1, afm_fc)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    {}\n",
      "call_method    squeeze              squeeze                                                     (add_3, 1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         {}\n",
      "call_function  sigmoid              <built-in method sigmoid of type object at 0x7f843076c760>  (squeeze,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         {}\n",
      "output         output               output                                                      (sigmoid,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         {}\n"
     ]
    }
   ],
   "source": [
    "afm_traced.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m matcher \u001b[38;5;241m=\u001b[39m  SubgraphMatcher(\u001b[43mpn\u001b[49m\u001b[38;5;241m.\u001b[39mgraph, match_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, match_placeholder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      2\u001b[0m                             remove_overlapping_matches\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m _matches \u001b[38;5;241m=\u001b[39m matcher\u001b[38;5;241m.\u001b[39mmatch(afm_traced\u001b[38;5;241m.\u001b[39mgraph)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pn' is not defined"
     ]
    }
   ],
   "source": [
    "matcher =  SubgraphMatcher(pn.graph, match_output=False, match_placeholder=False,\n",
    "                            remove_overlapping_matches=True)\n",
    "_matches = matcher.match(afm_traced.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[InternalMatch(anchors=[fc], nodes_map={fc: afm_fc, sum_1: sum_2, mul_1: mul_1, softmax: softmax, projection: afm_projection, relu: relu, atten: afm_attention, mul: mul, getitem: getitem, embed: embedding_embedding, add: add_2, x: x, offsets: embedding_offsets, getitem_1: getitem_1}, placeholder_nodes=[x], returning_nodes=[afm_fc], name_node_map={})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afm_model = afm.AttentionalFactorizationMachineModel([100 for i in range(22)],8,8,[0.1,0.1])\n",
    "afm_traced = symbolic_trace(afm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pattern_replace_and_matcher_for_afm(traced,\n",
    "                                                  redency_part_slice,unredency_part_slice,\n",
    "                                                  embed_node_name,getitem_node_names,num_field,batch = 4096,match_func = None\n",
    "                                                ):\n",
    "  from torch.fx.passes.utils.matcher_utils import SubgraphMatcher\n",
    "\n",
    "\n",
    "  def _match(match,ori,pat):\n",
    "    return True \n",
    "  env  = utils.get_env(traced)\n",
    "  target_node = env[embed_node_name]\n",
    "  target_node_mod = utils.get_target_mod(traced,target_node.target)\n",
    "  shape_info = target_node_mod.weight.data.shape\n",
    "  getitem_node_args = [env[i].args[1] for i in getitem_node_names]\n",
    "  class PatternClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = torch.nn.Embedding(1, 1)\n",
    "        self.offsets = nn.Parameter(torch.as_tensor(np.array((0, *np.cumsum([10,10])[:-1]), dtype=np.int64)),False)\n",
    "        self.embed_output_dim = 176\n",
    "        self.atten = nn.Linear(1,1)\n",
    "        self.projection = torch.nn.Linear(1, 1)\n",
    "        self.fc = torch.nn.Linear(1, 1)\n",
    "        # self.num_fields = 22\n",
    "\n",
    "    def inner_product(self,x):\n",
    "      return x[getitem_node_args[0]] * x[getitem_node_args[1]]\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.embed(x + self.offsets)\n",
    "        inner_product = self.inner_product(x)\n",
    "        # return inner_product\n",
    "        attn_scores = F.relu(self.atten(inner_product))\n",
    "        attn_scores = F.softmax(self.projection(attn_scores), dim=1)\n",
    "        return self.fc(torch.sum(attn_scores * inner_product, dim=1))\n",
    "  pattern = PatternClass()  \n",
    "  pattern_trace = symbolic_trace(pattern)\n",
    "  pattern_graph = pattern_trace.graph\n",
    "  original_graph = traced.graph\n",
    "  matcher =  SubgraphMatcher(pattern_graph, match_output=False, match_placeholder=False,\n",
    "                              remove_overlapping_matches=True)\n",
    "  _matches = matcher.match(original_graph)\n",
    "  match_filters = [_match if match_func is None else match_func]\n",
    "  _matches = [\n",
    "      m for m in _matches\n",
    "      if all(match_filter(m, original_graph, pattern_graph)\n",
    "              for match_filter in match_filters)\n",
    "  ]  \n",
    "  # 因为在过滤器中做了限制应该只有一个符合要求的\n",
    "  _matched = _matches[0]\n",
    "  pattern_env = utils.get_env(pattern_trace)\n",
    "  node_map = _matched.nodes_map\n",
    "  pn = pattern_env['offsets']\n",
    "  offsets_node = node_map[pn]\n",
    "  offsets_val = utils.get_target_mod(traced,offsets_node.target)\n",
    "  \n",
    "  embed_node = node_map[pattern_env['embed']]\n",
    "  embed_node_module = utils.get_target_mod(traced,embed_node.target)\n",
    "\n",
    "  \n",
    "  atten_node = node_map[pattern_env['atten']]\n",
    "  atten_node_module = utils.get_target_mod(traced,atten_node.target)\n",
    "  \n",
    "  projection_node = node_map[pattern_env['projection']]\n",
    "  projection_node_module = utils.get_target_mod(traced,projection_node.target)\n",
    "  \n",
    "  fc_node = node_map[pattern_env['fc']]\n",
    "  fc_node_module = utils.get_target_mod(traced,fc_node.target)\n",
    "  \n",
    "  \n",
    "  class ReplacementClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.redency_offset = torch.as_tensor(np.array(offsets_val[redency_part_slice[1]], dtype=np.int64))\n",
    "      self.unredency_offset = torch.as_tensor(np.array(offsets_val[unredency_part_slice[1]], dtype=np.int64))\n",
    "      self.num_fields = num_field\n",
    "      self.num_prefix = redency_part_slice[1].stop\n",
    "      self.num_sufix = self.num_fields - self.num_prefix\n",
    "      self.total = self.num_fields * (self.num_fields - 1) // 2\n",
    "      self.redency_cross_part_total = self.num_prefix * (self.num_prefix - 1) // 2\n",
    "      self.unredency_cross_part_total = self.num_sufix * (self.num_sufix - 1) // 2\n",
    "      self.rest_cross_part_total = self.total - self.redency_cross_part_total - self.unredency_cross_part_total\n",
    "      # 提取对应的权重参数逻辑有些复杂，先mock\n",
    "      self.embed = embed_node_module\n",
    "      self.embed_dim = self.embed.weight.data.shape[1]\n",
    "\n",
    "      self.attention = atten_node_module\n",
    "      self.projection = projection_node_module\n",
    "      self.fc = fc_node_module\n",
    "\n",
    "    def pn(self,reducey_x,unredency_x):\n",
    "       redency_x_row, reducey_x_col = list(),list()\n",
    "       unredency_x_row, unredency_x_col = list(), list()\n",
    "       mixed_x_row, mixed_x_col = list(), list()\n",
    "       prefix = self.num_prefix\n",
    "       sufix = self.num_sufix\n",
    "       for i in range(prefix - 1):\n",
    "          for j in range(i+1,prefix):\n",
    "             redency_x_row.append(i),reducey_x_col.append(j)\n",
    "       for i in range(sufix - 1):\n",
    "          for j in range(i + 1,sufix):\n",
    "             unredency_x_row.append(i),unredency_x_col.append(j)\n",
    "\n",
    "       for i in range(prefix):\n",
    "          for j in range(sufix):\n",
    "             mixed_x_row.append(i),mixed_x_col.append(j)\n",
    "       return (reducey_x[redency_x_row] * reducey_x[reducey_x_col]).unsqueeze(0),\\\n",
    "              unredency_x[:,unredency_x_row] * unredency_x[:,unredency_x_col],\\\n",
    "              reducey_x[mixed_x_row] * unredency_x[:,mixed_x_col]\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "      redency_part = x[redency_part_slice] + self.redency_offset\n",
    "      unredency_part = x[unredency_part_slice] + self.unredency_offset\n",
    "      redency_part_embed = self.embed(redency_part)\n",
    "      unredency_part_embed = self.embed(unredency_part)\n",
    "      redency_part_pn, unredency_part_pn, mixed_part_pn = self.pn(redency_part_embed,unredency_part_embed)\n",
    "      redency_attn_scores = self.projection(F.relu(self.attention(redency_part_pn)))\n",
    "      unredency_attn_scores = self.projection(F.relu(self.attention(unredency_part_pn)))\n",
    "      mixed_rest_attn_scores = self.projection(F.relu(self.attention(mixed_part_pn)))      \n",
    "      redency_attn_scores = redency_attn_scores.repeat([batch,1,1])\n",
    "      attn_scores  = torch.concat([redency_attn_scores,unredency_attn_scores,mixed_rest_attn_scores],dim = 1)\n",
    "      attn_scores = F.softmax(attn_scores, dim=1)\n",
    "      # return unredency_sum\n",
    "      redency_attn_scores = attn_scores[0,:self.redency_cross_part_total,:]\n",
    "      unredency_attn_scores = attn_scores[:,self.redency_cross_part_total:self.redency_cross_part_total+self.unredency_cross_part_total,:]\n",
    "      mixed_rest_attn_scores = attn_scores[:,self.redency_cross_part_total+self.unredency_cross_part_total:,]\n",
    "      attn_output = torch.sum(redency_attn_scores * redency_part_pn, dim=1) + torch.sum(unredency_attn_scores * unredency_part_pn, dim=1) + torch.sum(mixed_rest_attn_scores * mixed_part_pn, dim=1)\n",
    "      return self.fc(attn_output)\n",
    "  return pattern,ReplacementClass(),_match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "afm_model = afm.AttentionalFactorizationMachineModel([100 for i in range(22)],8,8,[0.1,0.1])\n",
    "afm_traced = symbolic_trace(afm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 20.403146743774414 ms\n",
      "Op type        Op                     Average runtime (s)    Pct total runtime\n",
      "-------------  -------------------  ---------------------  -------------------\n",
      "call_function  getitem                        0.00372028            18.2339\n",
      "call_function  getitem_1                      0.00365186            17.8985\n",
      "call_function  mul                            0.00241923            11.8572\n",
      "call_function  add                            0.00229907            11.2682\n",
      "call_module    afm_attention                  0.00201297             9.86597\n",
      "call_module    afm_projection                 0.00101638             4.98148\n",
      "call_function  relu                           0.000965357            4.73141\n",
      "call_function  mul_1                          0.000807524            3.95784\n",
      "call_module    linear_fc                      0.000775099            3.79892\n",
      "call_function  softmax                        0.000536442            2.62921\n",
      "call_module    embedding_embedding            0.00048852             2.39433\n",
      "call_function  sum_2                          0.000342607            1.67919\n",
      "call_function  add_2                          0.000331163            1.6231\n",
      "call_module    afm_fc                         0.00018096             0.886921\n",
      "call_function  sum_1                          0.00017333             0.849527\n",
      "call_function  add_3                          7.60555e-05            0.372764\n",
      "call_method    squeeze                        4.29153e-05            0.210337\n",
      "placeholder    x                              3.52859e-05            0.172944\n",
      "call_function  add_1                          3.33786e-05            0.163595\n",
      "call_function  sigmoid                        3.21865e-05            0.157753\n",
      "get_attr       linear_offsets                 2.90871e-05            0.142562\n",
      "get_attr       embedding_offsets              2.81334e-05            0.137888\n",
      "get_attr       linear_bias                    2.21729e-05            0.108674\n",
      "output         output                         1.0252e-05             0.0502471\n"
     ]
    }
   ],
   "source": [
    "interp = utils.ProfilingInterpreter(afm_traced)\n",
    "interp.run(torch.randint(low=0, high=88, size=(4096,22), dtype=torch.long))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern,replace,match = gen_pattern_replace_and_matcher_for_afm(afm_traced,\n",
    "                                                                      (0,slice(None,10,None)),(slice(None,None,None),slice(10,None,None)),\n",
    "                                                                      embed_node_name = \"embedding_embedding\",\n",
    "                                                                      getitem_node_names = [\"getitem\",\"getitem_1\"],num_field=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node redency_offset target redency_offset redency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node unredency_offset target unredency_offset unredency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n"
     ]
    }
   ],
   "source": [
    "matches = subgraph_rewriter.replace_pattern_with_filters(afm_traced, pattern, replace,[match])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 15.79904556274414 ms\n",
      "Op type        Op                  Average runtime (s)    Pct total runtime\n",
      "-------------  ----------------  ---------------------  -------------------\n",
      "call_function  add                         0.00236869            14.9926\n",
      "call_function  getitem_7                   0.00122476             7.75209\n",
      "call_function  softmax                     0.000989437            6.26264\n",
      "call_module    attention_2                 0.000893593            5.65599\n",
      "call_function  mul_5                       0.000732422            4.63586\n",
      "call_function  concat                      0.000711679            4.50457\n",
      "call_function  getitem_5                   0.000708103            4.48194\n",
      "call_function  getitem_4                   0.000699282            4.4261\n",
      "call_module    attention_1                 0.000670433            4.2435\n",
      "call_module    linear_fc                   0.000602245            3.81191\n",
      "call_function  mul_2                       0.000491619            3.1117\n",
      "call_module    projection_2                0.000483036            3.05737\n",
      "call_function  relu_2                      0.000481367            3.04681\n",
      "call_function  mul_4                       0.000472069            2.98796\n",
      "call_function  mul_1                       0.000465155            2.94419\n",
      "call_function  relu_1                      0.000289917            1.83503\n",
      "call_module    projection_1                0.000258923            1.63885\n",
      "call_function  sum_4                       0.000217676            1.37778\n",
      "call_function  getitem_6                   0.000197172            1.248\n",
      "call_function  sum_1                       0.000195503            1.23744\n",
      "call_function  sum_3                       0.00019002             1.20273\n",
      "call_module    attention                   0.000183105            1.15897\n",
      "call_module    embed_1                     0.000160456            1.0156\n",
      "call_method    repeat                      0.000151634            0.959768\n",
      "call_module    fc                          0.000127554            0.807352\n",
      "call_function  add_3                       0.000126362            0.799807\n",
      "call_function  getitem_2                   0.00012207             0.772644\n",
      "call_function  add_4                       0.000102758            0.650409\n",
      "call_function  getitem_3                   8.2016e-05             0.51912\n",
      "call_function  add_5                       7.70092e-05            0.487429\n",
      "call_method    squeeze                     7.24792e-05            0.458757\n",
      "call_module    embed                       7.15256e-05            0.452721\n",
      "call_function  getitem_8                   7.03335e-05            0.445176\n",
      "call_module    projection                  6.29425e-05            0.398394\n",
      "call_function  getitem                     5.45979e-05            0.345577\n",
      "call_function  add_6                       5.22137e-05            0.330486\n",
      "call_function  relu                        4.50611e-05            0.285214\n",
      "call_function  sum_2                       4.26769e-05            0.270123\n",
      "call_function  getitem_9                   3.71933e-05            0.235415\n",
      "call_function  sigmoid                     3.69549e-05            0.233906\n",
      "call_function  add_1                       3.67165e-05            0.232397\n",
      "call_function  getitem_10                  3.6478e-05             0.230888\n",
      "call_function  mul_3                       3.60012e-05            0.227869\n",
      "placeholder    x                           3.09944e-05            0.196179\n",
      "call_function  mul                         2.88486e-05            0.182597\n",
      "call_function  getitem_1                   2.64645e-05            0.167507\n",
      "call_method    unsqueeze                   2.55108e-05            0.16147\n",
      "get_attr       linear_bias                 2.45571e-05            0.155434\n",
      "output         output                      2.31266e-05            0.14638\n",
      "get_attr       linear_offsets              2.00272e-05            0.126762\n",
      "call_function  add_2                       1.95503e-05            0.123744\n",
      "get_attr       redency_offset              1.52588e-05            0.0965804\n",
      "get_attr       unredency_offset            1.38283e-05            0.087526\n"
     ]
    }
   ],
   "source": [
    "interp = utils.ProfilingInterpreter(afm_traced)\n",
    "interp.run(torch.randint(low=0, high=88, size=(4096,22), dtype=torch.long))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.ones((4096,22), dtype=torch.long)\n",
    "modify_mod = GraphModule(afm_traced, afm_traced.graph)\n",
    "\n",
    "torch.onnx.export(modify_mod,sample,f'afm_modify.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 14.925241470336914 ms\n",
      "Op type        Op                  Average runtime (s)    Pct total runtime\n",
      "-------------  ----------------  ---------------------  -------------------\n",
      "call_function  add                         0.00180006            12.0605\n",
      "call_function  getitem_7                   0.00124216             8.32255\n",
      "call_function  mul_5                       0.00124192             8.32095\n",
      "call_function  softmax                     0.000983238            6.58775\n",
      "call_module    attention_2                 0.000786066            5.26669\n",
      "call_function  getitem_4                   0.000716686            4.80184\n",
      "call_function  getitem_5                   0.00070715             4.73794\n",
      "call_module    linear_fc                   0.000674725            4.52069\n",
      "call_module    attention_1                 0.000495195            3.31784\n",
      "call_function  mul_1                       0.000464201            3.11017\n",
      "call_function  concat                      0.00043869             2.93925\n",
      "call_function  relu_2                      0.00041461             2.77791\n",
      "call_module    projection_1                0.000408888            2.73957\n",
      "call_function  mul_2                       0.000405073            2.71401\n",
      "call_module    projection_2                0.00036478             2.44405\n",
      "call_function  mul_4                       0.000344992            2.31146\n",
      "call_function  relu_1                      0.000234365            1.57026\n",
      "call_function  sum_3                       0.000201941            1.35301\n",
      "call_function  getitem_6                   0.000196934            1.31947\n",
      "call_function  sum_1                       0.000176907            1.18528\n",
      "call_function  sum_4                       0.000176907            1.18528\n",
      "call_method    repeat                      0.000166655            1.1166\n",
      "call_module    embed_1                     0.00015974             1.07027\n",
      "call_module    attention                   0.000157595            1.05589\n",
      "call_function  add_3                       0.000153542            1.02874\n",
      "call_function  getitem_2                   0.000124216            0.832255\n",
      "call_module    fc                          0.000123739            0.82906\n",
      "call_function  add_5                       0.000105619            0.707656\n",
      "call_function  add_4                       9.72748e-05            0.651747\n",
      "call_module    embed                       7.1764e-05             0.480823\n",
      "call_function  getitem_3                   6.96182e-05            0.466446\n",
      "call_function  getitem_8                   6.60419e-05            0.442485\n",
      "call_function  getitem                     6.24657e-05            0.418524\n",
      "call_module    projection                  5.76973e-05            0.386575\n",
      "call_function  add_6                       5.74589e-05            0.384978\n",
      "call_method    squeeze                     4.50611e-05            0.301912\n",
      "call_method    unsqueeze                   4.24385e-05            0.284341\n",
      "call_function  relu                        4.24385e-05            0.284341\n",
      "call_function  sum_2                       4.17233e-05            0.279548\n",
      "call_function  getitem_9                   3.69549e-05            0.2476\n",
      "call_function  getitem_10                  3.69549e-05            0.2476\n",
      "call_function  mul_3                       3.48091e-05            0.233223\n",
      "call_function  add_1                       3.21865e-05            0.215652\n",
      "call_function  sigmoid                     3.14713e-05            0.210859\n",
      "placeholder    x                           2.81334e-05            0.188495\n",
      "call_function  mul                         2.81334e-05            0.188495\n",
      "call_function  getitem_1                   2.71797e-05            0.182106\n",
      "get_attr       linear_bias                 2.3365e-05             0.156547\n",
      "get_attr       linear_offsets              2.0504e-05             0.137378\n",
      "call_function  add_2                       1.85966e-05            0.124599\n",
      "get_attr       redency_offset              1.57356e-05            0.10543\n",
      "get_attr       unredency_offset            1.43051e-05            0.0958451\n",
      "output         output                      1.23978e-05            0.0830658\n"
     ]
    }
   ],
   "source": [
    "interp = utils.ProfilingInterpreter(afm_traced)\n",
    "interp.run(torch.randint(low=0, high=88, size=(4096,22), dtype=torch.long))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "afm_model = afm.AttentionalFactorizationMachineModel([100 for i in range(100)],32,8,[0.1,0.1])\n",
    "afm_traced = symbolic_trace(afm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total true time 627.7472972869873 ms\n",
      "total time: 783.5931777954102 ms\n",
      "Op type        Op                     Average runtime (ms)    Pct total runtime\n",
      "-------------  -------------------  ----------------------  -------------------\n",
      "call_function  getitem                         128.221              16.3632\n",
      "call_function  getitem_1                       121.187              15.4655\n",
      "call_function  mul                             120.004              15.3146\n",
      "call_function  mul_1                           116.572              14.8766\n",
      "call_module    afm_attention                    60.8704              7.76811\n",
      "call_function  relu                             32.383               4.13262\n",
      "call_function  sum_2                            19.7294              2.51781\n",
      "call_module    afm_projection                   10.998               1.40354\n",
      "call_function  softmax                           8.53848             1.08966\n",
      "call_module    embedding_embedding               5.90801             0.753964\n",
      "call_function  add                               1.06978             0.136523\n",
      "call_module    linear_fc                         0.801802            0.102324\n",
      "call_function  add_2                             0.585318            0.0746966\n",
      "call_module    afm_fc                            0.417948            0.0533373\n",
      "call_function  sum_1                             0.121832            0.0155479\n",
      "call_function  add_3                             0.104427            0.0133267\n",
      "call_function  sigmoid                           0.0469685           0.00599399\n",
      "call_method    squeeze                           0.0405312           0.00517247\n",
      "placeholder    x                                 0.0333786           0.00425969\n",
      "call_function  add_1                             0.0321865           0.00410755\n",
      "get_attr       linear_offsets                    0.0255108           0.00325562\n",
      "get_attr       linear_bias                       0.023365            0.00298178\n",
      "get_attr       embedding_offsets                 0.0200272           0.00255581\n",
      "output         output                            0.0133514           0.00170387\n"
     ]
    }
   ],
   "source": [
    "interp = utils.ProfilingInterpreter(afm_traced)\n",
    "interp.run(torch.randint(low=0, high=88, size=(4096,100), dtype=torch.long))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern,replace,match = gen_pattern_replace_and_matcher_for_afm(afm_traced,\n",
    "                                                                      (0,slice(None,40,None)),(slice(None,None,None),slice(40,None,None)),\n",
    "                                                                      embed_node_name = \"embedding_embedding\",\n",
    "                                                                      getitem_node_names = [\"getitem\",\"getitem_1\"],num_field=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node redency_offset target redency_offset redency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node unredency_offset target unredency_offset unredency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n"
     ]
    }
   ],
   "source": [
    "matches = subgraph_rewriter.replace_pattern_with_filters(afm_traced, pattern, replace,[match])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total true time 449.93114471435547 ms\n",
      "total time: 581.6290378570557 ms\n",
      "Op type        Op                  Average runtime (ms)    Pct total runtime\n",
      "-------------  ----------------  ----------------------  -------------------\n",
      "call_function  mul_2                         55.0554              9.46572\n",
      "call_function  getitem_7                     53.9186              9.27027\n",
      "call_function  mul_5                         52.5537              9.0356\n",
      "call_function  getitem_4                     41.9025              7.20434\n",
      "call_function  mul_1                         41.0187              7.05239\n",
      "call_function  getitem_5                     40.2176              6.91465\n",
      "call_function  mul_4                         37.3588              6.42313\n",
      "call_module    attention_2                   28.8889              4.9669\n",
      "call_module    attention_1                   23.3145              4.00848\n",
      "call_function  relu_2                        12.7125              2.18567\n",
      "call_function  sum_4                         11.1961              1.92496\n",
      "call_function  relu_1                         9.46522             1.62736\n",
      "call_function  softmax                        8.55136             1.47024\n",
      "call_function  sum_3                          8.48556             1.45893\n",
      "call_module    projection_2                   5.10073             0.876973\n",
      "call_module    projection_1                   3.81947             0.656684\n",
      "call_function  concat                         3.60918             0.62053\n",
      "call_module    embed_1                        3.47066             0.596714\n",
      "call_function  getitem_6                      2.07663             0.357036\n",
      "call_method    repeat                         1.0035              0.172533\n",
      "call_module    linear_fc                      0.868797            0.149373\n",
      "call_function  add                            0.79298             0.136338\n",
      "call_function  getitem_2                      0.755548            0.129902\n",
      "call_function  getitem_3                      0.639677            0.10998\n",
      "call_function  add_5                          0.417471            0.0717762\n",
      "call_module    attention                      0.350237            0.0602165\n",
      "call_function  add_4                          0.330448            0.0568142\n",
      "call_module    fc                             0.314474            0.0540678\n",
      "call_function  add_3                          0.256538            0.0441069\n",
      "call_function  mul_3                          0.187874            0.0323013\n",
      "call_function  getitem_8                      0.151157            0.0259886\n",
      "call_function  sum_1                          0.142097            0.0244309\n",
      "call_module    projection                     0.10848             0.0186511\n",
      "call_method    unsqueeze                      0.0991821           0.0170525\n",
      "call_function  mul                            0.0879765           0.0151259\n",
      "call_module    embed                          0.077486            0.0133222\n",
      "call_function  getitem                        0.0748634           0.0128713\n",
      "call_function  relu                           0.0665188           0.0114366\n",
      "call_function  sum_2                          0.0560284           0.00963301\n",
      "call_function  add_6                          0.0455379           0.00782938\n",
      "call_function  sigmoid                        0.0455379           0.00782938\n",
      "call_method    squeeze                        0.0445843           0.00766541\n",
      "call_function  add_1                          0.0371933           0.00639468\n",
      "placeholder    x                              0.0367165           0.00631269\n",
      "call_function  getitem_9                      0.0333786           0.00573881\n",
      "call_function  getitem_1                      0.0331402           0.00569782\n",
      "call_function  add_2                          0.0324249           0.00557485\n",
      "get_attr       linear_bias                    0.0255108           0.00438609\n",
      "get_attr       linear_offsets                 0.0247955           0.00426312\n",
      "call_function  getitem_10                     0.0247955           0.00426312\n",
      "get_attr       redency_offset                 0.0171661           0.00295139\n",
      "get_attr       unredency_offset               0.0164509           0.00282841\n",
      "output         output                         0.0164509           0.00282841\n"
     ]
    }
   ],
   "source": [
    "interp = utils.ProfilingInterpreter(afm_traced)\n",
    "interp.run(torch.randint(low=0, high=88, size=(4096,100), dtype=torch.long))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torchfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def workload_afm(dim,batch):\n",
    "  print(f\"now gen workload of afm with config: dim: {dim},batch : {batch}\")\n",
    "  afm_model = afm.AttentionalFactorizationMachineModel([100 for i in range(22)],8,8,[0.1,0.1])\n",
    "\n",
    "\n",
    "  afm_model_traced_ori = symbolic_trace(afm_model)\n",
    "  \n",
    "  afm_model_modify = afm.AttentionalFactorizationMachineModel([100 for i in range(22)],8,8,[0.1,0.1])\n",
    "  afm_model_traced_modify = symbolic_trace(afm_model_modify)\n",
    "  pattern,replace,match = gen_pattern_replace_and_matcher_for_afm(afm_model_traced_modify,\n",
    "                                                                      (0,slice(None,10,None)),(slice(None,None,None),slice(10,None,None)),\n",
    "                                                                      embed_node_name = \"embedding_embedding\",\n",
    "                                                                      getitem_node_names = [\"getitem\",\"getitem_1\"],num_field=22,batch=batch)\n",
    "  matches = subgraph_rewriter.replace_pattern_with_filters(afm_model_traced_modify, pattern, replace,[match])\n",
    "  return afm_model_traced_ori,afm_model_traced_modify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dim = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of afm with config: dim: 8,batch : 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node redency_offset target redency_offset redency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node unredency_offset target unredency_offset unredency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n"
     ]
    }
   ],
   "source": [
    "ori,modify = workload_afm(8,1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.01 ms ± 1.18 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad():ori(torch.randint(low=0, high=88, size=(1024,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.28 ms ± 848 µs per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad():modify(torch.randint(low=0, high=88, size=(1024,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of afm with config: dim: 8,batch : 4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node redency_offset target redency_offset redency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node unredency_offset target unredency_offset unredency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n"
     ]
    }
   ],
   "source": [
    "ori,modify = workload_afm(8,4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.34 ms ± 2.47 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad():ori(torch.randint(low=0, high=88, size=(4096,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.22 ms ± 2.01 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad():modify(torch.randint(low=0, high=88, size=(4096,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of afm with config: dim: 32,batch : 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node redency_offset target redency_offset redency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node unredency_offset target unredency_offset unredency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n"
     ]
    }
   ],
   "source": [
    "ori,modify = workload_afm(32,1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.37 ms ± 1.29 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad():ori(torch.randint(low=0, high=88, size=(1024,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.41 ms ± 1.05 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad():modify(torch.randint(low=0, high=88, size=(1024,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of afm with config: dim: 32,batch : 4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node redency_offset target redency_offset redency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node unredency_offset target unredency_offset unredency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n"
     ]
    }
   ],
   "source": [
    "ori,modify = workload_afm(32,4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.43 ms ± 2.22 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad():ori(torch.randint(low=0, high=88, size=(4096,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.4 ms ± 2.14 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad():modify(torch.randint(low=0, high=88, size=(4096,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of afm with config: dim: 64,batch : 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node redency_offset target redency_offset redency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node unredency_offset target unredency_offset unredency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n"
     ]
    }
   ],
   "source": [
    "ori,modify = workload_afm(64,1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.04 ms ± 1.35 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad():ori(torch.randint(low=0, high=88, size=(1024,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.48 ms ± 1.2 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad():modify(torch.randint(low=0, high=88, size=(1024,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of afm with config: dim: 64,batch : 4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node redency_offset target redency_offset redency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node unredency_offset target unredency_offset unredency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n"
     ]
    }
   ],
   "source": [
    "ori,modify = workload_afm(64,4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.46 ms ± 2.18 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad():ori(torch.randint(low=0, high=88, size=(4096,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.25 ms ± 1.57 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad():modify(torch.randint(low=0, high=88, size=(4096,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of afm with config: dim: 128,batch : 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node redency_offset target redency_offset redency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node unredency_offset target unredency_offset unredency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n"
     ]
    }
   ],
   "source": [
    "ori,modify = workload_afm(128,1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.07 ms ± 1.27 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad():ori(torch.randint(low=0, high=88, size=(1024,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.42 ms ± 1.2 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad():modify(torch.randint(low=0, high=88, size=(1024,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of afm with config: dim: 64,batch : 4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node redency_offset target redency_offset redency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node unredency_offset target unredency_offset unredency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n"
     ]
    }
   ],
   "source": [
    "ori,modify = workload_afm(64,4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.36 ms ± 2.55 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad():ori(torch.randint(low=0, high=88, size=(4096,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.41 ms ± 2.56 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad():modify(torch.randint(low=0, high=88, size=(4096,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torchscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def workload_afm_script(dim,batch):\n",
    "  print(f\"now gen workload of afm with config: dim: {dim},batch : {batch}\")\n",
    "  afm_model = afm.AttentionalFactorizationMachineModel([100 for i in range(22)],8,8,[0.1,0.1])\n",
    "\n",
    "\n",
    "  afm_model_traced_ori = symbolic_trace(afm_model)\n",
    "  \n",
    "  afm_model_modify = afm.AttentionalFactorizationMachineModel([100 for i in range(22)],8,8,[0.1,0.1])\n",
    "  afm_model_traced_modify = symbolic_trace(afm_model_modify)\n",
    "  pattern,replace,match = gen_pattern_replace_and_matcher_for_afm(afm_model_traced_modify,\n",
    "                                                                      (0,slice(None,10,None)),(slice(None,None,None),slice(10,None,None)),\n",
    "                                                                      embed_node_name = \"embedding_embedding\",\n",
    "                                                                      getitem_node_names = [\"getitem\",\"getitem_1\"],num_field=22,batch=batch)\n",
    "  matches = subgraph_rewriter.replace_pattern_with_filters(afm_model_traced_modify, pattern, replace,[match])\n",
    "  ori = torch.jit.script(afm_model_traced_ori)\n",
    "  modify = torch.jit.script(afm_model_traced_modify)\n",
    "  ori.eval()\n",
    "  modify.eval()\n",
    "  return ori,modify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dim = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of afm with config: dim: 8,batch : 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node redency_offset target redency_offset redency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node unredency_offset target unredency_offset unredency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ori,modify = workload_afm_script(8,1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.74 ms ± 1.1 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad(): output = ori(torch.randint(low=0, high=88, size=(1024,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 ms ± 1.04 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad(): output = modify(torch.randint(low=0, high=88, size=(1024,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of afm with config: dim: 8,batch : 4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node redency_offset target redency_offset redency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node unredency_offset target unredency_offset unredency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ori,modify = workload_afm_script(8,4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.2 ms ± 2.19 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad(): output = ori(torch.randint(low=0, high=88, size=(4096,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.52 ms ± 1.79 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad(): output = modify(torch.randint(low=0, high=88, size=(4096,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of afm with config: dim: 32,batch : 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node redency_offset target redency_offset redency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node unredency_offset target unredency_offset unredency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ori,modify = workload_afm_script(32,1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.75 ms ± 942 µs per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad(): output = ori(torch.randint(low=0, high=88, size=(1024,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.98 ms ± 957 µs per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad(): output = modify(torch.randint(low=0, high=88, size=(1024,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of afm with config: dim: 32,batch : 4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node redency_offset target redency_offset redency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node unredency_offset target unredency_offset unredency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ori,modify = workload_afm_script(32,4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.81 ms ± 1.52 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad(): output = ori(torch.randint(low=0, high=88, size=(4096,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.66 ms ± 2.01 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad(): output = modify(torch.randint(low=0, high=88, size=(4096,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of afm with config: dim: 64,batch : 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node redency_offset target redency_offset redency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node unredency_offset target unredency_offset unredency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ori,modify = workload_afm_script(64,1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.85 ms ± 1.12 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad(): output = ori(torch.randint(low=0, high=88, size=(1024,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.06 ms ± 1.01 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad(): output = modify(torch.randint(low=0, high=88, size=(1024,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of afm with config: dim: 64,batch : 4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node redency_offset target redency_offset redency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node unredency_offset target unredency_offset unredency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ori,modify = workload_afm_script(64,4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.67 ms ± 4.15 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad(): output = ori(torch.randint(low=0, high=88, size=(4096,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.66 ms ± 2.06 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad(): output = modify(torch.randint(low=0, high=88, size=(4096,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of afm with config: dim: 128,batch : 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node redency_offset target redency_offset redency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node unredency_offset target unredency_offset unredency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ori,modify = workload_afm_script(128,1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.85 ms ± 1.22 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad(): output = ori(torch.randint(low=0, high=88, size=(1024,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.07 ms ± 1.14 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad(): output = modify(torch.randint(low=0, high=88, size=(1024,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of afm with config: dim: 128,batch : 4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node redency_offset target redency_offset redency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph.py:1460: UserWarning: Node unredency_offset target unredency_offset unredency_offset of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ori,modify = workload_afm_script(128,4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.48 ms ± 2.12 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad(): output = ori(torch.randint(low=0, high=88, size=(4096,22), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.48 ms ± 1.96 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 with torch.no_grad(): output = modify(torch.randint(low=0, high=88, size=(4096,22), dtype=torch.long))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepctr-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
