{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace success!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.fx import subgraph_rewriter, symbolic_trace\n",
    "import utils\n",
    "from torch.fx import Proxy, Graph, GraphModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel(torch.nn.Module):\n",
    "  \n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super().__init__()\n",
    "    self.mlp1 = torch.nn.Linear(input_dim, output_dim)\n",
    "    self.mlp1.weight.data.copy_(torch.zeros_like(self.mlp1.weight.data))\n",
    "    self.mlp2 = torch.nn.Linear(output_dim,1)\n",
    "    \n",
    "  def forward(self,x):\n",
    "    return self.mlp2(self.mlp1(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pattern_replace_and_matcher_for_linear(traced,\n",
    "                                                  redency_part_slice,unredency_part_slice,\n",
    "                                                  target_node_name\n",
    "                                                ):\n",
    "  env  = utils.get_env(traced)\n",
    "  target_node = env[target_node_name]\n",
    "  target_node_mod = utils.get_target_mod(traced,target_node_name)\n",
    "  def _match(match,ori,pat):\n",
    "    selected_node = None\n",
    "    for node in pat.nodes:\n",
    "      if node.op == \"call_module\" :\n",
    "        selected_node = node\n",
    "    return match.nodes_map[selected_node].name == target_node_name\n",
    "  \n",
    "  class PatternClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.mlp = torch.nn.Linear(1, 1)\n",
    "    def forward(self,x):\n",
    "      return self.mlp(x)\n",
    "  \n",
    "  class ReplacementClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      target_weight = target_node_mod.weight\n",
    "      target_bias = target_node_mod.bias\n",
    "      redency_weight = target_weight[:,redency_part_slice[1]]\n",
    "      self.redency_linear = torch.nn.Linear(redency_weight.shape[0],redency_weight.shape[1])\n",
    "      self.redency_linear.weight.data = redency_weight\n",
    "      self.redency_linear.bias.data = target_bias\n",
    "      \n",
    "      unredency_weight = target_weight[:,unredency_part_slice[1]]\n",
    "      self.unredency_linear = torch.nn.Linear(unredency_weight.shape[0],unredency_weight.shape[1],bias=False)\n",
    "      self.unredency_linear.weight.data = unredency_weight\n",
    "\n",
    "    def forward(self,x):\n",
    "      redency_part = x[redency_part_slice]\n",
    "      unredency_part = x[unredency_part_slice]\n",
    "      return self.redency_linear(redency_part) + self.unredency_linear(unredency_part)\n",
    "    \n",
    "  \n",
    "  return PatternClass(),ReplacementClass(),_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class TestModel(torch.nn.Module):\n",
      "    def forward(self, x):\n",
      "        # No stacktrace found for following nodes\n",
      "        mlp1 = self.mlp1(x);  x = None\n",
      "        mlp2 = self.mlp2(mlp1);  mlp1 = None\n",
      "        return mlp2\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'class TestModel(torch.nn.Module):\\n    def forward(self, x):\\n        # No stacktrace found for following nodes\\n        mlp1 = self.mlp1(x);  x = None\\n        mlp2 = self.mlp2(mlp1);  mlp1 = None\\n        return mlp2\\n        '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_func_model = symbolic_trace(TestModel(300,100))\n",
    "linear_func_model.print_readable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.ones((4096,300))\n",
    "modify_mod = GraphModule(linear_func_model, linear_func_model.graph)\n",
    "\n",
    "torch.onnx.export(modify_mod,sample,f'linear.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode       name    target    args     kwargs\n",
      "-----------  ------  --------  -------  --------\n",
      "placeholder  x       x         ()       {}\n",
      "call_module  mlp1    mlp1      (x,)     {}\n",
      "call_module  mlp2    mlp2      (mlp1,)  {}\n",
      "output       output  output    (mlp2,)  {}\n"
     ]
    }
   ],
   "source": [
    "linear_func_model.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern,replace,match = gen_pattern_replace_and_matcher_for_linear(linear_func_model,\n",
    "                                                                      (0,slice(None,10,None)),(slice(None,None,None),slice(10,None,None)),\n",
    "                                                                      \"mlp1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = subgraph_rewriter.replace_pattern_with_filters(linear_func_model, pattern, replace,[match])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.ones((4096,300))\n",
    "modify_mod = GraphModule(linear_func_model, linear_func_model.graph)\n",
    "\n",
    "torch.onnx.export(modify_mod,sample,f'linear_modify.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class TestModel(torch.nn.Module):\n",
      "    def forward(self, x):\n",
      "        # No stacktrace found for following nodes\n",
      "        getitem = x[(0, slice(None, 10, None))]\n",
      "        getitem_1 = x[(slice(None, None, None), slice(10, None, None))];  x = None\n",
      "        redency_linear = self.redency_linear(getitem);  getitem = None\n",
      "        unredency_linear = self.unredency_linear(getitem_1);  getitem_1 = None\n",
      "        add = redency_linear + unredency_linear;  redency_linear = unredency_linear = None\n",
      "        mlp2 = self.mlp2(add);  add = None\n",
      "        return mlp2\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'class TestModel(torch.nn.Module):\\n    def forward(self, x):\\n        # No stacktrace found for following nodes\\n        getitem = x[(0, slice(None, 10, None))]\\n        getitem_1 = x[(slice(None, None, None), slice(10, None, None))];  x = None\\n        redency_linear = self.redency_linear(getitem);  getitem = None\\n        unredency_linear = self.unredency_linear(getitem_1);  getitem_1 = None\\n        add = redency_linear + unredency_linear;  redency_linear = unredency_linear = None\\n        mlp2 = self.mlp2(add);  add = None\\n        return mlp2\\n        '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_func_model.print_readable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel(torch.nn.Module):\n",
    "  \n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super().__init__()\n",
    "    self.mlp1 = torch.nn.Linear(input_dim, output_dim)\n",
    "    self.mlp1.weight.data.copy_(torch.zeros_like(self.mlp1.weight.data))\n",
    "    self.mlp2 = torch.nn.Linear(output_dim,1)\n",
    "    \n",
    "  def forward(self,x):\n",
    "    return self.mlp2(self.mlp1(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepctr-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
