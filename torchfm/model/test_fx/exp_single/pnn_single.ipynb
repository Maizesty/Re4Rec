{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../')\n",
    "import time\n",
    "import pnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace success!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.fx import subgraph_rewriter, symbolic_trace\n",
    "import utils\n",
    "from torch.fx import Proxy, Graph, GraphModule\n",
    "from torch.fx.passes.utils.matcher_utils import SubgraphMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import time\n",
    "import torch._dynamo as dynamo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pattern_replace_and_matcher_for_loop_pnn_mul(traced,\n",
    "                                                  redundancy_part_slice,non_redundancy_part_slice,\n",
    "                                                  embed_node_name,getitem_node_names,num_field,batch = 4096,match_func = None, device = 'cpu',dim = 32\n",
    "                                                ):\n",
    "  from torch.fx.passes.utils.matcher_utils import SubgraphMatcher\n",
    "\n",
    "\n",
    "  def _match(match,ori,pat):\n",
    "    return True \n",
    "  env  = utils.get_env(traced)\n",
    "  target_node = env[embed_node_name]\n",
    "  target_node_mod = utils.get_target_mod(traced,target_node.target)\n",
    "  shape_info = target_node_mod.weight.data.shape\n",
    "  getitem_node_args = [env[i].args[1] for i in getitem_node_names]\n",
    "  class PatternClass(torch.nn.Module):\n",
    "      def __init__(self):\n",
    "          super().__init__()\n",
    "\n",
    "      def pn(self,x):\n",
    "         return torch.sum(x[getitem_node_args[0]] * x[getitem_node_args[1]], dim = 2)\n",
    "\n",
    "      def forward(self,x):\n",
    "          return self.pn(x)\n",
    "  pattern = PatternClass()  \n",
    "  pattern_trace = symbolic_trace(pattern)\n",
    "  pattern_graph = pattern_trace.graph\n",
    "  original_graph = traced.graph\n",
    "  matcher =  SubgraphMatcher(pattern_graph, match_output=False, match_placeholder=False,\n",
    "                              remove_overlapping_matches=True)\n",
    "  _matches = matcher.match(original_graph)\n",
    "  match_filters = [_match if match_func is None else match_func]\n",
    "  _matches = [\n",
    "      m for m in _matches\n",
    "      if all(match_filter(m, original_graph, pattern_graph)\n",
    "              for match_filter in match_filters)\n",
    "  ]  \n",
    "  # 因为在过滤器中做了限制应该只有一个符合要求的\n",
    "  _matched = _matches[0]\n",
    "  pattern_env = utils.get_env(pattern_trace)\n",
    "  node_map = _matched.nodes_map\n",
    "  \n",
    "  \n",
    "#   linear_node = node_map[pattern_env['mlp']]\n",
    "#   linear_node_module = utils.get_target_mod(traced,linear_node.target)\n",
    "#   linear_node_weight = linear_node_module.weight.data\n",
    "#   linear_node_bias = linear_node_module.bias.data\n",
    "  \n",
    "  class ReplacementClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.num_fields = num_field\n",
    "      self.num_prefix = redundancy_part_slice[1].stop\n",
    "      # self.ori_linear_shape = linear_node_weight.shape\n",
    "      self.num_sufix = self.num_fields - self.num_prefix\n",
    "      self.total = self.num_fields * (self.num_fields - 1) // 2\n",
    "      self.redundancy_cross_part_total = self.num_prefix * (self.num_prefix - 1) // 2\n",
    "      self.non_redundancy_cross_part_total = self.num_sufix * (self.num_sufix - 1) // 2\n",
    "      self.rest_cross_part_total = self.total - self.redundancy_cross_part_total - self.non_redundancy_cross_part_total\n",
    "\n",
    "    def pn(self,embed):\n",
    "      empty_tensor = torch.empty((batch,self.total,dim),device=device)\n",
    "      row = embed[getitem_node_args[0]] \n",
    "      col = embed[getitem_node_args[1]]\n",
    "      empty_tensor[:,self.num_prefix:] = row[0,self.num_prefix:] * col[0,self.num_prefix:]\n",
    "      empty_tensor[:,:self.num_prefix] = row[:,:self.num_prefix] * col[:,:self.num_prefix]\n",
    "      return torch.sum(empty_tensor,dim = -1)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "      return self.pn(x)\n",
    "    \n",
    "  \n",
    "  return pattern,ReplacementClass(),_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只修改哈达玛积\n",
    "def workload_pnn(num_field, prefix,dim = 64,l = [1024,512,256],batch = 4096,device = 'cuda'):\n",
    "  print(f\"now gen workload of PNN with config: dim: {dim}, num_field: {num_field}, prefix: {prefix}\")\n",
    "  pnn_loop = pnn.ProductNeuralNetworkModel([100 for i in range(num_field)],dim,l,0.1)\n",
    "\n",
    "  pnn_model_traced_ori = symbolic_trace(pnn_loop)\n",
    "  \n",
    "  pnn_model_modify = pnn.ProductNeuralNetworkModel([100 for i in range(num_field)],dim,l,0.1)\n",
    "  pnn_model_traced_modify = symbolic_trace(pnn_model_modify)\n",
    "  pattern,replace,match = gen_pattern_replace_and_matcher_for_loop_pnn_mul(pnn_model_traced_modify,\n",
    "                                                                      (0,slice(None,prefix,None)),(slice(None,None,None),slice(prefix,None,None)),\n",
    "                                                                      embed_node_name = \"embedding_embedding\",\n",
    "                                                                      getitem_node_names = [\"getitem\",\"getitem_1\"],num_field=num_field,batch = batch,dim=dim,device=device)\n",
    "  matches = subgraph_rewriter.replace_pattern_with_filters(pnn_model_traced_modify, pattern, replace,[match])\n",
    "  return pnn_model_traced_ori,pnn_model_traced_modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_and_test(num_field = 22,prefix = 10, batch = 4096, dim = 32, workload_func = workload_pnn,l = [1024,512,256]):\n",
    "  def run(model):\n",
    "    model = model.cuda()\n",
    "    model.eval()\n",
    "    # traced_model = torch.jit.trace(, torch.randint(low=0, high=88, size=(batch,num_field), dtype=torch.long).cuda())\n",
    "    compiled_model = torch.compile(model, backend=\"inductor\")\n",
    "    compiled_model.eval()\n",
    "    t = torch.randint(low=0, high=88, size=(batch ,num_field), dtype=torch.long).cuda()\n",
    "    for i in range(6):\n",
    "        soutput = compiled_model(t)\n",
    "    torch.cuda.synchronize()\n",
    "    start_time = time.time()  # 开始计时\n",
    "\n",
    "    for i in range(100):\n",
    "        soutput = compiled_model(t)\n",
    "    # torch.cuda.synchronize()\n",
    "    end_time = time.time()  # 结束计时\n",
    "        \n",
    "        # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"time : {elapsed_time * 1000 /100} ms\")\n",
    "  print(f\"now gen workload of DFM with config: dim: {dim}, num_field: {num_field}, prefix: {prefix}, batch :{batch}\")\n",
    "  ori, modify = workload_func(num_field,prefix,dim,l,batch = batch,device = 'cuda')\n",
    "  run(ori)\n",
    "  run(modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of DFM with config: dim: 32, num_field: 22, prefix: 10, batch :4096\n",
      "now gen workload of PNN with config: dim: 32, num_field: 22, prefix: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/fx/graph.py:1801: UserWarning: Node _tensor_constant0 target _tensor_constant0 _tensor_constant0 of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/fx/graph.py:1801: UserWarning: Node _tensor_constant0_1 target _tensor_constant0 _tensor_constant0 of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/fx/graph.py:1801: UserWarning: Node _tensor_constant1 target _tensor_constant1 _tensor_constant1 of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 0.3384065628051758 ms\n",
      "time : 0.4471778869628906 ms\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 ,prefix = 10 , batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of DFM with config: dim: 32, num_field: 110, prefix: 50, batch :4096\n",
      "now gen workload of PNN with config: dim: 32, num_field: 110, prefix: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/fx/graph.py:1801: UserWarning: Node _tensor_constant0 target _tensor_constant0 _tensor_constant0 of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/fx/graph.py:1801: UserWarning: Node _tensor_constant0_1 target _tensor_constant0 _tensor_constant0 of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/fx/graph.py:1801: UserWarning: Node _tensor_constant1 target _tensor_constant1 _tensor_constant1 of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 2.6438069343566895 ms\n",
      "time : 8.160557746887207 ms\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 4096, dim = 32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorrt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
