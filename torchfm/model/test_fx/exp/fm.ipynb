{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../')\n",
    "\n",
    "import fm\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace success!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.fx import subgraph_rewriter, symbolic_trace\n",
    "import utils\n",
    "import torch.fx as fx\n",
    "from torch.fx import Proxy, Graph, GraphModule\n",
    "from torch.fx.passes.utils.matcher_utils import SubgraphMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch._dynamo as dynamo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pattern_replace_and_matcher_for_FM(traced,\n",
    "                                                  redency_part_slice,unredency_part_slice,\n",
    "                                                  match_func = None\n",
    "                                                ):\n",
    "  from torch.fx.passes.utils.matcher_utils import SubgraphMatcher\n",
    "\n",
    "  class PatternClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.embed = torch.nn.Embedding(1, 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "      x = self.embed(x)\n",
    "      square_of_sum = torch.sum(x, dim=1) ** 2\n",
    "      sum_of_square = torch.sum(x ** 2, dim=1)\n",
    "      ix = square_of_sum - sum_of_square    \n",
    "      ix = torch.sum(ix, dim=1, keepdim=True)  \n",
    "      return 0.5 * ix\n",
    "  def _match(match,ori,pat):\n",
    "    return True \n",
    "  # env  = utils.get_env(traced)\n",
    "  # target_node = env[target_node_name]\n",
    "  # target_node_mod = utils.get_target_mod(traced,target_node_name,\"_\")\n",
    "  pattern = PatternClass()  \n",
    "  pattern_trace = symbolic_trace(pattern)\n",
    "  pattern_graph = pattern_trace.graph\n",
    "  original_graph = traced.graph\n",
    "  matcher =  SubgraphMatcher(pattern_graph, match_output=False, match_placeholder=False,\n",
    "                              remove_overlapping_matches=True)\n",
    "  _matches = matcher.match(original_graph)\n",
    "  match_filters = [_match if match_func is None else match_func]\n",
    "  _matches = [\n",
    "      m for m in _matches\n",
    "      if all(match_filter(m, original_graph, pattern_graph)\n",
    "              for match_filter in match_filters)\n",
    "  ]  \n",
    "  # 因为在过滤器中做了限制应该只有一个符合要求的\n",
    "  _matched = _matches[0]\n",
    "  pattern_env = utils.get_env(pattern_trace)\n",
    "  node_map = _matched.nodes_map\n",
    "  \n",
    "  embed_node = node_map[pattern_env['embed']]\n",
    "  embed_node_module = utils.get_target_mod(traced,embed_node.target)\n",
    "  \n",
    "\n",
    "  \n",
    "  \n",
    "  class ReplacementClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      embedding_config = embed_node_module.weight.data.shape\n",
    "      self.embed = nn.Embedding(embedding_config[0],embedding_config[1])\n",
    "      self.embed.weight.data.copy_(embed_node_module.weight.data)\n",
    "    def forward(self,x):\n",
    "      redency_part = x[redency_part_slice] \n",
    "      unredency_part = x[unredency_part_slice] \n",
    "      redency_embed = self.embed(redency_part)\n",
    "      unredency_embed = self.embed(unredency_part)\n",
    "      redency_embed_sum = torch.sum(redency_embed,dim=0)\n",
    "      unredency_embed_sum = torch.sum(unredency_embed,dim=1)\n",
    "      square_of_sum = (redency_embed_sum + unredency_embed_sum) ** 2\n",
    "      redency_embed_square_sum = torch.sum(redency_embed ** 2,dim=0)\n",
    "      unredency_embed_square_sum = torch.sum(unredency_embed ** 2,dim=1)\n",
    "      sum_of_square = redency_embed_square_sum + unredency_embed_square_sum\n",
    "      ix = square_of_sum - sum_of_square\n",
    "      ix = torch.sum(ix,dim = 1,keepdim=True)\n",
    "      return 0.5 * ix\n",
    "    \n",
    "  \n",
    "  return pattern,ReplacementClass(),_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def workload_FM(num_field, prefix,dim = 64):\n",
    "  # print(f\"now gen workload of wdl with config: dim: {dim}, num_field: {num_field}, prefix: {prefix}\")\n",
    "  model_ori = fm.FactorizationMachineModel([100 for i in range(num_field)],dim,)\n",
    "  ori_traced = symbolic_trace(model_ori)\n",
    "  \n",
    "  model_modify = fm.FactorizationMachineModel([100 for i in range(num_field)],dim,)\n",
    "  modify_traced = symbolic_trace(model_modify)\n",
    "  pattern,replace,match = gen_pattern_replace_and_matcher_for_FM(modify_traced,\n",
    "                                                                      (0,slice(None,prefix,None)),(slice(None,None,None),slice(prefix,None,None)),\n",
    "                                                                      )\n",
    "  matches = subgraph_rewriter.replace_pattern_with_filters(modify_traced, pattern, replace,[match])\n",
    "  return ori_traced,modify_traced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genWorkload(num_field = 34 * 5,prefix = 29 * 5, batch = 4096, dim = 64):\n",
    "  ori_model_name = f'/home/yssun/pytorch-fm/torchfm/model/test_fx/exp/model_repo/fm_rate/fm_{batch}_{num_field}_{prefix}_{dim}_ori.onnx'\n",
    "  modify_model_name = f'/home/yssun/pytorch-fm/torchfm/model/test_fx/exp/model_repo/fm_rate/fm_{batch}_{num_field}_{prefix}_{dim}_modify.onnx'\n",
    "  ori, modify = workload_FM(num_field = num_field,prefix = prefix,  dim = dim)\n",
    "  torch.onnx.export(ori,               # 模型 being run\n",
    "                  torch.randint(low=0, high=20, size=(batch,num_field), dtype=torch.long),                  # 模型输入 (or a tuple for multiple inputs)\n",
    "                  ori_model_name,        # 导出文件的文件名\n",
    "                  export_params=True, # 如果设置为True，则参数也会被导出。注意某些情况下参数可能无法被导出。\n",
    "                  opset_version=10,   # ONNX版本\n",
    "                  do_constant_folding=True,  # 是否执行常量折叠以优化模型\n",
    "                  input_names = ['input'],   # 输入的名称\n",
    "                  output_names = ['output'], # 输出的名称\n",
    "                  )\n",
    "  torch.onnx.export(modify,               # 模型 being run\n",
    "                  torch.randint(low=0, high=20, size=(batch,num_field), dtype=torch.long),                  # 模型输入 (or a tuple for multiple inputs)\n",
    "                  modify_model_name,        # 导出文件的文件名\n",
    "                  export_params=True, # 如果设置为True，则参数也会被导出。注意某些情况下参数可能无法被导出。\n",
    "                  opset_version=10,   # ONNX版本\n",
    "                  do_constant_folding=True,  # 是否执行常量折叠以优化模型\n",
    "                  input_names = ['input'],   # 输入的名称\n",
    "                  output_names = ['output'], # 输出的名称\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims= [32]\n",
    "batches = [1024,2048,4096]\n",
    "num_field_and_prefixs = [(34 * 5,29*5),(22 * 5,10 * 5),(34 ,29),(22 ,10 )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_field_and_prefixs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dim \u001b[38;5;129;01min\u001b[39;00m dims:\n\u001b[1;32m      2\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m num_field,prefix \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnum_field_and_prefixs\u001b[49m:\n\u001b[1;32m      4\u001b[0m       genWorkload(num_field\u001b[38;5;241m=\u001b[39mnum_field,prefix\u001b[38;5;241m=\u001b[39mprefix,batch\u001b[38;5;241m=\u001b[39mbatch,dim\u001b[38;5;241m=\u001b[39mdim)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_field_and_prefixs' is not defined"
     ]
    }
   ],
   "source": [
    "for dim in dims:\n",
    "  for batch in batches:\n",
    "    for num_field,prefix in num_field_and_prefixs:\n",
    "      genWorkload(num_field=num_field,prefix=prefix,batch=batch,dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dims= [32]\n",
    "batches = [1024,2048,4096]\n",
    "for dim in dims:\n",
    "  for batch in batches:\n",
    "    for prefix in [10,20,30,40,50,60,70,80,90,99]:\n",
    "      genWorkload(num_field=100,prefix=prefix,batch=batch,dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_and_variance_manual(data):\n",
    "    n = len(data)\n",
    "    mean = sum(data) / n\n",
    "    variance = sum((x - mean) ** 2 for x in data) / n\n",
    "    return mean, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_and_test(num_field = 22,prefix = 10, batch = 4096, dim = 32, workload_func = workload_FM):\n",
    "  def run(model):\n",
    "    traced_model = torch.jit.trace(model, torch.randint(low=0, high=88, size=(batch,num_field), dtype=torch.long))\n",
    "    compiled_model = torch.compile(traced_model, backend=\"inductor\")\n",
    "    compiled_model.eval()\n",
    "    total_time = 0\n",
    "    total_time = []\n",
    "    t = torch.randint(low=0, high=88, size=(batch ,num_field), dtype=torch.long)\n",
    "\n",
    "    with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "        with record_function(\"model_inference\"):\n",
    "          for i in range(100):\n",
    "              start_time = time.time()  # 开始计时\n",
    "              with torch.no_grad():\n",
    "                soutput = compiled_model(t)\n",
    "              end_time = time.time()  # 结束计时\n",
    "              \n",
    "              # 计算并打印函数执行所需的时间\n",
    "              elapsed_time = end_time - start_time\n",
    "              total_time.append(elapsed_time * 1000)\n",
    "    print(calculate_mean_and_variance_manual(total_time))\n",
    "  print(f\"now gen workload of fm with config: dim: {dim}, num_field: {num_field}, prefix: {prefix}, batch :{batch}\")\n",
    "  ori, modify = workload_func(num_field,prefix,dim)\n",
    "  run(ori)\n",
    "  run(modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 22, prefix: 10, batch :1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 00:59:37 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 00:59:37 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 00:59:37 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8416485786437988, 0.16393162656527238)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 00:59:37 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 00:59:38 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 00:59:38 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9055399894714355, 0.12827783950228877)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 1024, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 22, prefix: 10, batch :2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 00:59:42 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 00:59:43 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 00:59:43 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0996079444885254, 0.10654750905700894)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 00:59:43 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 00:59:43 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 00:59:43 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.1716532707214355, 0.12533544219763826)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 2048, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 22, prefix: 10, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 00:59:45 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 00:59:45 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 00:59:45 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.1705207824707031, 0.3099678889157076)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 00:59:46 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 00:59:46 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.3215446472167969, 0.2406660722954257)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 00:59:46 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 22, prefix: 10, batch :8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 00:59:48 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 00:59:48 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 00:59:48 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.3257694244384766, 0.24388953520428913)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 00:59:49 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 00:59:49 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 00:59:49 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.3782858848571777, 0.22229009957186463)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 8192, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 22, prefix: 10, batch :1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 00:59:52 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 00:59:52 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 00:59:52 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.1367392539978027, 0.06965451240716902)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 00:59:52 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 00:59:52 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 00:59:52 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.2312746047973633, 0.11455207097696984)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 1024, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 22, prefix: 10, batch :2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:03 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:03 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:03 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9548068046569824, 0.15408704072683577)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:04 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:04 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:04 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0307502746582031, 0.18146815486943524)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 2048, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 22, prefix: 10, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:04 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:04 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:04 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.567110061645508, 3.382787081272909)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:05 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:05 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:05 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.4825963973999023, 0.15916405393454625)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 4096, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 22, prefix: 10, batch :8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:06 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:06 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:06 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2025-02-07 19:53:07 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9.518556594848633, 19.34084221043122)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:07 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:07 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6.235754489898682, 9.663418555163616)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 8192, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 34, prefix: 29, batch :1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 01:01:00 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 01:01:00 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 01:01:00 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0046100616455078, 0.09465318785260024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 01:01:01 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 01:01:01 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 01:01:01 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0007023811340332, 0.12646167576235712)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34,prefix = 29, batch = 1024, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 34, prefix: 29, batch :2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 01:01:07 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 01:01:07 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 01:01:07 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9464263916015625, 0.11204329098291055)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 01:01:07 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 01:01:08 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 01:01:08 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.1504411697387695, 0.14993648562722228)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34,prefix = 29, batch = 2048, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 34, prefix: 29, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 01:01:10 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 01:01:10 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 01:01:10 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.3439488410949707, 0.1347106061245995)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 01:01:11 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 01:01:11 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.3246703147888184, 0.16576934883119065)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 01:01:11 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34,prefix = 29, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 34, prefix: 29, batch :8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:11 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:12 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:12 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2025-02-07 19:53:12 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.523454189300537, 0.13468056187662114)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:12 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:12 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.4367294311523438, 0.2579140228590404)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34,prefix = 29, batch = 8192, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 34, prefix: 29, batch :1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:13 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:13 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:13 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.1168384552001953, 0.263013534458878)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:13 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:13 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:13 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9875202178955078, 0.16032600901780825)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34,prefix = 29, batch = 1024, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 34, prefix: 29, batch :2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:14 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:14 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:14 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.1469244956970215, 0.19664496036853052)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:14 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:14 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:14 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.1899399757385254, 0.10601153969105326)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34,prefix = 29, batch = 2048, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 34, prefix: 29, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:15 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:15 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:15 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2025-02-07 19:53:15 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.608266830444336, 0.7529647238243342)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:16 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:16 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.4737462997436523, 0.18840984037069575)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34,prefix = 29, batch = 4096, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 34, prefix: 29, batch :8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:16 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:18 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:18 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14.982514381408691, 24.531377205880744)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:18 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:18 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:18 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.4224481582641602, 0.44050454832813557)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34,prefix = 29, batch = 8192, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 110, prefix: 50, batch :1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:19 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:19 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:19 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.2922930717468262, 0.08359043005725653)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:19 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:19 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:19 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.2433910369873047, 0.1659640437537746)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 1024, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 110, prefix: 50, batch :2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:20 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:20 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:20 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.357567310333252, 0.11862930406891792)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:21 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:21 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:21 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.3428258895874023, 0.7335291963727286)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 2048, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 110, prefix: 50, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:26:24 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:26:25 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:26:25 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.898378372192383, 0.3319453627227631)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:26:25 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:26:25 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:26:25 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.8217110633850098, 0.22489647414545288)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 110, prefix: 50, batch :8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:26:44 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:26:47 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:26:47 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27.14857578277588, 32.741037217397206)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:26:47 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:26:48 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:26:48 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4.137053489685059, 0.6568070191633524)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 8192, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 110, prefix: 50, batch :1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:28 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:28 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:28 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.9640564918518066, 0.6878889546158007)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:29 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:29 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:29 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.5652275085449219, 0.1994717580600991)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 1024, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 110, prefix: 50, batch :2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:29 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:30 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:30 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.6950740814208984, 0.5970603580408351)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:30 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:30 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:30 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.5949296951293945, 0.24020775160806807)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 2048, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 110, prefix: 50, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:27:42 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:27:45 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:27:45 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31.65731906890869, 0.8585032960354511)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:27:45 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:27:46 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:27:46 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11.692490577697754, 0.2845200276851756)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 4096, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 110, prefix: 50, batch :8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:35 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:41 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:41 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57.32489585876465, 2.0474609015309397)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:42 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:45 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:45 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33.90780448913574, 2.246284015564015)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 8192, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 170, prefix: 145, batch :1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:46 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:46 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:46 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.6725349426269531, 0.3848434088013164)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:46 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:46 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:46 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.164708137512207, 0.1876634144309719)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 1024, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 170, prefix: 145, batch :2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:47 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:47 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:47 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2025-02-07 19:53:47 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.2417330741882324, 1.1623654989932675)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:48 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:48 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.3333487510681152, 0.288530038068302)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 2048, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 170, prefix: 145, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:48 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:49 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:49 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5.362715721130371, 2.884875063978143)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:49 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:49 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:49 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.395406723022461, 0.7451441537341452)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 170, prefix: 145, batch :8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:50 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:55 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:55 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44.30685997009277, 1.2634602743673895)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:55 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:55 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:55 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.9654035568237305, 1.335709188765577)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 8192, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 170, prefix: 145, batch :1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:56 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:56 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:56 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.695791721343994, 1.3220789974809577)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:56 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:57 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:57 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.282038688659668, 0.13799362093322998)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 1024, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 170, prefix: 145, batch :2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:57 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:53:58 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:58 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2025-02-07 19:53:58 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5.091557502746582, 1.8570046147715402)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:58 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:53:58 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.3472771644592285, 0.37800713118372187)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 2048, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 170, prefix: 145, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:53:59 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:54:03 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:54:03 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43.39672327041626, 1.3906020176079892)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:54:04 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:54:04 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:54:04 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.7615699768066406, 0.25738419744811836)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 4096, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 170, prefix: 145, batch :8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:31:16 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:31:25 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:31:25 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85.56152105331421, 2.656289586246885)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:31:26 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:31:27 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:31:27 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17.30111598968506, 1.179403911942245)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 8192, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 10, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:30:52 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:30:54 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:30:54 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15.58389663696289, 0.270720742037156)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:30:54 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:30:54 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:30:54 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.4332261085510254, 0.2918034632500621)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 10, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 20, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:30:49 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:30:51 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:30:51 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15.703754425048828, 0.7753242890430556)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:30:52 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:30:52 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:30:52 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.1569204330444336, 0.27175533384706796)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 20, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 30, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:30:47 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:30:48 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:30:48 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14.414472579956055, 3.3435604073929426)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:30:48 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:30:48 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:30:48 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.9005012512207031, 0.7007505201727326)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 30, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 40, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:31:36 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:31:38 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:31:38 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16.057605743408203, 0.8357440145573491)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:31:38 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:31:38 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:31:38 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.8061017990112305, 0.4902163757606104)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 40, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 50, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:30:41 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:30:42 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:30:42 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14.10285472869873, 6.702689909411674)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:30:43 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:30:43 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:30:43 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.5732431411743164, 0.3137766898589689)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 50, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 60, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:30:39 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:30:40 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:30:40 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.5649261474609375, 0.1645695871047792)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:30:40 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:30:40 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:30:40 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.4886021614074707, 0.36051086269139887)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 60, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 70, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:30:38 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:30:38 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:30:38 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.718806266784668, 0.7372549981710108)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:30:39 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:30:39 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:30:39 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.4331436157226562, 0.14862782441014133)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 70, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 80, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:30:36 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:30:37 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:30:37 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.8404688835144043, 0.7762883652674191)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:30:37 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:30:37 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:30:37 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.6406798362731934, 0.35401794036147294)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 80, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 90, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:30:35 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:30:35 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:30:35 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.5604963302612305, 0.18206015568011935)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:30:36 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:30:36 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:30:36 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.3909673690795898, 0.15843232179122424)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 90, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 99, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:33:52 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:33:54 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:33:54 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15.424516201019287, 0.6036945852599729)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:33:54 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:33:54 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:33:54 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.2678003311157227, 0.14349893651797174)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 99, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_and_test_KFLOPS(num_field = 22,prefix = 10, batch = 4096, dim = 32, workload_func = workload_FM):\n",
    "  def run(model):\n",
    "    traced_model = torch.jit.trace(model, torch.randint(low=0, high=88, size=(batch,num_field), dtype=torch.long))\n",
    "    compiled_model = torch.compile(traced_model, backend=\"inductor\")\n",
    "    compiled_model.eval()\n",
    "    total_time = 0\n",
    "    total_time = []\n",
    "    t = torch.randint(low=0, high=88, size=(batch ,num_field), dtype=torch.long)\n",
    "\n",
    "    with profile(activities=[ProfilerActivity.CPU], record_shapes=True,    with_flops=True,  ) as prof:\n",
    "        with record_function(\"model_inference\"):\n",
    "          for i in range(100):\n",
    "              start_time = time.time()  # 开始计时\n",
    "              with torch.no_grad():\n",
    "                soutput = compiled_model(t)\n",
    "              end_time = time.time()  # 结束计时\n",
    "              \n",
    "              # 计算并打印函数执行所需的时间\n",
    "              elapsed_time = end_time - start_time\n",
    "              total_time.append(elapsed_time * 1000)\n",
    "    print(calculate_mean_and_variance_manual(total_time))\n",
    "    return prof\n",
    "  print(f\"now gen workload of fm with config: dim: {dim}, num_field: {num_field}, prefix: {prefix}, batch :{batch}\")\n",
    "  ori, modify = workload_func(num_field,prefix,dim)\n",
    "  p1 = run(ori)\n",
    "  p2 = run(modify)\n",
    "  return p1, p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_and_test_gpu(num_field = 22,prefix = 10, batch = 4096, dim = 32, workload_func = workload_FM):\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "  def run(model):\n",
    "    model.to(device)\n",
    "    traced_model = torch.jit.trace(model, torch.randint(low=0, high=88, size=(batch,num_field), dtype=torch.long).to(device)).to(device)\n",
    "    compiled_model = torch.compile(traced_model, backend=\"inductor\").to(device)\n",
    "    compiled_model.eval()\n",
    "    total_time = 0\n",
    "    t = torch.randint(low=0, high=88, size=(batch ,num_field), dtype=torch.long).to(device)\n",
    "\n",
    "    with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "        with record_function(\"model_inference\"):\n",
    "          for i in range(100):\n",
    "              start_time = time.time()  # 开始计时\n",
    "              with torch.no_grad():\n",
    "                soutput = compiled_model(t)\n",
    "              end_time = time.time()  # 结束计时\n",
    "              \n",
    "              # 计算并打印函数执行所需的时间\n",
    "              elapsed_time = end_time - start_time\n",
    "              total_time += elapsed_time\n",
    "    print(total_time * 1000)\n",
    "    return prof\n",
    "  print(f\"now gen workload of fm with config: dim: {dim}, num_field: {num_field}, prefix: {prefix}, batch :{batch}\")\n",
    "  ori, modify = workload_func(num_field,prefix,dim)\n",
    "  p1 = run(ori)\n",
    "  p2 = run(modify)\n",
    "  return p1, p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 34, prefix: 29, batch :8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:54:15 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:54:16 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:54:16 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269.34075355529785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:54:16 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:54:16 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:54:16 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268.4900760650635\n"
     ]
    }
   ],
   "source": [
    "p1, p2 = gen_and_test_gpu(num_field = 34,prefix = 29, batch = 8192, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference         0.00%       0.000us         0.00%       0.000us       0.000us      66.500ms        50.69%      66.500ms      66.500ms             1  \n",
      "                                        model_inference        79.64%     242.540ms        88.51%     269.541ms     269.541ms       0.000us         0.00%      64.697ms      64.697ms             1  \n",
      "                                                forward         0.94%       2.860ms         8.87%      27.001ms     270.010us       0.000us         0.00%      64.697ms     646.970us           100  \n",
      "                                              aten::sum         1.81%       5.514ms         2.46%       7.499ms      18.747us      23.283ms        17.75%      23.283ms      58.208us           400  \n",
      "void at::native::reduce_kernel<128, 4, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      22.282ms        16.98%      22.282ms     111.410us           200  \n",
      "                                              aten::pow         0.43%       1.316ms         0.59%       1.792ms      17.920us      20.596ms        15.70%      20.596ms     205.960us           100  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      20.596ms        15.70%      20.596ms     205.960us           100  \n",
      "                                        aten::embedding         0.43%       1.318ms         2.19%       6.681ms      33.405us       0.000us         0.00%      18.902ms      94.510us           200  \n",
      "                                     aten::index_select         0.79%       2.414ms         1.66%       5.064ms      25.320us      18.902ms        14.41%      18.902ms      94.510us           200  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us      18.402ms        14.03%      18.402ms     184.020us           100  \n",
      "                                              aten::add         0.76%       2.300ms         1.15%       3.492ms      17.460us       1.016ms         0.77%       1.016ms       5.080us           200  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.016ms         0.77%       1.016ms       5.080us           200  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       1.001ms         0.76%       1.001ms       5.005us           200  \n",
      "                                          fused_pow_sub         0.36%       1.107ms         0.49%       1.491ms      14.910us     700.000us         0.53%     700.000us       7.000us           100  \n",
      "                                          fused_pow_sub         0.00%       0.000us         0.00%       0.000us       0.000us     700.000us         0.53%     700.000us       7.000us           100  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us     500.000us         0.38%     500.000us       5.000us           100  \n",
      "                                      fused_add_mul_add         0.28%     855.000us         0.39%       1.189ms      11.890us     100.000us         0.08%     100.000us       1.000us           100  \n",
      "                                          aten::sigmoid         0.35%       1.077ms         0.51%       1.545ms      15.450us     100.000us         0.08%     100.000us       1.000us           100  \n",
      "                                      fused_add_mul_add         0.00%       0.000us         0.00%       0.000us       0.000us     100.000us         0.08%     100.000us       1.000us           100  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     100.000us         0.08%     100.000us       1.000us           100  \n",
      "                                       cudaLaunchKernel         1.71%       5.221ms         1.71%       5.221ms       5.221us       0.000us         0.00%       0.000us       0.000us          1000  \n",
      "                                          aten::reshape         0.08%     235.000us         0.10%     294.000us       1.470us       0.000us         0.00%       0.000us       0.000us           200  \n",
      "                                             aten::view         0.02%      64.000us         0.02%      64.000us       0.160us       0.000us         0.00%       0.000us       0.000us           400  \n",
      "                                            aten::empty         0.25%     750.000us         0.25%     750.000us       3.750us       0.000us         0.00%       0.000us       0.000us           200  \n",
      "                                          aten::resize_         0.26%     792.000us         0.26%     792.000us       3.960us       0.000us         0.00%       0.000us       0.000us           200  \n",
      "                                       aten::as_strided         0.00%       6.000us         0.00%       6.000us       0.015us       0.000us         0.00%       0.000us       0.000us           400  \n",
      "                                      aten::result_type         0.00%       1.000us         0.00%       1.000us       0.010us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                               aten::to         0.00%       1.000us         0.00%       1.000us       0.010us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                         cuLaunchKernel         0.25%     758.000us         0.25%     758.000us       3.790us       0.000us         0.00%       0.000us       0.000us           200  \n",
      "                                          aten::squeeze         0.14%     412.000us         0.14%     412.000us       4.120us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                  cudaDeviceSynchronize        11.49%      34.989ms        11.49%      34.989ms      34.989ms       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 304.530ms\n",
      "Self CUDA time total: 131.197ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p1.key_averages().table(sort_by=\"cuda_time_total\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference         0.00%       0.000us         0.00%       0.000us       0.000us      44.951ms        75.29%      44.951ms      44.951ms             1  \n",
      "                                        model_inference        85.03%     228.484ms       100.00%     268.706ms     268.706ms       0.000us         0.00%      14.754ms      14.754ms             1  \n",
      "                                                forward         1.60%       4.290ms        14.96%      40.192ms     401.920us       0.000us         0.00%      14.752ms     147.520us           100  \n",
      "                                              aten::sum         3.00%       8.069ms         4.08%      10.972ms      18.287us       6.029ms        10.10%       6.029ms      10.048us           600  \n",
      "void at::native::reduce_kernel<128, 4, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       4.995ms         8.37%       4.995ms      12.488us           400  \n",
      "                                        aten::embedding         0.62%       1.655ms         4.49%      12.070ms      40.233us       0.000us         0.00%       3.702ms      12.340us           300  \n",
      "                                     aten::index_select         1.26%       3.397ms         2.74%       7.360ms      24.533us       3.506ms         5.87%       3.506ms      11.687us           300  \n",
      "                                              aten::pow         0.86%       2.324ms         1.21%       3.246ms      16.230us       3.108ms         5.21%       3.108ms      15.540us           200  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       3.108ms         5.21%       3.108ms      15.540us           200  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us       3.006ms         5.03%       3.006ms      15.030us           200  \n",
      "                                              aten::add         0.86%       2.305ms         1.28%       3.450ms      17.250us       1.084ms         1.82%       1.084ms       5.420us           200  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.084ms         1.82%       1.084ms       5.420us           200  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       1.034ms         1.73%       1.034ms       5.170us           200  \n",
      "                                  fused_add_pow_add_sub         0.43%       1.162ms         0.58%       1.571ms      15.710us     627.000us         1.05%     627.000us       6.270us           100  \n",
      "                                  fused_add_pow_add_sub         0.00%       0.000us         0.00%       0.000us       0.000us     627.000us         1.05%     627.000us       6.270us           100  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us     500.000us         0.84%     500.000us       5.000us           100  \n",
      "                                          aten::reshape         0.21%     566.000us         1.15%       3.097ms      15.485us       0.000us         0.00%     200.000us       1.000us           200  \n",
      "                                            aten::copy_         0.32%     859.000us         0.52%       1.390ms      13.900us     200.000us         0.33%     200.000us       2.000us           100  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     200.000us         0.33%     200.000us       2.000us           100  \n",
      "                                            aten::clone         0.14%     380.000us         0.89%       2.385ms      23.850us       0.000us         0.00%     192.000us       1.920us           100  \n",
      "                                      fused_add_mul_add         0.33%     895.000us         0.47%       1.253ms      12.530us     100.000us         0.17%     100.000us       1.000us           100  \n",
      "                                      fused_add_mul_add         0.00%       0.000us         0.00%       0.000us       0.000us     100.000us         0.17%     100.000us       1.000us           100  \n",
      "                                          aten::sigmoid         0.40%       1.082ms         0.57%       1.543ms      15.430us     100.000us         0.17%     100.000us       1.000us           100  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     100.000us         0.17%     100.000us       1.000us           100  \n",
      "                                       cudaLaunchKernel         2.82%       7.582ms         2.82%       7.582ms       5.055us       0.000us         0.00%       0.000us       0.000us          1500  \n",
      "                                             aten::view         0.03%      90.000us         0.03%      90.000us       0.300us       0.000us         0.00%       0.000us       0.000us           300  \n",
      "                                            aten::empty         0.60%       1.616ms         0.60%       1.616ms       4.040us       0.000us         0.00%       0.000us       0.000us           400  \n",
      "                                          aten::resize_         0.44%       1.179ms         0.44%       1.179ms       3.930us       0.000us         0.00%       0.000us       0.000us           300  \n",
      "                                       aten::as_strided         0.01%      21.000us         0.01%      21.000us       0.021us       0.000us         0.00%       0.000us       0.000us          1000  \n",
      "                                           aten::select         0.20%     535.000us         0.20%     539.000us       5.390us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                            aten::slice         0.31%     838.000us         0.31%     842.000us       2.807us       0.000us         0.00%       0.000us       0.000us           300  \n",
      "                                       aten::empty_like         0.08%     206.000us         0.24%     652.000us       6.520us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                     aten::_unsafe_view         0.00%       5.000us         0.00%       5.000us       0.050us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                      aten::result_type         0.00%       1.000us         0.00%       1.000us       0.005us       0.000us         0.00%       0.000us       0.000us           200  \n",
      "                                               aten::to         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           200  \n",
      "                                         cuLaunchKernel         0.30%     811.000us         0.30%     811.000us       4.055us       0.000us         0.00%       0.000us       0.000us           200  \n",
      "                                          aten::squeeze         0.13%     354.000us         0.13%     354.000us       3.540us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                  cudaDeviceSynchronize         0.00%       8.000us         0.00%       8.000us       8.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 268.714ms\n",
      "Self CUDA time total: 59.705ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p2.key_averages().table(sort_by=\"cuda_time_total\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 34, prefix: 29, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:54:17 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:54:18 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:54:18 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2025-02-07 19:54:18 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258.59737396240234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:54:18 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:54:18 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279.2832851409912\n"
     ]
    }
   ],
   "source": [
    "p1, p2 = gen_and_test_gpu(num_field = 34,prefix = 29, batch = 4096, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference         0.00%       0.000us         0.00%       0.000us       0.000us      35.174ms        51.34%      35.174ms      35.174ms             1  \n",
      "                                        model_inference        88.30%     231.538ms        98.69%     258.778ms     258.778ms       0.000us         0.00%      33.334ms      33.334ms             1  \n",
      "                                                forward         1.12%       2.929ms        10.39%      27.240ms     272.400us       0.000us         0.00%      33.334ms     333.340us           100  \n",
      "                                              aten::sum         2.12%       5.558ms         2.88%       7.549ms      18.872us      12.401ms        18.10%      12.401ms      31.003us           400  \n",
      "void at::native::reduce_kernel<128, 4, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      11.601ms        16.93%      11.601ms      58.005us           200  \n",
      "                                              aten::pow         0.51%       1.338ms         0.69%       1.821ms      18.210us      10.217ms        14.91%      10.217ms     102.170us           100  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      10.217ms        14.91%      10.217ms     102.170us           100  \n",
      "                                        aten::embedding         0.53%       1.384ms         2.61%       6.848ms      34.240us       0.000us         0.00%       9.709ms      48.545us           200  \n",
      "                                     aten::index_select         0.93%       2.448ms         1.96%       5.146ms      25.730us       9.709ms        14.17%       9.709ms      48.545us           200  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us       9.309ms        13.59%       9.309ms      93.090us           100  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     800.000us         1.17%     800.000us       4.000us           200  \n",
      "                                              aten::add         0.87%       2.277ms         1.29%       3.388ms      16.940us     507.000us         0.74%     507.000us       2.535us           200  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     507.000us         0.74%     507.000us       2.535us           200  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us     400.000us         0.58%     400.000us       4.000us           100  \n",
      "                                          fused_pow_sub         0.42%       1.112ms         0.58%       1.526ms      15.260us     300.000us         0.44%     300.000us       3.000us           100  \n",
      "                                          fused_pow_sub         0.00%       0.000us         0.00%       0.000us       0.000us     300.000us         0.44%     300.000us       3.000us           100  \n",
      "                                      fused_add_mul_add         0.32%     847.000us         0.47%       1.221ms      12.210us     100.000us         0.15%     100.000us       1.000us           100  \n",
      "                                          aten::sigmoid         0.41%       1.074ms         0.58%       1.517ms      15.170us     100.000us         0.15%     100.000us       1.000us           100  \n",
      "                                      fused_add_mul_add         0.00%       0.000us         0.00%       0.000us       0.000us     100.000us         0.15%     100.000us       1.000us           100  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     100.000us         0.15%     100.000us       1.000us           100  \n",
      "                                       cudaLaunchKernel         1.92%       5.036ms         1.92%       5.036ms       5.036us       0.000us         0.00%       0.000us       0.000us          1000  \n",
      "                                          aten::reshape         0.10%     251.000us         0.12%     307.000us       1.535us       0.000us         0.00%       0.000us       0.000us           200  \n",
      "                                             aten::view         0.03%      67.000us         0.03%      67.000us       0.168us       0.000us         0.00%       0.000us       0.000us           400  \n",
      "                                            aten::empty         0.30%     783.000us         0.30%     783.000us       3.915us       0.000us         0.00%       0.000us       0.000us           200  \n",
      "                                          aten::resize_         0.32%     831.000us         0.32%     831.000us       4.155us       0.000us         0.00%       0.000us       0.000us           200  \n",
      "                                       aten::as_strided         0.03%      75.000us         0.03%      75.000us       0.188us       0.000us         0.00%       0.000us       0.000us           400  \n",
      "                                      aten::result_type         0.00%       1.000us         0.00%       1.000us       0.010us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                               aten::to         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                         cuLaunchKernel         0.31%     812.000us         0.31%     812.000us       4.060us       0.000us         0.00%       0.000us       0.000us           200  \n",
      "                                          aten::squeeze         0.16%     417.000us         0.16%     417.000us       4.170us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                  cudaDeviceSynchronize         1.31%       3.432ms         1.31%       3.432ms       3.432ms       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 262.210ms\n",
      "Self CUDA time total: 68.508ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p1.key_averages().table(sort_by=\"cuda_time_total\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference         0.00%       0.000us         0.00%       0.000us       0.000us      45.573ms        86.03%      45.573ms      45.573ms             1  \n",
      "                                        model_inference        85.18%     238.050ms       100.00%     279.455ms     279.455ms       0.000us         0.00%       7.401ms       7.401ms             1  \n",
      "                                                forward         1.56%       4.361ms        14.80%      41.374ms     413.740us       0.000us         0.00%       7.399ms      73.990us           100  \n",
      "                                              aten::sum         2.97%       8.302ms         3.97%      11.081ms      18.468us       2.777ms         5.24%       2.777ms       4.628us           600  \n",
      "                                        aten::embedding         0.60%       1.663ms         4.39%      12.264ms      40.880us       0.000us         0.00%       2.097ms       6.990us           300  \n",
      "                                     aten::index_select         1.22%       3.407ms         2.69%       7.520ms      25.067us       2.000ms         3.78%       2.000ms       6.667us           300  \n",
      "void at::native::reduce_kernel<128, 4, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       1.977ms         3.73%       1.977ms       4.942us           400  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us       1.600ms         3.02%       1.600ms       8.000us           200  \n",
      "                                              aten::pow         0.84%       2.345ms         1.17%       3.258ms      16.290us       1.323ms         2.50%       1.323ms       6.615us           200  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.323ms         2.50%       1.323ms       6.615us           200  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     800.000us         1.51%     800.000us       4.000us           200  \n",
      "                                              aten::add         0.86%       2.408ms         1.48%       4.148ms      20.740us     600.000us         1.13%     600.000us       3.000us           200  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     600.000us         1.13%     600.000us       3.000us           200  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us     400.000us         0.76%     400.000us       4.000us           100  \n",
      "                                  fused_add_pow_add_sub         0.43%       1.203ms         0.57%       1.606ms      16.060us     400.000us         0.76%     400.000us       4.000us           100  \n",
      "                                  fused_add_pow_add_sub         0.00%       0.000us         0.00%       0.000us       0.000us     400.000us         0.76%     400.000us       4.000us           100  \n",
      "                                          aten::reshape         0.22%     608.000us         1.12%       3.119ms      15.595us       0.000us         0.00%     101.000us       0.505us           200  \n",
      "                                            aten::copy_         0.32%     894.000us         0.51%       1.417ms      14.170us     101.000us         0.19%     101.000us       1.010us           100  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     101.000us         0.19%     101.000us       1.010us           100  \n",
      "                                            aten::clone         0.12%     348.000us         0.86%       2.409ms      24.090us       0.000us         0.00%     100.000us       1.000us           100  \n",
      "                                      fused_add_mul_add         0.32%     895.000us         0.46%       1.290ms      12.900us     100.000us         0.19%     100.000us       1.000us           100  \n",
      "                                      fused_add_mul_add         0.00%       0.000us         0.00%       0.000us       0.000us     100.000us         0.19%     100.000us       1.000us           100  \n",
      "                                          aten::sigmoid         0.40%       1.118ms         0.57%       1.583ms      15.830us     100.000us         0.19%     100.000us       1.000us           100  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     100.000us         0.19%     100.000us       1.000us           100  \n",
      "                                       cudaLaunchKernel         2.88%       8.056ms         2.88%       8.056ms       5.371us       0.000us         0.00%       0.000us       0.000us          1500  \n",
      "                                             aten::view         0.03%      90.000us         0.03%      90.000us       0.300us       0.000us         0.00%       0.000us       0.000us           300  \n",
      "                                            aten::empty         0.59%       1.647ms         0.59%       1.647ms       4.117us       0.000us         0.00%       0.000us       0.000us           400  \n",
      "                                          aten::resize_         0.45%       1.269ms         0.45%       1.269ms       4.230us       0.000us         0.00%       0.000us       0.000us           300  \n",
      "                                       aten::as_strided         0.00%      11.000us         0.00%      11.000us       0.011us       0.000us         0.00%       0.000us       0.000us          1000  \n",
      "                                           aten::select         0.19%     536.000us         0.19%     538.000us       5.380us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                            aten::slice         0.30%     832.000us         0.30%     833.000us       2.777us       0.000us         0.00%       0.000us       0.000us           300  \n",
      "                                       aten::empty_like         0.08%     210.000us         0.23%     648.000us       6.480us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                     aten::_unsafe_view         0.00%       7.000us         0.00%       7.000us       0.070us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                      aten::result_type         0.00%       1.000us         0.00%       1.000us       0.005us       0.000us         0.00%       0.000us       0.000us           200  \n",
      "                                               aten::to         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           200  \n",
      "                                         cuLaunchKernel         0.29%     819.000us         0.29%     819.000us       4.095us       0.000us         0.00%       0.000us       0.000us           200  \n",
      "                                          aten::squeeze         0.13%     375.000us         0.13%     375.000us       3.750us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                  cudaDeviceSynchronize         0.00%       7.000us         0.00%       7.000us       7.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 279.462ms\n",
      "Self CUDA time total: 52.974ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p2.key_averages().table(sort_by=\"cuda_time_total\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 22, prefix: 10, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:54:19 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:54:19 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:54:19 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255.65147399902344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:54:20 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:54:20 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:54:20 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274.85132217407227\n"
     ]
    }
   ],
   "source": [
    "p1, p2 = gen_and_test_gpu(num_field = 22,prefix = 10, batch = 4096, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference         0.00%       0.000us         0.00%       0.000us       0.000us      32.045ms        58.63%      32.045ms      32.045ms             1  \n",
      "                                        model_inference        88.97%     227.638ms       100.00%     255.842ms     255.842ms       0.000us         0.00%      22.608ms      22.608ms             1  \n",
      "                                                forward         1.13%       2.903ms        11.02%      28.188ms     281.880us       0.000us         0.00%      22.607ms     226.070us           100  \n",
      "                                              aten::sum         2.22%       5.690ms         2.99%       7.654ms      19.135us       8.602ms        15.74%       8.602ms      21.505us           400  \n",
      "void at::native::reduce_kernel<128, 4, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       7.996ms        14.63%       7.996ms      39.980us           200  \n",
      "                                              aten::pow         0.52%       1.322ms         0.71%       1.823ms      18.230us       6.505ms        11.90%       6.505ms      65.050us           100  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       6.505ms        11.90%       6.505ms      65.050us           100  \n",
      "                                        aten::embedding         0.55%       1.396ms         2.70%       6.913ms      34.565us       0.000us         0.00%       6.501ms      32.505us           200  \n",
      "                                     aten::index_select         0.95%       2.424ms         2.03%       5.181ms      25.905us       6.501ms        11.90%       6.501ms      32.505us           200  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us       6.111ms        11.18%       6.111ms      61.110us           100  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     606.000us         1.11%     606.000us       3.030us           200  \n",
      "                                              aten::add         0.91%       2.337ms         1.58%       4.048ms      20.240us     500.000us         0.91%     500.000us       2.500us           200  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     500.000us         0.91%     500.000us       2.500us           200  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us     390.000us         0.71%     390.000us       3.900us           100  \n",
      "                                          fused_pow_sub         0.45%       1.159ms         0.61%       1.551ms      15.510us     300.000us         0.55%     300.000us       3.000us           100  \n",
      "                                          fused_pow_sub         0.00%       0.000us         0.00%       0.000us       0.000us     300.000us         0.55%     300.000us       3.000us           100  \n",
      "                                      fused_add_mul_add         0.34%     870.000us         0.49%       1.263ms      12.630us     100.000us         0.18%     100.000us       1.000us           100  \n",
      "                                          aten::sigmoid         0.44%       1.138ms         0.63%       1.604ms      16.040us     100.000us         0.18%     100.000us       1.000us           100  \n",
      "                                      fused_add_mul_add         0.00%       0.000us         0.00%       0.000us       0.000us     100.000us         0.18%     100.000us       1.000us           100  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     100.000us         0.18%     100.000us       1.000us           100  \n",
      "                                       cudaLaunchKernel         2.22%       5.672ms         2.22%       5.672ms       5.672us       0.000us         0.00%       0.000us       0.000us          1000  \n",
      "                                          aten::reshape         0.10%     266.000us         0.13%     329.000us       1.645us       0.000us         0.00%       0.000us       0.000us           200  \n",
      "                                             aten::view         0.03%      70.000us         0.03%      70.000us       0.175us       0.000us         0.00%       0.000us       0.000us           400  \n",
      "                                            aten::empty         0.32%     808.000us         0.32%     808.000us       4.040us       0.000us         0.00%       0.000us       0.000us           200  \n",
      "                                          aten::resize_         0.34%     860.000us         0.34%     860.000us       4.300us       0.000us         0.00%       0.000us       0.000us           200  \n",
      "                                       aten::as_strided         0.02%      57.000us         0.02%      57.000us       0.142us       0.000us         0.00%       0.000us       0.000us           400  \n",
      "                                      aten::result_type         0.00%       1.000us         0.00%       1.000us       0.010us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                               aten::to         0.00%       1.000us         0.00%       1.000us       0.010us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                         cuLaunchKernel         0.32%     814.000us         0.32%     814.000us       4.070us       0.000us         0.00%       0.000us       0.000us           200  \n",
      "                                          aten::squeeze         0.16%     416.000us         0.16%     416.000us       4.160us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                  cudaDeviceSynchronize         0.00%       7.000us         0.00%       7.000us       7.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 255.849ms\n",
      "Self CUDA time total: 54.653ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p1.key_averages().table(sort_by=\"cuda_time_total\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference         0.00%       0.000us         0.00%       0.000us       0.000us      46.072ms        75.51%      46.072ms      46.072ms             1  \n",
      "                                        model_inference        84.80%     233.237ms       100.00%     275.053ms     275.053ms       0.000us         0.00%      14.942ms      14.942ms             1  \n",
      "                                                forward         1.64%       4.510ms        15.20%      41.816ms     418.160us       0.000us         0.00%      14.942ms     149.420us           100  \n",
      "                                              aten::sum         3.02%       8.305ms         4.06%      11.169ms      18.615us       5.827ms         9.55%       5.827ms       9.712us           600  \n",
      "void at::native::reduce_kernel<128, 4, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       5.199ms         8.52%       5.199ms      12.998us           400  \n",
      "                                        aten::embedding         0.64%       1.761ms         4.54%      12.489ms      41.630us       0.000us         0.00%       4.584ms      15.280us           300  \n",
      "                                     aten::index_select         1.27%       3.497ms         2.75%       7.569ms      25.230us       4.398ms         7.21%       4.398ms      14.660us           300  \n",
      "                                              aten::pow         0.85%       2.345ms         1.19%       3.261ms      16.305us       3.508ms         5.75%       3.508ms      17.540us           200  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       3.508ms         5.75%       3.508ms      17.540us           200  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us       3.397ms         5.57%       3.397ms      33.970us           100  \n",
      "void at::native::(anonymous namespace)::indexSelectS...         0.00%       0.000us         0.00%       0.000us       0.000us     700.000us         1.15%     700.000us       7.000us           100  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     628.000us         1.03%     628.000us       3.140us           200  \n",
      "                                              aten::add         0.85%       2.332ms         1.47%       4.045ms      20.225us     500.000us         0.82%     500.000us       2.500us           200  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     500.000us         0.82%     500.000us       2.500us           200  \n",
      "                                  fused_add_pow_add_sub         0.44%       1.199ms         0.59%       1.619ms      16.190us     309.000us         0.51%     309.000us       3.090us           100  \n",
      "                                  fused_add_pow_add_sub         0.00%       0.000us         0.00%       0.000us       0.000us     309.000us         0.51%     309.000us       3.090us           100  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us     301.000us         0.49%     301.000us       3.010us           100  \n",
      "                                          aten::reshape         0.21%     568.000us         1.16%       3.196ms      15.980us       0.000us         0.00%     200.000us       1.000us           200  \n",
      "                                            aten::copy_         0.32%     870.000us         0.51%       1.395ms      13.950us     200.000us         0.33%     200.000us       2.000us           100  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     200.000us         0.33%     200.000us       2.000us           100  \n",
      "                                            aten::clone         0.16%     452.000us         0.89%       2.444ms      24.440us       0.000us         0.00%     188.000us       1.880us           100  \n",
      "                                      fused_add_mul_add         0.32%     881.000us         0.46%       1.275ms      12.750us     100.000us         0.16%     100.000us       1.000us           100  \n",
      "                                      fused_add_mul_add         0.00%       0.000us         0.00%       0.000us       0.000us     100.000us         0.16%     100.000us       1.000us           100  \n",
      "                                          aten::sigmoid         0.39%       1.086ms         0.56%       1.540ms      15.400us     100.000us         0.16%     100.000us       1.000us           100  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     100.000us         0.16%     100.000us       1.000us           100  \n",
      "                                       cudaLaunchKernel         2.93%       8.067ms         2.93%       8.067ms       5.378us       0.000us         0.00%       0.000us       0.000us          1500  \n",
      "                                             aten::view         0.04%      98.000us         0.04%      98.000us       0.327us       0.000us         0.00%       0.000us       0.000us           300  \n",
      "                                            aten::empty         0.60%       1.662ms         0.60%       1.662ms       4.155us       0.000us         0.00%       0.000us       0.000us           400  \n",
      "                                          aten::resize_         0.45%       1.238ms         0.45%       1.238ms       4.127us       0.000us         0.00%       0.000us       0.000us           300  \n",
      "                                       aten::as_strided         0.02%      47.000us         0.02%      47.000us       0.047us       0.000us         0.00%       0.000us       0.000us          1000  \n",
      "                                           aten::select         0.21%     567.000us         0.21%     573.000us       5.730us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                            aten::slice         0.31%     859.000us         0.31%     861.000us       2.870us       0.000us         0.00%       0.000us       0.000us           300  \n",
      "                                       aten::empty_like         0.08%     218.000us         0.25%     681.000us       6.810us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                     aten::_unsafe_view         0.01%      15.000us         0.01%      15.000us       0.150us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                      aten::result_type         0.00%       1.000us         0.00%       1.000us       0.005us       0.000us         0.00%       0.000us       0.000us           200  \n",
      "                                               aten::to         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           200  \n",
      "                                         cuLaunchKernel         0.30%     834.000us         0.30%     834.000us       4.170us       0.000us         0.00%       0.000us       0.000us           200  \n",
      "                                          aten::squeeze         0.15%     404.000us         0.15%     404.000us       4.040us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                  cudaDeviceSynchronize         0.00%       6.000us         0.00%       6.000us       6.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 275.059ms\n",
      "Self CUDA time total: 61.014ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p2.key_averages().table(sort_by=\"cuda_time_total\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 22, prefix: 10, batch :8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:54:21 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:54:21 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:54:21 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249.2961883544922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:54:22 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:54:22 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:54:22 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272.2022533416748\n"
     ]
    }
   ],
   "source": [
    "p1, p2 = gen_and_test_gpu(num_field = 22,prefix = 10, batch = 8192, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference         0.00%       0.000us         0.00%       0.000us       0.000us      44.995ms        51.03%      44.995ms      44.995ms             1  \n",
      "                                        model_inference        84.30%     222.510ms        94.50%     249.433ms     249.433ms       0.000us         0.00%      43.181ms      43.181ms             1  \n",
      "                                                forward         1.07%       2.828ms        10.20%      26.923ms     269.230us       0.000us         0.00%      43.181ms     431.810us           100  \n",
      "                                              aten::sum         2.02%       5.338ms         2.76%       7.277ms      18.192us      15.903ms        18.04%      15.903ms      39.758us           400  \n",
      "void at::native::reduce_kernel<128, 4, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      15.004ms        17.02%      15.004ms      75.020us           200  \n",
      "                                              aten::pow         0.49%       1.302ms         0.67%       1.766ms      17.660us      13.276ms        15.06%      13.276ms     132.760us           100  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      13.276ms        15.06%      13.276ms     132.760us           100  \n",
      "                                        aten::embedding         0.50%       1.318ms         2.49%       6.572ms      32.860us       0.000us         0.00%      12.402ms      62.010us           200  \n",
      "                                     aten::index_select         0.91%       2.401ms         1.87%       4.947ms      24.735us      12.402ms        14.07%      12.402ms      62.010us           200  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us      12.001ms        13.61%      12.001ms     120.010us           100  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     899.000us         1.02%     899.000us       4.495us           200  \n",
      "                                              aten::add         0.82%       2.171ms         1.47%       3.887ms      19.435us     700.000us         0.79%     700.000us       3.500us           200  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     700.000us         0.79%     700.000us       3.500us           200  \n",
      "                                          fused_pow_sub         0.42%       1.099ms         0.56%       1.480ms      14.800us     700.000us         0.79%     700.000us       7.000us           100  \n",
      "                                          fused_pow_sub         0.00%       0.000us         0.00%       0.000us       0.000us     700.000us         0.79%     700.000us       7.000us           100  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us     401.000us         0.45%     401.000us       4.010us           100  \n",
      "                                      fused_add_mul_add         0.32%     836.000us         0.44%       1.167ms      11.670us     100.000us         0.11%     100.000us       1.000us           100  \n",
      "                                          aten::sigmoid         0.41%       1.077ms         0.57%       1.500ms      15.000us     100.000us         0.11%     100.000us       1.000us           100  \n",
      "                                      fused_add_mul_add         0.00%       0.000us         0.00%       0.000us       0.000us     100.000us         0.11%     100.000us       1.000us           100  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     100.000us         0.11%     100.000us       1.000us           100  \n",
      "                                       cudaLaunchKernel         2.09%       5.524ms         2.09%       5.524ms       5.524us       0.000us         0.00%       0.000us       0.000us          1000  \n",
      "                                          aten::reshape         0.10%     270.000us         0.11%     298.000us       1.490us       0.000us         0.00%       0.000us       0.000us           200  \n",
      "                                             aten::view         0.01%      37.000us         0.01%      37.000us       0.092us       0.000us         0.00%       0.000us       0.000us           400  \n",
      "                                            aten::empty         0.28%     727.000us         0.28%     727.000us       3.635us       0.000us         0.00%       0.000us       0.000us           200  \n",
      "                                          aten::resize_         0.29%     771.000us         0.29%     771.000us       3.855us       0.000us         0.00%       0.000us       0.000us           200  \n",
      "                                       aten::as_strided         0.02%      64.000us         0.02%      64.000us       0.160us       0.000us         0.00%       0.000us       0.000us           400  \n",
      "                                      aten::result_type         0.00%       2.000us         0.00%       2.000us       0.020us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                               aten::to         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                         cuLaunchKernel         0.28%     748.000us         0.28%     748.000us       3.740us       0.000us         0.00%       0.000us       0.000us           200  \n",
      "                                          aten::squeeze         0.16%     410.000us         0.16%     410.000us       4.100us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                  cudaDeviceSynchronize         5.50%      14.527ms         5.50%      14.527ms      14.527ms       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 263.960ms\n",
      "Self CUDA time total: 88.176ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p1.key_averages().table(sort_by=\"cuda_time_total\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference         0.00%       0.000us         0.00%       0.000us       0.000us      46.249ms        62.93%      46.249ms      46.249ms             1  \n",
      "                                        model_inference        84.55%     230.346ms       100.00%     272.414ms     272.414ms       0.000us         0.00%      27.240ms      27.240ms             1  \n",
      "                                                forward         1.63%       4.431ms        15.44%      42.052ms     420.520us       0.000us         0.00%      27.239ms     272.390us           100  \n",
      "                                              aten::sum         3.09%       8.409ms         4.15%      11.308ms      18.847us      10.382ms        14.13%      10.382ms      17.303us           600  \n",
      "void at::native::reduce_kernel<128, 4, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       9.424ms        12.82%       9.424ms      23.560us           400  \n",
      "                                        aten::embedding         0.64%       1.732ms         4.63%      12.625ms      42.083us       0.000us         0.00%       7.896ms      26.320us           300  \n",
      "                                     aten::index_select         1.28%       3.477ms         2.82%       7.675ms      25.583us       7.703ms        10.48%       7.703ms      25.677us           300  \n",
      "                                              aten::pow         0.87%       2.359ms         1.20%       3.265ms      16.325us       7.355ms        10.01%       7.355ms      36.775us           200  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       7.355ms        10.01%       7.355ms      36.775us           200  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us       6.601ms         8.98%       6.601ms      66.010us           100  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     958.000us         1.30%     958.000us       4.790us           200  \n",
      "                                              aten::add         0.86%       2.342ms         1.52%       4.139ms      20.695us     700.000us         0.95%     700.000us       3.500us           200  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     700.000us         0.95%     700.000us       3.500us           200  \n",
      "void at::native::(anonymous namespace)::indexSelectS...         0.00%       0.000us         0.00%       0.000us       0.000us     700.000us         0.95%     700.000us       7.000us           100  \n",
      "                                  fused_add_pow_add_sub         0.43%       1.181ms         0.58%       1.576ms      15.760us     700.000us         0.95%     700.000us       7.000us           100  \n",
      "                                  fused_add_pow_add_sub         0.00%       0.000us         0.00%       0.000us       0.000us     700.000us         0.95%     700.000us       7.000us           100  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us     402.000us         0.55%     402.000us       4.020us           100  \n",
      "                                          aten::reshape         0.23%     619.000us         1.18%       3.228ms      16.140us       0.000us         0.00%     200.000us       1.000us           200  \n",
      "                                            aten::copy_         0.33%     893.000us         0.52%       1.414ms      14.140us     200.000us         0.27%     200.000us       2.000us           100  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     200.000us         0.27%     200.000us       2.000us           100  \n",
      "                                            aten::clone         0.15%     398.000us         0.91%       2.492ms      24.920us       0.000us         0.00%     196.000us       1.960us           100  \n",
      "                                      fused_add_mul_add         0.33%     896.000us         0.46%       1.263ms      12.630us     100.000us         0.14%     100.000us       1.000us           100  \n",
      "                                          aten::sigmoid         0.40%       1.099ms         0.58%       1.567ms      15.670us     100.000us         0.14%     100.000us       1.000us           100  \n",
      "                                      fused_add_mul_add         0.00%       0.000us         0.00%       0.000us       0.000us     100.000us         0.14%     100.000us       1.000us           100  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     100.000us         0.14%     100.000us       1.000us           100  \n",
      "                                       cudaLaunchKernel         2.99%       8.148ms         2.99%       8.148ms       5.432us       0.000us         0.00%       0.000us       0.000us          1500  \n",
      "                                             aten::view         0.04%      98.000us         0.04%      98.000us       0.327us       0.000us         0.00%       0.000us       0.000us           300  \n",
      "                                            aten::empty         0.64%       1.750ms         0.64%       1.750ms       4.375us       0.000us         0.00%       0.000us       0.000us           400  \n",
      "                                          aten::resize_         0.48%       1.306ms         0.48%       1.306ms       4.353us       0.000us         0.00%       0.000us       0.000us           300  \n",
      "                                       aten::as_strided         0.03%      76.000us         0.03%      76.000us       0.076us       0.000us         0.00%       0.000us       0.000us          1000  \n",
      "                                           aten::select         0.21%     559.000us         0.21%     565.000us       5.650us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                            aten::slice         0.32%     876.000us         0.32%     880.000us       2.933us       0.000us         0.00%       0.000us       0.000us           300  \n",
      "                                       aten::empty_like         0.08%     227.000us         0.26%     705.000us       7.050us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                     aten::_unsafe_view         0.00%       5.000us         0.00%       5.000us       0.050us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                      aten::result_type         0.00%       1.000us         0.00%       1.000us       0.005us       0.000us         0.00%       0.000us       0.000us           200  \n",
      "                                               aten::to         0.00%       1.000us         0.00%       1.000us       0.005us       0.000us         0.00%       0.000us       0.000us           200  \n",
      "                                         cuLaunchKernel         0.29%     800.000us         0.29%     800.000us       4.000us       0.000us         0.00%       0.000us       0.000us           200  \n",
      "                                          aten::squeeze         0.14%     385.000us         0.14%     385.000us       3.850us       0.000us         0.00%       0.000us       0.000us           100  \n",
      "                                  cudaDeviceSynchronize         0.00%       8.000us         0.00%       8.000us       8.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 272.422ms\n",
      "Self CUDA time total: 73.489ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p2.key_averages().table(sort_by=\"cuda_time_total\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori, modify = workload_FM(22,10,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(ori, torch.randint(low=0, high=88, size=(4096,22), dtype=torch.long))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_model = torch.compile(traced_model, backend=\"inductor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:54:23 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:54:23 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:54:23 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "122.13635444641113"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_model.eval()\n",
    "total_time = 0\n",
    "t = torch.randint(low=0, high=88, size=(4096 ,22), dtype=torch.long)\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = compiled_model(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time += elapsed_time\n",
    "total_time * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "        model_inference         6.97%       8.553ms       100.00%     122.791ms     122.791ms             1  \n",
      "                forward         3.43%       4.214ms        93.03%     114.238ms       1.142ms           100  \n",
      "        aten::embedding         1.65%       2.031ms        30.41%      37.342ms     186.710us           200  \n",
      "     aten::index_select        27.16%      33.348ms        28.40%      34.868ms     174.340us           200  \n",
      "              aten::sum        16.97%      20.839ms        22.08%      27.117ms      67.793us           400  \n",
      "              aten::add        15.90%      19.521ms        15.90%      19.521ms      48.803us           400  \n",
      "              aten::pow        13.88%      17.043ms        13.90%      17.065ms      85.325us           200  \n",
      "            aten::fill_         5.09%       6.253ms         5.09%       6.253ms      15.633us           400  \n",
      "              aten::sub         3.90%       4.783ms         3.90%       4.783ms      47.830us           100  \n",
      "              aten::mul         1.18%       1.450ms         2.26%       2.778ms      27.780us           100  \n",
      "           aten::select         1.05%       1.294ms         1.12%       1.371ms       3.428us           400  \n",
      "               aten::to         0.24%     300.000us         1.01%       1.242ms       4.140us           300  \n",
      "         aten::_to_copy         0.54%     660.000us         0.83%       1.017ms      10.170us           100  \n",
      "          aten::sigmoid         0.69%     851.000us         0.69%     851.000us       8.510us           100  \n",
      "          aten::squeeze         0.44%     540.000us         0.46%     567.000us       5.670us           100  \n",
      "          aten::reshape         0.27%     328.000us         0.34%     423.000us       2.115us           200  \n",
      "            aten::copy_         0.21%     253.000us         0.21%     253.000us       2.530us           100  \n",
      "            aten::empty         0.12%     146.000us         0.12%     146.000us       0.730us           200  \n",
      "       aten::as_strided         0.11%     132.000us         0.11%     132.000us       0.165us           800  \n",
      "    aten::empty_strided         0.10%     125.000us         0.10%     125.000us       1.250us           100  \n",
      "             aten::view         0.09%     115.000us         0.09%     115.000us       0.287us           400  \n",
      "      aten::result_type         0.01%      12.000us         0.01%      12.000us       0.060us           200  \n",
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 122.791ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(modify, torch.randint(low=0, high=88, size=(4096 ,22), dtype=torch.long))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_model = torch.compile(traced_model, backend=\"inductor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:54:24 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:54:24 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:54:24 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "128.45373153686523"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_model.eval()\n",
    "total_time = 0\n",
    "t = torch.randint(low=0, high=88, size=(4096 ,22), dtype=torch.long)\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = compiled_model(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time += elapsed_time\n",
    "total_time * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "        model_inference         7.23%       9.322ms       100.00%     128.853ms     128.853ms             1  \n",
      "                forward         4.75%       6.121ms        92.76%     119.518ms       1.195ms           100  \n",
      "        aten::embedding         1.70%       2.186ms        32.26%      41.574ms     138.580us           300  \n",
      "     aten::index_select        22.55%      29.058ms        23.96%      30.875ms     102.917us           300  \n",
      "              aten::add        22.92%      29.529ms        22.92%      29.529ms      49.215us           600  \n",
      "              aten::sum        16.03%      20.650ms        20.60%      26.542ms      44.237us           600  \n",
      "          aten::reshape         0.55%     706.000us         6.61%       8.522ms      42.610us           200  \n",
      "              aten::pow         5.91%       7.616ms         5.91%       7.616ms      25.387us           300  \n",
      "            aten::clone         0.51%     651.000us         5.86%       7.547ms      75.470us           100  \n",
      "            aten::copy_         5.30%       6.826ms         5.30%       6.826ms      34.130us           200  \n",
      "            aten::fill_         4.55%       5.859ms         4.55%       5.859ms       9.765us           600  \n",
      "              aten::mul         1.05%       1.357ms         2.03%       2.617ms      26.170us           100  \n",
      "              aten::sub         1.88%       2.422ms         1.88%       2.422ms      24.220us           100  \n",
      "           aten::select         1.67%       2.152ms         1.74%       2.237ms       3.196us           700  \n",
      "            aten::slice         0.92%       1.187ms         0.93%       1.199ms       3.997us           300  \n",
      "               aten::to         0.26%     332.000us         0.86%       1.104ms       2.760us           400  \n",
      "         aten::_to_copy         0.46%     593.000us         0.72%     928.000us       9.280us           100  \n",
      "          aten::sigmoid         0.63%     812.000us         0.63%     812.000us       8.120us           100  \n",
      "          aten::squeeze         0.38%     492.000us         0.39%     506.000us       5.060us           100  \n",
      "       aten::empty_like         0.21%     276.000us         0.32%     407.000us       4.070us           100  \n",
      "            aten::empty         0.22%     285.000us         0.22%     285.000us       0.713us           400  \n",
      "       aten::as_strided         0.11%     147.000us         0.11%     147.000us       0.092us          1600  \n",
      "    aten::empty_strided         0.10%     127.000us         0.10%     127.000us       1.270us           100  \n",
      "             aten::view         0.08%     102.000us         0.08%     102.000us       0.340us           300  \n",
      "     aten::_unsafe_view         0.03%      45.000us         0.03%      45.000us       0.450us           100  \n",
      "      aten::result_type         0.00%       0.000us         0.00%       0.000us       0.000us           300  \n",
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 128.853ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori, modify = workload_FM(22,10,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(ori, torch.randint(low=0, high=88, size=(4096,22), dtype=torch.long))\n",
    "compiled_model = torch.compile(traced_model, backend=\"inductor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:54:25 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:54:25 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:54:25 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "140.59686660766602"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_model.eval()\n",
    "total_time = 0\n",
    "t = torch.randint(low=0, high=88, size=(4096 ,22), dtype=torch.long)\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = compiled_model(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time += elapsed_time\n",
    "total_time * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "        model_inference         6.14%       8.646ms       100.00%     140.914ms     140.914ms             1  \n",
      "                forward         3.02%       4.258ms        93.86%     132.260ms       1.323ms           100  \n",
      "        aten::embedding         1.64%       2.311ms        29.42%      41.451ms     207.255us           200  \n",
      "     aten::index_select        26.25%      36.993ms        27.41%      38.629ms     193.145us           200  \n",
      "              aten::sum        22.39%      31.548ms        25.69%      36.203ms      90.507us           400  \n",
      "              aten::pow        17.64%      24.861ms        17.66%      24.881ms     124.405us           200  \n",
      "              aten::add        11.55%      16.282ms        11.55%      16.282ms      40.705us           400  \n",
      "              aten::sub         3.62%       5.098ms         3.62%       5.098ms      50.980us           100  \n",
      "            aten::fill_         3.21%       4.526ms         3.21%       4.526ms      11.315us           400  \n",
      "              aten::mul         0.97%       1.363ms         1.97%       2.770ms      27.426us           101  \n",
      "           aten::select         0.98%       1.380ms         1.06%       1.490ms       3.725us           400  \n",
      "               aten::to         0.22%     317.000us         0.96%       1.346ms       4.487us           300  \n",
      "         aten::_to_copy         0.47%     657.000us         0.77%       1.079ms      10.790us           100  \n",
      "          aten::sigmoid         0.51%     723.000us         0.51%     723.000us       7.230us           100  \n",
      "          aten::squeeze         0.41%     576.000us         0.43%     602.000us       6.020us           100  \n",
      "          aten::reshape         0.27%     387.000us         0.35%     500.000us       2.500us           200  \n",
      "       aten::as_strided         0.19%     270.000us         0.19%     270.000us       0.338us           800  \n",
      "            aten::copy_         0.18%     253.000us         0.18%     253.000us       2.530us           100  \n",
      "    aten::empty_strided         0.13%     190.000us         0.13%     190.000us       1.900us           100  \n",
      "            aten::empty         0.10%     141.000us         0.10%     141.000us       0.705us           200  \n",
      "             aten::view         0.09%     124.000us         0.09%     124.000us       0.310us           400  \n",
      "      aten::result_type         0.01%      10.000us         0.01%      10.000us       0.050us           200  \n",
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 140.914ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(modify, torch.randint(low=0, high=88, size=(4096,22), dtype=torch.long))\n",
    "compiled_model = torch.compile(traced_model, backend=\"inductor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:54:25 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:54:26 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:54:26 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "139.2350196838379"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_model.eval()\n",
    "total_time = 0\n",
    "t = torch.randint(low=0, high=88, size=(4096 ,22), dtype=torch.long)\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = compiled_model(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time += elapsed_time\n",
    "total_time * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "        model_inference         6.92%       9.657ms       100.00%     139.538ms     139.538ms             1  \n",
      "                forward         4.37%       6.095ms        93.08%     129.881ms       1.299ms           100  \n",
      "        aten::embedding         1.67%       2.333ms        31.24%      43.591ms     145.303us           300  \n",
      "     aten::index_select        22.35%      31.180ms        23.80%      33.217ms     110.723us           300  \n",
      "              aten::sum        18.74%      26.143ms        23.31%      32.523ms      54.205us           600  \n",
      "              aten::add        19.27%      26.888ms        19.27%      26.888ms      44.813us           600  \n",
      "              aten::pow         8.78%      12.254ms         8.78%      12.254ms      40.847us           300  \n",
      "          aten::reshape         0.55%     766.000us         5.75%       8.023ms      40.115us           200  \n",
      "            aten::clone         0.42%     585.000us         5.06%       7.056ms      70.560us           100  \n",
      "            aten::fill_         4.49%       6.261ms         4.49%       6.261ms      10.435us           600  \n",
      "            aten::copy_         4.49%       6.260ms         4.49%       6.260ms      31.300us           200  \n",
      "              aten::sub         1.93%       2.693ms         1.93%       2.693ms      26.930us           100  \n",
      "              aten::mul         0.96%       1.345ms         1.87%       2.605ms      26.050us           100  \n",
      "           aten::select         1.70%       2.377ms         1.79%       2.495ms       3.564us           700  \n",
      "            aten::slice         0.85%       1.188ms         0.86%       1.198ms       3.993us           300  \n",
      "               aten::to         0.21%     290.000us         0.82%       1.144ms       2.860us           400  \n",
      "         aten::_to_copy         0.44%     618.000us         0.69%     961.000us       9.610us           100  \n",
      "          aten::sigmoid         0.60%     844.000us         0.60%     844.000us       8.440us           100  \n",
      "          aten::squeeze         0.37%     513.000us         0.39%     548.000us       5.480us           100  \n",
      "       aten::empty_like         0.20%     282.000us         0.36%     497.000us       4.970us           100  \n",
      "            aten::empty         0.28%     396.000us         0.28%     396.000us       0.990us           400  \n",
      "       aten::as_strided         0.20%     285.000us         0.20%     285.000us       0.178us          1600  \n",
      "    aten::empty_strided         0.09%     122.000us         0.09%     122.000us       1.220us           100  \n",
      "             aten::view         0.08%     107.000us         0.08%     107.000us       0.357us           300  \n",
      "     aten::_unsafe_view         0.04%      56.000us         0.04%      56.000us       0.560us           100  \n",
      "      aten::result_type         0.00%       0.000us         0.00%       0.000us       0.000us           300  \n",
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 139.538ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori, modify = workload_FM(34,29,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(ori, torch.randint(low=0, high=88, size=(4096,34), dtype=torch.long))\n",
    "compiled_model = torch.compile(traced_model, backend=\"inductor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:54:27 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:54:27 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:54:27 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "125.51569938659668"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_model.eval()\n",
    "total_time = 0\n",
    "t = torch.randint(low=0, high=88, size=(4096 ,34), dtype=torch.long)\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = compiled_model(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time += elapsed_time\n",
    "total_time * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "        model_inference         6.91%       8.683ms       100.00%     125.728ms     125.728ms             1  \n",
      "                forward         3.49%       4.385ms        93.09%     117.045ms       1.170ms           100  \n",
      "        aten::embedding         1.85%       2.331ms        30.07%      37.812ms     189.060us           200  \n",
      "     aten::index_select        26.50%      33.320ms        27.83%      34.987ms     174.935us           200  \n",
      "              aten::sum        19.52%      24.540ms        24.67%      31.018ms      77.545us           400  \n",
      "              aten::pow        13.92%      17.502ms        13.93%      17.513ms      87.565us           200  \n",
      "              aten::add        13.89%      17.462ms        13.89%      17.462ms      43.655us           400  \n",
      "            aten::fill_         5.07%       6.375ms         5.07%       6.375ms      15.938us           400  \n",
      "              aten::sub         3.75%       4.719ms         3.75%       4.719ms      47.190us           100  \n",
      "              aten::mul         1.10%       1.382ms         2.24%       2.816ms      28.160us           100  \n",
      "           aten::select         1.13%       1.425ms         1.20%       1.511ms       3.777us           400  \n",
      "               aten::to         0.25%     315.000us         1.09%       1.368ms       4.560us           300  \n",
      "         aten::_to_copy         0.53%     666.000us         0.88%       1.103ms      11.030us           100  \n",
      "          aten::sigmoid         0.56%     709.000us         0.56%     709.000us       7.090us           100  \n",
      "          aten::squeeze         0.47%     588.000us         0.49%     611.000us       6.110us           100  \n",
      "          aten::reshape         0.30%     376.000us         0.38%     480.000us       2.400us           200  \n",
      "            aten::copy_         0.21%     270.000us         0.21%     270.000us       2.700us           100  \n",
      "       aten::as_strided         0.17%     213.000us         0.17%     213.000us       0.266us           800  \n",
      "    aten::empty_strided         0.15%     194.000us         0.15%     194.000us       1.940us           100  \n",
      "            aten::empty         0.12%     155.000us         0.12%     155.000us       0.775us           200  \n",
      "             aten::view         0.09%     118.000us         0.09%     118.000us       0.295us           400  \n",
      "      aten::result_type         0.00%       0.000us         0.00%       0.000us       0.000us           200  \n",
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 125.728ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(modify, torch.randint(low=0, high=88, size=(4096,34), dtype=torch.long))\n",
    "compiled_model = torch.compile(traced_model, backend=\"inductor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:54:27 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:54:27 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:54:27 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "137.09211349487305"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_model.eval()\n",
    "total_time = 0\n",
    "t = torch.randint(low=0, high=88, size=(4096 ,34), dtype=torch.long)\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = compiled_model(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time += elapsed_time\n",
    "total_time * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "        model_inference         6.74%       9.251ms       100.00%     137.322ms     137.322ms             1  \n",
      "                forward         4.62%       6.344ms        93.26%     128.071ms       1.281ms           100  \n",
      "        aten::embedding         1.59%       2.185ms        33.42%      45.897ms     152.990us           300  \n",
      "     aten::index_select        20.02%      27.487ms        21.33%      29.296ms      97.653us           300  \n",
      "              aten::add        21.29%      29.235ms        21.29%      29.235ms      48.725us           600  \n",
      "              aten::sum        16.61%      22.813ms        20.78%      28.536ms      47.560us           600  \n",
      "          aten::reshape         0.53%     722.000us        10.50%      14.414ms      72.070us           200  \n",
      "            aten::clone         0.42%     583.000us         9.77%      13.410ms     134.100us           100  \n",
      "            aten::copy_         9.30%      12.773ms         9.30%      12.773ms      63.865us           200  \n",
      "              aten::pow         7.05%       9.683ms         7.05%       9.683ms      32.277us           300  \n",
      "            aten::fill_         4.16%       5.717ms         4.16%       5.717ms       9.528us           600  \n",
      "              aten::mul         1.01%       1.382ms         1.91%       2.624ms      26.240us           100  \n",
      "              aten::sub         1.88%       2.582ms         1.88%       2.582ms      25.820us           100  \n",
      "           aten::select         1.57%       2.151ms         1.62%       2.226ms       3.180us           700  \n",
      "            aten::slice         0.85%       1.173ms         0.88%       1.213ms       4.043us           300  \n",
      "               aten::to         0.20%     279.000us         0.83%       1.134ms       2.835us           400  \n",
      "         aten::_to_copy         0.45%     618.000us         0.70%     963.000us       9.630us           100  \n",
      "          aten::sigmoid         0.59%     814.000us         0.59%     814.000us       8.140us           100  \n",
      "          aten::squeeze         0.38%     518.000us         0.39%     537.000us       5.370us           100  \n",
      "       aten::empty_like         0.20%     273.000us         0.28%     386.000us       3.860us           100  \n",
      "            aten::empty         0.21%     290.000us         0.21%     290.000us       0.725us           400  \n",
      "    aten::empty_strided         0.10%     141.000us         0.10%     141.000us       1.410us           100  \n",
      "       aten::as_strided         0.10%     140.000us         0.10%     140.000us       0.087us          1600  \n",
      "             aten::view         0.08%     104.000us         0.08%     104.000us       0.347us           300  \n",
      "     aten::_unsafe_view         0.05%      64.000us         0.05%      64.000us       0.640us           100  \n",
      "      aten::result_type         0.00%       0.000us         0.00%       0.000us       0.000us           300  \n",
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 137.322ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori, modify = workload_FM(34,29,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(ori, torch.randint(low=0, high=88, size=(4096,34), dtype=torch.long))\n",
    "compiled_model = torch.compile(traced_model, backend=\"inductor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:54:28 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:54:29 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:54:29 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "        model_inference         6.18%      10.310ms       100.00%     166.759ms     166.759ms             1  \n",
      "                forward         3.10%       5.172ms        93.82%     156.449ms       1.564ms           100  \n",
      "              aten::sum        23.25%      38.768ms        26.66%      44.466ms     111.165us           400  \n",
      "        aten::embedding         1.53%       2.546ms        26.14%      43.592ms     217.960us           200  \n",
      "     aten::index_select        23.21%      38.700ms        24.30%      40.530ms     202.650us           200  \n",
      "              aten::pow        22.68%      37.822ms        22.69%      37.833ms     189.165us           200  \n",
      "              aten::add         9.13%      15.233ms         9.13%      15.233ms      38.083us           400  \n",
      "            aten::fill_         3.33%       5.561ms         3.33%       5.561ms      13.902us           400  \n",
      "              aten::sub         3.30%       5.505ms         3.30%       5.505ms      55.050us           100  \n",
      "              aten::mul         0.90%       1.508ms         1.92%       3.197ms      31.970us           100  \n",
      "           aten::select         0.93%       1.556ms         1.00%       1.662ms       4.155us           400  \n",
      "               aten::to         0.24%     405.000us         0.96%       1.600ms       5.333us           300  \n",
      "         aten::_to_copy         0.46%     767.000us         0.77%       1.284ms      12.840us           100  \n",
      "          aten::sigmoid         0.46%     768.000us         0.46%     768.000us       7.680us           100  \n",
      "          aten::squeeze         0.39%     654.000us         0.41%     683.000us       6.830us           100  \n",
      "          aten::reshape         0.23%     377.000us         0.29%     486.000us       2.430us           200  \n",
      "            aten::copy_         0.19%     309.000us         0.19%     309.000us       3.090us           100  \n",
      "       aten::as_strided         0.16%     274.000us         0.16%     274.000us       0.343us           800  \n",
      "    aten::empty_strided         0.12%     208.000us         0.12%     208.000us       2.080us           100  \n",
      "            aten::empty         0.10%     166.000us         0.10%     166.000us       0.830us           200  \n",
      "             aten::view         0.08%     139.000us         0.08%     139.000us       0.347us           400  \n",
      "      aten::result_type         0.01%      11.000us         0.01%      11.000us       0.055us           200  \n",
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 166.759ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compiled_model.eval()\n",
    "total_time = 0\n",
    "t = torch.randint(low=0, high=88, size=(4096 ,34), dtype=torch.long)\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = compiled_model(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time += elapsed_time\n",
    "total_time * 1000\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(modify, torch.randint(low=0, high=88, size=(4096,34), dtype=torch.long))\n",
    "compiled_model = torch.compile(traced_model, backend=\"inductor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:54:29 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:54:29 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:54:29 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "        model_inference         6.33%       9.100ms       100.00%     143.811ms     143.811ms             1  \n",
      "                forward         4.33%       6.222ms        93.67%     134.702ms       1.347ms           100  \n",
      "        aten::embedding         1.53%       2.197ms        30.96%      44.522ms     148.407us           300  \n",
      "              aten::sum        20.88%      30.028ms        24.83%      35.704ms      59.507us           600  \n",
      "              aten::add        19.66%      28.267ms        19.66%      28.267ms      47.112us           600  \n",
      "     aten::index_select        17.16%      24.673ms        18.42%      26.495ms      88.317us           300  \n",
      "          aten::reshape         0.16%     237.000us        11.00%      15.816ms      79.080us           200  \n",
      "            aten::clone         0.76%       1.093ms        10.31%      14.827ms     148.270us           100  \n",
      "            aten::copy_         9.84%      14.155ms         9.84%      14.155ms      70.775us           200  \n",
      "              aten::pow         8.34%      11.996ms         8.34%      11.996ms      39.987us           300  \n",
      "            aten::fill_         3.94%       5.663ms         3.94%       5.663ms       9.438us           600  \n",
      "              aten::sub         1.75%       2.510ms         1.75%       2.510ms      25.100us           100  \n",
      "              aten::mul         0.87%       1.254ms         1.72%       2.478ms      24.780us           100  \n",
      "           aten::select         1.52%       2.179ms         1.54%       2.216ms       3.166us           700  \n",
      "            aten::slice         0.79%       1.137ms         0.80%       1.145ms       3.817us           300  \n",
      "               aten::to         0.21%     302.000us         0.75%       1.085ms       2.712us           400  \n",
      "         aten::_to_copy         0.42%     603.000us         0.64%     919.000us       9.190us           100  \n",
      "          aten::sigmoid         0.53%     767.000us         0.53%     767.000us       7.670us           100  \n",
      "          aten::squeeze         0.36%     513.000us         0.36%     516.000us       5.160us           100  \n",
      "       aten::empty_like         0.16%     236.000us         0.25%     365.000us       3.650us           100  \n",
      "            aten::empty         0.21%     301.000us         0.21%     301.000us       0.752us           400  \n",
      "             aten::view         0.08%     114.000us         0.08%     114.000us       0.380us           300  \n",
      "    aten::empty_strided         0.08%     114.000us         0.08%     114.000us       1.140us           100  \n",
      "     aten::_unsafe_view         0.06%      88.000us         0.06%      88.000us       0.880us           100  \n",
      "       aten::as_strided         0.04%      62.000us         0.04%      62.000us       0.039us          1600  \n",
      "      aten::result_type         0.00%       0.000us         0.00%       0.000us       0.000us           300  \n",
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 143.811ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compiled_model.eval()\n",
    "total_time = 0\n",
    "t = torch.randint(low=0, high=88, size=(4096 ,34), dtype=torch.long)\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = compiled_model(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time += elapsed_time\n",
    "total_time * 1000\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori, modify = workload_FM(100,40,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(ori, torch.randint(low=0, high=88, size=(4096,100), dtype=torch.long))\n",
    "compiled_model = torch.compile(traced_model, backend=\"inductor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290.47369956970215"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_model.eval()\n",
    "total_time = 0\n",
    "for i in range(100):\n",
    "    t = torch.randint(low=0, high=88, size=(4096 ,100), dtype=torch.long)\n",
    "    start_time = time.time()  # 开始计时\n",
    "    with torch.no_grad():\n",
    "      soutput = compiled_model(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time += elapsed_time\n",
    "total_time * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:54:31 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:54:32 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:54:32 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "281.5871238708496"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_model.eval()\n",
    "total_time = 0\n",
    "t = torch.randint(low=0, high=88, size=(4096 ,100), dtype=torch.long)\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = compiled_model(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time += elapsed_time\n",
    "total_time * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "        model_inference         6.02%      16.995ms       100.00%     282.179ms     282.179ms             1  \n",
      "                forward         2.89%       8.169ms        93.98%     265.184ms       2.652ms           100  \n",
      "        aten::embedding         1.20%       3.394ms        26.43%      74.578ms     372.890us           200  \n",
      "              aten::sum        22.84%      64.442ms        25.70%      72.524ms     181.310us           400  \n",
      "              aten::pow        25.18%      71.047ms        25.21%      71.135ms     355.675us           200  \n",
      "     aten::index_select        24.11%      68.027ms        24.94%      70.365ms     351.825us           200  \n",
      "              aten::add         7.94%      22.412ms         7.94%      22.412ms      56.030us           400  \n",
      "              aten::sub         2.82%       7.965ms         2.82%       7.965ms      79.650us           100  \n",
      "            aten::fill_         2.80%       7.895ms         2.80%       7.895ms      19.738us           400  \n",
      "              aten::mul         0.90%       2.526ms         2.03%       5.720ms      56.634us           101  \n",
      "               aten::to         0.28%     785.000us         1.07%       3.028ms      10.093us           300  \n",
      "         aten::_to_copy         0.51%       1.433ms         0.86%       2.426ms      24.260us           100  \n",
      "           aten::select         0.67%       1.880ms         0.73%       2.047ms       5.117us           400  \n",
      "          aten::sigmoid         0.50%       1.425ms         0.50%       1.425ms      14.250us           100  \n",
      "          aten::squeeze         0.41%       1.144ms         0.45%       1.256ms      12.560us           100  \n",
      "          aten::reshape         0.18%     515.000us         0.25%     714.000us       3.570us           200  \n",
      "            aten::copy_         0.21%     600.000us         0.21%     600.000us       6.000us           100  \n",
      "       aten::as_strided         0.17%     466.000us         0.17%     466.000us       0.583us           800  \n",
      "    aten::empty_strided         0.14%     403.000us         0.14%     403.000us       4.030us           100  \n",
      "             aten::view         0.11%     304.000us         0.11%     304.000us       0.760us           400  \n",
      "            aten::empty         0.10%     291.000us         0.10%     291.000us       1.455us           200  \n",
      "      aten::result_type         0.02%      61.000us         0.02%      61.000us       0.305us           200  \n",
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 282.179ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(modify, torch.randint(low=0, high=88, size=(4096,100), dtype=torch.long))\n",
    "compiled_model = torch.compile(traced_model, backend=\"inductor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188.47107887268066"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_model.eval()\n",
    "total_time = 0\n",
    "for i in range(100):\n",
    "    t = torch.randint(low=0, high=88, size=(4096 ,100), dtype=torch.long)\n",
    "    start_time = time.time()  # 开始计时\n",
    "    with torch.no_grad():\n",
    "      soutput = compiled_model(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time += elapsed_time\n",
    "total_time * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 19:54:33 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 19:54:33 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 19:54:33 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "174.88574981689453"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_model.eval()\n",
    "total_time = 0\n",
    "t = torch.randint(low=0, high=88, size=(4096 ,100), dtype=torch.long)\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = compiled_model(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time += elapsed_time\n",
    "total_time * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "        model_inference         4.04%       7.071ms       100.00%     175.148ms     175.148ms             1  \n",
      "                forward         4.12%       7.224ms        95.96%     168.077ms       1.681ms           100  \n",
      "        aten::embedding         1.34%       2.344ms        33.99%      59.541ms     198.470us           300  \n",
      "     aten::index_select        24.44%      42.799ms        25.45%      44.576ms     148.587us           300  \n",
      "              aten::sum        21.22%      37.171ms        24.63%      43.147ms      71.912us           600  \n",
      "              aten::add        15.13%      26.500ms        15.13%      26.500ms      44.167us           600  \n",
      "              aten::pow        12.80%      22.411ms        12.80%      22.411ms      74.703us           300  \n",
      "          aten::reshape         0.49%     853.000us         7.19%      12.588ms      62.940us           200  \n",
      "            aten::clone         0.33%     573.000us         6.64%      11.628ms     116.280us           100  \n",
      "            aten::copy_         6.19%      10.846ms         6.19%      10.846ms      54.230us           200  \n",
      "            aten::fill_         3.38%       5.925ms         3.38%       5.925ms       9.875us           600  \n",
      "              aten::mul         0.92%       1.608ms         1.69%       2.958ms      29.580us           100  \n",
      "              aten::sub         1.67%       2.923ms         1.67%       2.923ms      29.230us           100  \n",
      "           aten::select         1.22%       2.141ms         1.27%       2.224ms       3.177us           700  \n",
      "               aten::to         0.15%     265.000us         0.73%       1.279ms       3.197us           400  \n",
      "            aten::slice         0.68%       1.190ms         0.69%       1.207ms       4.023us           300  \n",
      "         aten::_to_copy         0.39%     685.000us         0.61%       1.076ms      10.760us           100  \n",
      "          aten::sigmoid         0.53%     930.000us         0.53%     930.000us       9.300us           100  \n",
      "          aten::squeeze         0.32%     568.000us         0.35%     607.000us       6.070us           100  \n",
      "       aten::empty_like         0.15%     258.000us         0.25%     443.000us       4.430us           100  \n",
      "            aten::empty         0.21%     368.000us         0.21%     368.000us       0.920us           400  \n",
      "       aten::as_strided         0.11%     191.000us         0.11%     191.000us       0.119us          1600  \n",
      "    aten::empty_strided         0.09%     164.000us         0.09%     164.000us       1.640us           100  \n",
      "             aten::view         0.07%     131.000us         0.07%     131.000us       0.437us           300  \n",
      "     aten::_unsafe_view         0.01%       9.000us         0.01%       9.000us       0.090us           100  \n",
      "      aten::result_type         0.00%       0.000us         0.00%       0.000us       0.000us           300  \n",
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 175.148ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph_module.py\", line 304, in __call__\n",
      "    return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]\n",
      "  File \"/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1522, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<eval_with_key>.257 from /home/yssun/pytorch-fm/torchfm/model/test_fx/exp/../../fm.py:23 in forward\", line 6, in forward\n",
      "    add = x + linear_offsets;  linear_offsets = None\n",
      "RuntimeError: The size of tensor a (34) must match the size of tensor b (100) at non-singleton dimension 1\n",
      "\n",
      "Call using an FX-traced Module, line 6 of the traced Module's generated forward function:\n",
      "    linear_offsets = self.linear.offsets\n",
      "    add = x + linear_offsets;  linear_offsets = None\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "    linear_fc = self.linear.fc(add);  add = None\n",
      "\n",
      "    sum_1 = torch.sum(linear_fc, dim = 1);  linear_fc = None\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (34) must match the size of tensor b (100) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m traced_model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodify\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhigh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m88\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m34\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m compiled_model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcompile(traced_model, backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minductor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py:451\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m prior \u001b[38;5;241m=\u001b[39m set_eval_frame(callback)\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    453\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m~/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/_dynamo/external_utils.py:36\u001b[0m, in \u001b[0;36mwrap_inline.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/jit/_trace.py:820\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    819\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_kwarg_inputs should be a dict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrap_check_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_inputs_is_kwarg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexample_kwarg_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_store_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[1;32m    836\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    837\u001b[0m ):\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m example_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/jit/_trace.py:1088\u001b[0m, in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_inputs_is_kwarg, _store_inputs)\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1087\u001b[0m     example_inputs \u001b[38;5;241m=\u001b[39m make_tuple(example_inputs)\n\u001b[0;32m-> 1088\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_method_from_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar_lookup_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m        \u001b[49m\u001b[43margument_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m check_trace_method \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_c\u001b[38;5;241m.\u001b[39m_get_method(method_name)\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;66;03m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph_module.py:737\u001b[0m, in \u001b[0;36mGraphModule.recompile.<locals>.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/graph_module.py:315\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_with_key\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m topmost_framesummary\u001b[38;5;241m.\u001b[39mfilename:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    312\u001b[0m         _WrappedCall\u001b[38;5;241m.\u001b[39m_generate_error_message(topmost_framesummary),\n\u001b[1;32m    313\u001b[0m         file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    314\u001b[0m     )\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# noqa: TRY200\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (34) must match the size of tensor b (100) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "traced_model = torch.jit.trace(modify, torch.randint(low=0, high=88, size=(4096,34), dtype=torch.long))\n",
    "compiled_model = torch.compile(traced_model, backend=\"inductor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130.51867485046387"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_model.eval()\n",
    "total_time = 0\n",
    "for i in range(100):\n",
    "    t = torch.randint(low=0, high=88, size=(4096 ,34), dtype=torch.long)\n",
    "    start_time = time.time()  # 开始计时\n",
    "    with torch.no_grad():\n",
    "      soutput = compiled_model(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time += elapsed_time\n",
    "total_time * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124.3293285369873"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_model.eval()\n",
    "total_time = 0\n",
    "for i in range(100):\n",
    "    t = torch.randint(low=0, high=88, size=(4096 ,34), dtype=torch.long)\n",
    "    start_time = time.time()  # 开始计时\n",
    "    with torch.no_grad():\n",
    "      soutput = traced_model(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time += elapsed_time\n",
    "total_time * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of wdl with config: dim: 32, num_field: 22, prefix: 10\n"
     ]
    }
   ],
   "source": [
    "ori, modify = workload_FM(22,10,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.64225578308105"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_model = torch.jit.trace(ori, torch.randint(low=0, high=88, size=(2048,22), dtype=torch.long))\n",
    "total_time = 0\n",
    "for i in range(100):\n",
    "    t = torch.randint(low=0, high=88, size=(2048 ,22), dtype=torch.long)\n",
    "    start_time = time.time()  # 开始计时\n",
    "    soutput = traced_model(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time += elapsed_time\n",
    "total_time * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102.48804092407227"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_model = torch.jit.trace(modify, torch.randint(low=0, high=88, size=(2048,22), dtype=torch.long))\n",
    "total_time = 0\n",
    "for i in range(100):\n",
    "    t = torch.randint(low=0, high=88, size=(2048 ,22), dtype=torch.long)\n",
    "    start_time = time.time()  # 开始计时\n",
    "    soutput = traced_model(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time += elapsed_time\n",
    "total_time * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of wdl with config: dim: 64, num_field: 22, prefix: 10\n"
     ]
    }
   ],
   "source": [
    "ori, modify = workload_FM(22,10,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111.09638214111328"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_model = torch.jit.trace(ori, torch.randint(low=0, high=88, size=(2048,22), dtype=torch.long))\n",
    "total_time = 0\n",
    "for i in range(100):\n",
    "    t = torch.randint(low=0, high=88, size=(2048 ,22), dtype=torch.long)\n",
    "    start_time = time.time()  # 开始计时\n",
    "    soutput = traced_model(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time += elapsed_time\n",
    "total_time * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.17354583740234"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_model = torch.jit.trace(modify, torch.randint(low=0, high=88, size=(2048,22), dtype=torch.long))\n",
    "total_time = 0\n",
    "for i in range(100):\n",
    "    t = torch.randint(low=0, high=88, size=(2048 ,22), dtype=torch.long)\n",
    "    start_time = time.time()  # 开始计时\n",
    "    soutput = traced_model(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time += elapsed_time\n",
    "total_time * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298.5067367553711"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_model = torch.jit.trace(ori, torch.randint(low=0, high=88, size=(4096,22), dtype=torch.long))\n",
    "total_time = 0\n",
    "for i in range(100):\n",
    "    t = torch.randint(low=0, high=88, size=(4096 ,22), dtype=torch.long)\n",
    "    start_time = time.time()  # 开始计时\n",
    "    soutput = traced_model(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time += elapsed_time\n",
    "total_time * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116.41645431518555"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_model = torch.jit.trace(modify, torch.randint(low=0, high=88, size=(4096,22), dtype=torch.long))\n",
    "total_time = 0\n",
    "for i in range(100):\n",
    "    t = torch.randint(low=0, high=88, size=(4096 ,22), dtype=torch.long)\n",
    "    start_time = time.time()  # 开始计时\n",
    "    soutput = traced_model(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time += elapsed_time\n",
    "total_time * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FactorizationMachineModel(\n",
       "  (linear): Module(\n",
       "    (fc): Embedding(2200, 1)\n",
       "  )\n",
       "  (embedding): Module(\n",
       "    (embedding): Embedding(2200, 32)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(ori, torch.randint(low=0, high=88, size=(4096 * 2,22), dtype=torch.long).to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.06 ms ± 982 µs per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30  output = traced_model(torch.randint(low=0, high=88, size=(4096 * 2,22), dtype=torch.long).to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FactorizationMachineModel(\n",
       "  (linear): Module(\n",
       "    (fc): Embedding(2200, 1)\n",
       "  )\n",
       "  (embedding): Module()\n",
       "  (embed): Embedding(2200, 32)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modify.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(modify, torch.randint(low=0, high=88, size=(4096 * 2,22), dtype=torch.long).to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.06 ms ± 880 µs per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30  output = traced_model(torch.randint(low=0, high=88, size=(4096 * 2,22), dtype=torch.long).to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of wdl with config: dim: 64, num_field: 22, prefix: 10\n"
     ]
    }
   ],
   "source": [
    "ori, modify = workload_FM(22,10,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FactorizationMachineModel(\n",
       "  (linear): Module(\n",
       "    (fc): Embedding(2200, 1)\n",
       "  )\n",
       "  (embedding): Module(\n",
       "    (embedding): Embedding(2200, 64)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(ori, torch.randint(low=0, high=88, size=(4096 * 2,22), dtype=torch.long).to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.randint(low=0, high=88, size=(4096 * 2,22), dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311 µs ± 142 µs per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "t = torch.randint(low=0, high=88, size=(4096 * 2,22), dtype=torch.long).to(device)\n",
    "%timeit -n 1 -r 30  output = traced_model(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.293006896972656"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_time = 0\n",
    "for i in range(30):\n",
    "    t = torch.randint(low=0, high=88, size=(4096 * 2,22), dtype=torch.long).to(device)\n",
    "    start_time = time.time()  # 开始计时\n",
    "    soutput = traced_model(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time += elapsed_time\n",
    "total_time * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FactorizationMachineModel(\n",
       "  (linear): Module(\n",
       "    (fc): Embedding(2200, 1)\n",
       "  )\n",
       "  (embedding): Module()\n",
       "  (embed): Embedding(2200, 64)\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modify.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(modify, torch.randint(low=0, high=88, size=(4096 * 2,22), dtype=torch.long).to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.randint(low=0, high=88, size=(4096 * 2,22), dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.205434799194336"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_time = 0\n",
    "for i in range(30):\n",
    "    t = torch.randint(low=0, high=88, size=(4096 * 2,22), dtype=torch.long).to(device)\n",
    "    start_time = time.time()  # 开始计时\n",
    "    soutput = traced_model(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time += elapsed_time\n",
    "total_time * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.58 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "418 µs ± 165 µs per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30  output = traced_model(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of wdl with config: dim: 64, num_field: 110, prefix: 50\n"
     ]
    }
   ],
   "source": [
    "ori, modify = workload_FM(110,50,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FactorizationMachineModel(\n",
       "  (linear): Module(\n",
       "    (fc): Embedding(11000, 1)\n",
       "  )\n",
       "  (embedding): Module(\n",
       "    (embedding): Embedding(11000, 64)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(ori, torch.randint(low=0, high=88, size=(4096 * 2 ,110), dtype=torch.long).to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.686614990234375"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_time = 0\n",
    "for i in range(30):\n",
    "    t = torch.randint(low=0, high=88, size=(4096 * 2,110), dtype=torch.long).to(device)\n",
    "    start_time = time.time()  # 开始计时\n",
    "    soutput = traced_model(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time += elapsed_time\n",
    "total_time * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FactorizationMachineModel(\n",
       "  (linear): Module(\n",
       "    (fc): Embedding(11000, 1)\n",
       "  )\n",
       "  (embedding): Module()\n",
       "  (embed): Embedding(11000, 64)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modify.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(modify, torch.randint(low=0, high=88, size=(4096 * 2 ,110), dtype=torch.long).to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.19430160522461"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_time = 0\n",
    "for i in range(30):\n",
    "    t = torch.randint(low=0, high=88, size=(4096 * 2 ,110), dtype=torch.long).to(device)\n",
    "    start_time = time.time()  # 开始计时\n",
    "    soutput = traced_model(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time += elapsed_time\n",
    "total_time * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of wdl with config: dim: 128, num_field: 34, prefix: 29\n"
     ]
    }
   ],
   "source": [
    "ori, modify = workload_FM(34,29,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FactorizationMachineModel(\n",
       "  (linear): Module(\n",
       "    (fc): Embedding(3400, 1)\n",
       "  )\n",
       "  (embedding): Module(\n",
       "    (embedding): Embedding(3400, 128)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(ori, torch.randint(low=0, high=88, size=(4096 * 2,34), dtype=torch.long).to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.440826416015625"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_time = 0\n",
    "for i in range(30):\n",
    "    t = torch.randint(low=0, high=88, size=(4096 * 2,34), dtype=torch.long).to(device)\n",
    "    start_time = time.time()  # 开始计时\n",
    "    soutput = traced_model(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time += elapsed_time\n",
    "total_time * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FactorizationMachineModel(\n",
       "  (linear): Module(\n",
       "    (fc): Embedding(3400, 1)\n",
       "  )\n",
       "  (embedding): Module()\n",
       "  (embed): Embedding(3400, 128)\n",
       ")"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modify.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(modify, torch.randint(low=0, high=88, size=(4096 * 2,34), dtype=torch.long).to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.769222259521484"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_time = 0\n",
    "for i in range(30):\n",
    "    t = torch.randint(low=0, high=88, size=(4096 * 2,34), dtype=torch.long).to(device)\n",
    "    start_time = time.time()  # 开始计时\n",
    "    soutput = traced_model(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time += elapsed_time\n",
    "total_time * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 10, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 01:19:05 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 01:19:07 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 01:19:07 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17.118701934814453, 0.3701509728216479)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 01:19:07 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 01:19:08 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 01:19:08 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3.230431079864502, 1.686831036630565)\n"
     ]
    }
   ],
   "source": [
    "p1, p2 = gen_and_test_KFLOPS(num_field = 100,prefix = 10, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  Total KFLOPs  \n",
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "              aten::pow        46.47%     795.709ms        46.48%     795.822ms       3.979ms           200            --  \n",
      "              aten::sum        29.13%     498.883ms        30.10%     515.376ms       1.288ms           400            --  \n",
      "     aten::index_select        16.62%     284.552ms        16.75%     286.831ms       1.434ms           200            --  \n",
      "              aten::add         3.27%      55.910ms         3.27%      55.910ms     139.775us           400     82739.200  \n",
      "        model_inference         1.09%      18.647ms       100.00%        1.712s        1.712s             1            --  \n",
      "            aten::fill_         0.95%      16.334ms         0.95%      16.334ms      40.835us           400            --  \n",
      "              aten::sub         0.90%      15.345ms         0.90%      15.345ms     153.450us           100            --  \n",
      "                forward         0.64%      10.993ms        98.91%        1.694s      16.937ms           100            --  \n",
      "        aten::embedding         0.18%       3.108ms        16.99%     290.911ms       1.455ms           200            --  \n",
      "              aten::mul         0.16%       2.786ms         0.35%       6.046ms      60.460us           100       409.600  \n",
      "          aten::sigmoid         0.12%       2.063ms         0.12%       2.063ms      20.630us           100            --  \n",
      "           aten::select         0.11%       1.838ms         0.11%       1.968ms       4.920us           400            --  \n",
      "         aten::_to_copy         0.08%       1.435ms         0.15%       2.652ms      26.520us           100            --  \n",
      "          aten::squeeze         0.07%       1.122ms         0.07%       1.225ms      12.250us           100            --  \n",
      "            aten::copy_         0.05%     792.000us         0.05%     792.000us       7.920us           100            --  \n",
      "          aten::reshape         0.04%     649.000us         0.05%     848.000us       4.240us           200            --  \n",
      "               aten::to         0.03%     594.000us         0.18%       3.104ms      10.347us           300            --  \n",
      "    aten::empty_strided         0.03%     441.000us         0.03%     441.000us       4.410us           100            --  \n",
      "       aten::as_strided         0.02%     395.000us         0.02%     395.000us       0.494us           800            --  \n",
      "             aten::view         0.02%     323.000us         0.02%     323.000us       0.807us           400            --  \n",
      "            aten::empty         0.02%     308.000us         0.02%     308.000us       1.540us           200            --  \n",
      "      aten::result_type         0.01%     111.000us         0.01%     111.000us       0.555us           200            --  \n",
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.712s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p1.key_averages().table(sort_by=\"self_cpu_time_total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  Total KFLOPs  \n",
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "              aten::pow        23.86%      77.179ms        23.87%      77.212ms     257.373us           300            --  \n",
      "              aten::add        19.37%      62.661ms        19.37%      62.661ms     104.435us           600     83558.400  \n",
      "     aten::index_select        19.32%      62.504ms        19.92%      64.446ms     214.820us           300            --  \n",
      "              aten::sum        15.96%      51.639ms        18.26%      59.080ms      98.467us           600            --  \n",
      "        model_inference         5.20%      16.836ms       100.00%     323.498ms     323.498ms             1            --  \n",
      "                forward         3.35%      10.843ms        94.80%     306.662ms       3.067ms           100            --  \n",
      "            aten::copy_         2.94%       9.523ms         2.94%       9.523ms      47.615us           200            --  \n",
      "              aten::sub         2.36%       7.619ms         2.36%       7.619ms      76.190us           100            --  \n",
      "            aten::fill_         2.28%       7.381ms         2.28%       7.381ms      12.302us           600            --  \n",
      "        aten::embedding         0.86%       2.781ms        24.74%      80.048ms     266.827us           300            --  \n",
      "           aten::select         0.74%       2.387ms         0.76%       2.467ms       3.524us           700            --  \n",
      "              aten::mul         0.71%       2.288ms         1.40%       4.541ms      45.410us           100       409.600  \n",
      "            aten::clone         0.63%       2.047ms         3.53%      11.405ms     114.050us           100            --  \n",
      "          aten::sigmoid         0.49%       1.570ms         0.49%       1.570ms      15.700us           100            --  \n",
      "            aten::slice         0.43%       1.382ms         0.45%       1.443ms       4.810us           300            --  \n",
      "         aten::_to_copy         0.32%       1.044ms         0.55%       1.781ms      17.810us           100            --  \n",
      "          aten::reshape         0.28%     910.000us         3.95%      12.776ms      63.880us           200            --  \n",
      "          aten::squeeze         0.27%     881.000us         0.28%     918.000us       9.180us           100            --  \n",
      "               aten::to         0.14%     459.000us         0.66%       2.142ms       5.355us           400            --  \n",
      "       aten::empty_like         0.11%     355.000us         0.16%     521.000us       5.210us           100            --  \n",
      "            aten::empty         0.11%     354.000us         0.11%     354.000us       0.885us           400            --  \n",
      "    aten::empty_strided         0.10%     338.000us         0.10%     338.000us       3.380us           100            --  \n",
      "       aten::as_strided         0.07%     239.000us         0.07%     239.000us       0.149us          1600            --  \n",
      "             aten::view         0.05%     155.000us         0.05%     155.000us       0.517us           300            --  \n",
      "     aten::_unsafe_view         0.03%      90.000us         0.03%      90.000us       0.900us           100            --  \n",
      "      aten::result_type         0.01%      33.000us         0.01%      33.000us       0.110us           300            --  \n",
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 323.498ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p2.key_averages().table(sort_by=\"self_cpu_time_total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 5, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 01:20:28 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 01:20:30 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 01:20:30 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16.083087921142578, 0.2523498727896367)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 01:20:30 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 01:20:32 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 01:20:32 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15.818719863891602, 0.27503584246915125)\n"
     ]
    }
   ],
   "source": [
    "p1, p2 = gen_and_test_KFLOPS(num_field = 100,prefix = 5, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1, p2 = gen_and_test_KFLOPS(num_field = 100,prefix = 5, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 5, batch :2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 01:29:24 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 01:29:24 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 01:29:24 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.384519577026367, 0.1783459845228208)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 01:29:24 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 01:29:24 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 01:29:24 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.3348379135131836, 0.20727670741962356)\n"
     ]
    }
   ],
   "source": [
    "p1, p2 = gen_and_test_KFLOPS(num_field = 100,prefix = 5, batch = 2048, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 10, batch :2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 01:29:26 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 01:29:27 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 01:29:27 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.950448989868164, 1.058004542846902)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 01:29:27 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 01:29:28 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 01:29:28 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.9997572898864746, 0.2690364102534204)\n"
     ]
    }
   ],
   "source": [
    "p1, p2 = gen_and_test_KFLOPS(num_field = 100,prefix = 10, batch = 2048, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 30, batch :2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 01:29:19 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 01:29:20 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 01:29:20 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.27262020111084, 0.10422725360967888)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 01:29:20 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 01:29:20 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 01:29:20 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.8941926956176758, 0.284242965312842)\n"
     ]
    }
   ],
   "source": [
    "p1, p2 = gen_and_test_KFLOPS(num_field = 100,prefix = 30, batch = 2048, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 80, batch :2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 01:29:38 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 01:29:38 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 01:29:38 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.1103262901306152, 0.08136321227425469)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 01:29:38 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 01:29:39 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 01:29:39 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.4752578735351562, 0.09373878342557873)\n"
     ]
    }
   ],
   "source": [
    "p1, p2 = gen_and_test_KFLOPS(num_field = 100,prefix = 80, batch = 2048, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 100, prefix: 10, batch :2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 01:30:04 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 01:30:06 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 01:30:06 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14.344596862792969, 0.10257133908453397)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 01:30:06 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 01:30:08 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 01:30:08 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13.439013957977295, 1.2807581045933603)\n"
     ]
    }
   ],
   "source": [
    "p1, p2 = gen_and_test_KFLOPS(num_field = 100,prefix = 10, batch = 2048, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 100, prefix: 80, batch :2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 01:29:58 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 01:29:59 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 01:29:59 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14.297704696655273, 0.13789806721433706)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-08 01:30:00 2592637:2592637 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-08 01:30:00 2592637:2592637 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-08 01:30:00 2592637:2592637 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.6067957878112793, 0.2092130067637754)\n"
     ]
    }
   ],
   "source": [
    "p1, p2 = gen_and_test_KFLOPS(num_field = 100,prefix = 80, batch = 2048, dim = 64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorrt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
