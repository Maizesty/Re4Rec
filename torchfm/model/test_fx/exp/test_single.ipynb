{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../')\n",
    "import time\n",
    "import pnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch_tensorrt/fx/tracer/acc_tracer/acc_ops.py:895: UserWarning: Unable to import torchvision related libraries.: No module named 'torchvision'. Please install torchvision lib in order to lower stochastic_depth\n",
      "  warnings.warn(\n",
      "Unable to import quantization op. Please install modelopt library (https://github.com/NVIDIA/TensorRT-Model-Optimizer?tab=readme-ov-file#installation) to add support for compiling quantized models\n",
      "TensorRT-LLM is not installed. Please install TensorRT-LLM or set TRTLLM_PLUGINS_PATH to the directory containing libnvinfer_plugin_tensorrt_llm.so to use converters for torch.distributed ops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/11/2025-10:39:15] [TRT] [W] Functionality provided through tensorrt.plugin module is experimental.\n"
     ]
    }
   ],
   "source": [
    "import torch_tensorrt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace success!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.fx import subgraph_rewriter, symbolic_trace\n",
    "import utils\n",
    "from torch.fx import Proxy, Graph, GraphModule\n",
    "from torch.fx.passes.utils.matcher_utils import SubgraphMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import time\n",
    "import torch._dynamo as dynamo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_and_variance_manual(data):\n",
    "    n = len(data)\n",
    "    mean = sum(data) / n\n",
    "    variance = sum((x - mean) ** 2 for x in data) / n\n",
    "    return mean, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatternClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self,x):\n",
    "      empty_like_tensor = torch.ones((4096,100,32))\n",
    "      result_x = x[0,:] - x[0,:]\n",
    "      empty_like_tensor[:,] = result_x\n",
    "      reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "      return torch.sum(reorder_x, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatternClass1(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self,x):\n",
    "      empty_like_tensor = torch.empty((4096,100,32))\n",
    "      result_x = x[0,:] - x[0,:]\n",
    "      empty_like_tensor[:,] = result_x\n",
    "      # reorder_x =  empty_like_tensor[:,(24, 25, 12, 4, 16, 11, 2, 28, 30, 21, 14, 27, 15, 31, 9, 10, 0, 5, 22, 19, 29, 26, 8, 7, 1, 6, 13, 18, 3, 20, 17, 23),:]\n",
    "      return torch.sum(empty_like_tensor, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatternClass2(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self,x):\n",
    "      x * x\n",
    "      # reorder_x =  empty_like_tensor[:,(24, 25, 12, 4, 16, 11, 2, 28, 30, 21, 14, 27, 15, 31, 9, 10, 0, 5, 22, 19, 29, 26, 8, 7, 1, 6, 13, 18, 3, 20, 17, 23),:]\n",
    "      return torch.sum(x * x, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile = torch.compile(PatternClass())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.randint(low=0, high=88, size=(4096 ,100,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6078457832336426, 0.04882914310542219)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = compile(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile = torch.compile(PatternClass(), backend=\"openvino\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25.180869102478027, 3.9181262520514792)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = compile(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cudagraphs', 'inductor', 'onnxrt', 'openvino', 'openxla', 'tvm']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch._dynamo.list_backends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile = torch.compile(PatternClass(), backend=\"cudagraphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26.095049381256104, 7.956240326910802)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = compile(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile = torch.compile(PatternClass1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.21811962127685547, 0.004303291257201636)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = compile(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile = torch.compile(PatternClass1(), backend=\"openvino\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20.279502868652344, 2.6546979233899037)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = compile(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile = torch.compile(PatternClass1(), backend=\"cudagraphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19.095818996429443, 5.34275703450362)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = compile(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile = torch.compile(PatternClass2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.130509376525879, 0.2827468068744565)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = compile(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile = torch.compile(PatternClass2(), backend=\"openvino\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6.178276538848877, 1.1584116421715862)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = compile(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile = torch.compile(PatternClass2(), backend=\"cudagraphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping cudagraphs due to skipping cudagraphs due to cpu device (arg0_1). Found from : \n",
      "   File \"/tmp/ipykernel_3585688/2837069808.py\", line 8, in forward\n",
      "    return torch.sum(x * x, dim = 1)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \u001b[38;5;66;03m# 开始计时\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 7\u001b[0m   soutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \u001b[38;5;66;03m# 结束计时\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# 计算并打印函数执行所需的时间\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py:574\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m saved_dynamic_layer_stack_depth \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    570\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_functorch\u001b[38;5;241m.\u001b[39mget_dynamic_layer_stack_depth()\n\u001b[1;32m    571\u001b[0m )\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;66;03m# Restore the dynamic layer stack depth if necessary.\u001b[39;00m\n\u001b[1;32m    577\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_functorch\u001b[38;5;241m.\u001b[39mpop_dynamic_layer_stack_and_undo_to_depth(\n\u001b[1;32m    578\u001b[0m         saved_dynamic_layer_stack_depth\n\u001b[1;32m    579\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[35], line 5\u001b[0m, in \u001b[0;36mPatternClass2.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[1;32m      6\u001b[0m   x \u001b[38;5;241m*\u001b[39m x\n\u001b[1;32m      7\u001b[0m   \u001b[38;5;66;03m# reorder_x =  empty_like_tensor[:,(24, 25, 12, 4, 16, 11, 2, 28, 30, 21, 14, 27, 15, 31, 9, 10, 0, 5, 22, 19, 29, 26, 8, 7, 1, 6, 13, 18, 3, 20, 17, 23),:]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py:745\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    741\u001b[0m prior_skip_guard_eval_unsafe \u001b[38;5;241m=\u001b[39m set_skip_guard_eval_unsafe(\n\u001b[1;32m    742\u001b[0m     _is_skip_guard_eval_unsafe_stance()\n\u001b[1;32m    743\u001b[0m )\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m     _maybe_set_eval_frame(prior)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py:1184\u001b[0m, in \u001b[0;36maot_module_simplified.<locals>.forward\u001b[0;34m(*runtime_args)\u001b[0m\n\u001b[1;32m   1182\u001b[0m full_args\u001b[38;5;241m.\u001b[39mextend(params_flat)\n\u001b[1;32m   1183\u001b[0m full_args\u001b[38;5;241m.\u001b[39mextend(runtime_args)\n\u001b[0;32m-> 1184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiled_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:323\u001b[0m, in \u001b[0;36m_create_runtime_wrapper.<locals>.runtime_wrapper\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m grad_enabled:\n\u001b[1;32m    322\u001b[0m         torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_set_grad_enabled(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 323\u001b[0m     all_outs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_func_at_runtime_with_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompiled_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_amp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_amp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteal_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m grad_enabled:\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/_functorch/_aot_autograd/utils.py:126\u001b[0m, in \u001b[0;36mcall_func_at_runtime_with_args\u001b[0;34m(f, args, steal_args, disable_amp)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_boxed_call\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 126\u001b[0m         out \u001b[38;5;241m=\u001b[39m normalize_as_list(\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;66;03m# TODO: Please remove soon\u001b[39;00m\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670\u001b[39;00m\n\u001b[1;32m    130\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    131\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour compiler for AOTAutograd is returning a function that doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt take boxed arguments. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    132\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease wrap it with functorch.compile.make_boxed_func or handle the boxed arguments yourself. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    133\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670 for rationale.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:672\u001b[0m, in \u001b[0;36mEffectTokensWrapper.post_compile.<locals>.inner_fn\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    669\u001b[0m     args \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m([\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m num_tokens), \u001b[38;5;241m*\u001b[39margs]\n\u001b[1;32m    670\u001b[0m     old_args\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m--> 672\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[43mcompiled_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;66;03m# Inductor cache DummyModule can return None\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:490\u001b[0m, in \u001b[0;36mFunctionalizedRngRuntimeWrapper.post_compile.<locals>.wrapper\u001b[0;34m(runtime_args)\u001b[0m\n\u001b[1;32m    483\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_functionalized_rng_runtime_epilogue(\n\u001b[1;32m    484\u001b[0m         runtime_metadata,\n\u001b[1;32m    485\u001b[0m         out,\n\u001b[1;32m    486\u001b[0m         \u001b[38;5;66;03m# TODO: this won't be right for the backward when we convert the call_compiled_backward to use the wrapper\u001b[39;00m\n\u001b[1;32m    487\u001b[0m         runtime_metadata\u001b[38;5;241m.\u001b[39mnum_forward_returns,\n\u001b[1;32m    488\u001b[0m     )\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m--> 490\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiled_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruntime_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/_dynamo/backends/debugging.py:115\u001b[0m, in \u001b[0;36mboxed_nop.<locals>.run\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(args):\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInterpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfx_g\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboxed_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/fx/interpreter.py:203\u001b[0m, in \u001b[0;36mInterpreter.boxed_run\u001b[0;34m(self, args_list)\u001b[0m\n\u001b[1;32m    201\u001b[0m         env[n] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(args_iter)\n\u001b[1;32m    202\u001b[0m args_list\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m--> 203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/fx/interpreter.py:180\u001b[0m, in \u001b[0;36mInterpreter.run\u001b[0;34m(self, initial_env, enable_io_processing, *args)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgarbage_collect_values:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m to_delete \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_to_last_uses\u001b[38;5;241m.\u001b[39mget(node, []):\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv[to_delete]\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node\u001b[38;5;241m.\u001b[39mop \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    183\u001b[0m     output_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv[node]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = compile(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile = torch.compile(PatternClass2(), backend=\"tensorrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30.812289714813232, 2.842436174313434)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = compile(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(PatternClass2(),\n",
    "                  t,\n",
    "        '/home/yssun/pytorch-fm/torchfm/model/test_fx/exp/model_repo/test/ori.onnx',\n",
    "                  input_names=['input'],\n",
    "                  output_names=['output'],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(PatternClass1(),\n",
    "                  t,\n",
    "        '/home/yssun/pytorch-fm/torchfm/model/test_fx/exp/model_repo/test/modify_noreorder.onnx',\n",
    "                  input_names=['input'],\n",
    "                  output_names=['output'],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(PatternClass(),\n",
    "                  t,\n",
    "        '/home/yssun/pytorch-fm/torchfm/model/test_fx/exp/model_repo/test/modify_reorder.onnx',\n",
    "                  input_names=['input'],\n",
    "                  output_names=['output'],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(PatternClass(),'/home/yssun/pytorch-fm/torchfm/model/test_fx/exp/model_repo/test/modify_reorder.pt',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [i for i  in range(100) if i != 1 and i != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [i for i in range(100)]\n",
    "l[0] = 1\n",
    "l[1] = 2\n",
    "l[2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self,x):\n",
    "      empty_like_tensor = torch.ones((4096,100,32))\n",
    "      result_x = x[0,(1,2),:] * x[0,(1,2),:]\n",
    "      empty_like_tensor[:,:2,:] = result_x\n",
    "      empty_like_tensor[:,2:,:] = x[0,2:,:] * x[0,2:,:]\n",
    "    #   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "      return torch.sum(empty_like_tensor, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile = torch.compile(TestClass())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.randint(low=0, high=88, size=(4096 ,100,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.3200984001159668, 0.1526529321097314)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = compile(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self,x):\n",
    "      empty_like_tensor = torch.ones((4096,100,32))\n",
    "      result_x = x[0,(1,2),:] * x[0,(1,2),:]\n",
    "      empty_like_tensor[:,:2,:] = result_x\n",
    "      empty_like_tensor[:,2:,:] = x[0,2:,:] * x[0,2:,:]\n",
    "    #   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "      return torch.sum(empty_like_tensor[:,l_100,:], dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_100 = [i for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile()\n",
    "def f_modify(x):\n",
    "  empty_like_tensor = torch.ones((4096,100,32))\n",
    "  result_x = x[0,(1,2),:] * x[0,(1,2),:]\n",
    "  empty_like_tensor[:,:2,:] = result_x\n",
    "  empty_like_tensor[:,2:,:] = x[0,2:,:] * x[0,2:,:]\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "  return torch.sum(empty_like_tensor, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_modify(torch.empty([4096,100,32]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.177678108215332, 0.11754041158837936)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "t = torch.empty([4096,100,32])\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = f_modify(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_100 = [i for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_100[0], l_100[3] = l_100[3], l_100[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile()\n",
    "def f_modify_cuda(x):\n",
    "  empty_like_tensor = torch.ones((4096,100,32),device='cuda')\n",
    "  result_x = x[0,(1,2),:] * x[0,(1,2),:]\n",
    "  empty_like_tensor[:,:2,:] = result_x\n",
    "  empty_like_tensor[:,2:,:] = x[0,2:,:] * x[0,2:,:]\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "  return torch.sum(empty_like_tensor[:,l_100,:], dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.14787912368774414, 0.17312163137717107)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "t = torch.empty([4096,100,32],device='cuda')\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = f_modify_cuda(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.1826000213623047, 0.270089240393645)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "t = torch.empty([4096,100,32],device='cuda')\n",
    "with profile(activities=[torch.profiler.ProfilerActivity.CUDA,ProfilerActivity.CPU], record_shapes=True,\n",
    "        profile_memory=True,  # 记录内存使用情况\n",
    "    with_stack=True,  # 记录代码堆栈信息\n",
    "    with_flops=True,  # 记录FLOPs\n",
    "    on_trace_ready=torch.profiler.tensorboard_trace_handler('./log_single') ) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = f_modify_cuda(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile\n",
    "def f(x):\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "  return torch.sum(x * x, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(torch.empty([4096,100,32],device = \"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.12805700302124023, 0.019240927593955348)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "t = torch.empty([4096,100,32],device=\"cuda\")\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = f(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.37773847579956055, 0.028915579122212876)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "t = torch.empty([4096,100,32],device=\"cpu\")\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = f(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正式测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基准"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile\n",
    "def f(x):\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "  return torch.sum(x * x, dim = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(torch.empty([4096,100,32],device = \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.24803638458251953, 0.24365854894767836)\n"
     ]
    }
   ],
   "source": [
    "f(torch.empty([4096,100,32],device = \"cpu\"))\n",
    "l_time = []\n",
    "t = torch.empty([4096,100,32],device=\"cpu\")\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = f(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(torch.empty([4096,5050,32],device = \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.986135482788086, 190.77499564914433)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "t = torch.empty([4096,5050,32],device=\"cpu\")\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = f(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(torch.empty([4096,100,32],device = \"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.1461338996887207, 0.016801451755554808)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "t = torch.empty([4096,100,32],device=\"cuda\")\n",
    "for i in range(100):\n",
    "    start_time = time.time()  # 开始计时\n",
    "    with torch.no_grad():\n",
    "      soutput = f(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time.append(elapsed_time * 1000)\n",
    "print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(torch.empty([4096,100,64],device = \"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.16957759857177734, 0.10733138153682376)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "t = torch.empty([4096,100,64],device=\"cuda\")\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = f(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(torch.empty([4096,1000,64],device = \"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.17182350158691406, 0.1147689020854159)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "t = torch.empty([4096,1000,64],device=\"cuda\")\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = f(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 4.93 GiB. GPU 0 has a total capacity of 47.53 GiB of which 175.88 MiB is free. Process 3708359 has 1.50 GiB memory in use. Process 3709323 has 45.28 GiB memory in use. Including non-PyTorch memory, this process has 576.00 MiB memory in use. Of the allocated memory 52.50 MiB is allocated by PyTorch, and 207.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m f(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5050\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 4.93 GiB. GPU 0 has a total capacity of 47.53 GiB of which 175.88 MiB is free. Process 3708359 has 1.50 GiB memory in use. Process 3709323 has 45.28 GiB memory in use. Including non-PyTorch memory, this process has 576.00 MiB memory in use. Of the allocated memory 52.50 MiB is allocated by PyTorch, and 207.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "f(torch.empty([4096,5050,64],device = \"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.20398855209350586, 0.034293661991569024)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "t = torch.empty([4096,5050,64],device=\"cuda\")\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = f(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 修改-不加reorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile()\n",
    "def f_modify_without_reorder(x):\n",
    "  empty_like_tensor = torch.ones((4096,100,32))\n",
    "  result_x = x[0,:50,:] * x[0,:50,:]\n",
    "  empty_like_tensor[:,:50,:] = result_x\n",
    "  empty_like_tensor[:,50:,:] = x[0,50:,:] * x[0,50:,:]\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "  return torch.sum(empty_like_tensor, dim = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_modify_without_reorder(torch.empty([4096,100,32],device = \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2469944953918457, 0.0381317698327166)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "t = torch.empty([4096,100,32],device=\"cpu\")\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = f_modify_without_reorder(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile()\n",
    "def f_modify_without_reorder(x):\n",
    "  empty_like_tensor = torch.ones((4096,5050,32),device=\"cpu\")\n",
    "  result_x = x[0,:1000,:] * x[0,:1000,:]\n",
    "  empty_like_tensor[:,:1000,:] = result_x\n",
    "  empty_like_tensor[:,1000:,:] = x[0,1000:,:] * x[0,1000:,:]\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "  return torch.sum(empty_like_tensor, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_modify_without_reorder(torch.empty([4096,5050,32],device = \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.904205322265625, 0.5978259051516943)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "t = torch.empty([4096,5050,32],device=\"cpu\")\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = f_modify_without_reorder(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile()\n",
    "def f_modify_without_reorder(x):\n",
    "  empty_like_tensor = torch.ones((4096,5050,32))\n",
    "  result_x = x[0,:10,:] * x[0,:10,:]\n",
    "  empty_like_tensor[:,:10,:] = result_x\n",
    "  empty_like_tensor[:,10:,:] = x[0,10:,:] * x[0,10:,:]\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "  return torch.sum(empty_like_tensor, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_modify_without_reorder(torch.empty([4096,5050,32],device = \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.8104615211486816, 0.9702228104004007)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "t = torch.empty([4096,5050,32],device=\"cpu\")\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = f_modify_without_reorder(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile()\n",
    "def f_modify_without_reorder(x):\n",
    "  empty_like_tensor = torch.ones((4096,5050,32))\n",
    "  result_x = x[0,:20,:] * x[0,:20,:]\n",
    "  empty_like_tensor[:,:20,:] = result_x\n",
    "  empty_like_tensor[:,20:,:] = x[0,20:,:] * x[0,20:,:]\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "  return torch.sum(empty_like_tensor, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_modify_without_reorder(torch.empty([4096,5050,32],device = \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.7547073364257812, 0.6252128408505087)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "t = torch.empty([4096,5050,32],device=\"cpu\")\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = f_modify_without_reorder(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile()\n",
    "def f_modify_without_reorder(x):\n",
    "  empty_like_tensor = torch.ones((4096,5050,32))\n",
    "  result_x = x[0,:50,:] * x[0,:50,:]\n",
    "  empty_like_tensor[:,:50,:] = result_x\n",
    "  empty_like_tensor[:,50:,:] = x[0,50:,:] * x[0,50:,:]\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "  return torch.sum(empty_like_tensor, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_modify_without_reorder(torch.empty([4096,5050,32],device = \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.8177928924560547, 0.5390379372784082)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "t = torch.empty([4096,5050,32],device=\"cpu\")\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = f_modify_without_reorder(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile()\n",
    "def f_modify_without_reorder(x):\n",
    "  empty_like_tensor = torch.ones((4096,100,32),device = \"cuda\")\n",
    "  result_x = x[0,:50,:] * x[0,:50,:]\n",
    "  empty_like_tensor[:,:50,:] = result_x\n",
    "  empty_like_tensor[:,50:,:] = x[0,50:,:] * x[0,50:,:]\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "  return torch.sum(empty_like_tensor, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_modify_without_reorder(torch.empty([4096,100,32],device = \"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.1113271713256836, 0.005528314454750216)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "t = torch.empty([4096,100,32],device=\"cuda\")\n",
    "for i in range(100):\n",
    "    start_time = time.time()  # 开始计时\n",
    "    soutput = f_modify_without_reorder(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time.append(elapsed_time * 1000)\n",
    "print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile()\n",
    "def f_modify_without_reorder64(x):\n",
    "  empty_like_tensor = torch.ones((4096,100,64),device='cuda')\n",
    "  result_x = x[0,:2,:] * x[0,:2,:]\n",
    "  empty_like_tensor[:,:2,:] = result_x\n",
    "  empty_like_tensor[:,2:,:] = x[0,2:,:] * x[0,2:,:]\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "  return torch.sum(empty_like_tensor, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_modify_without_reorder64(torch.empty([4096,100,64],device = \"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.13831615447998047, 0.11335041679103597)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "t = torch.empty([4096,100,64],device=\"cuda\")\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = f_modify_without_reorder64(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile()\n",
    "def f_modify_without_reorder64(x):\n",
    "  empty_like_tensor = torch.ones((4096,1000,64),device='cuda')\n",
    "  result_x = x[0,:2,:] * x[0,:2,:]\n",
    "  empty_like_tensor[:,:2,:] = result_x\n",
    "  empty_like_tensor[:,2:,:] = x[0,2:,:] * x[0,2:,:]\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "  return torch.sum(empty_like_tensor, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.13556241989135742, 0.03458348725757787)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "t = torch.empty([4096,1000,64],device=\"cuda\")\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = f_modify_without_reorder64(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile()\n",
    "def f_modify_without_reorder64(x):\n",
    "  empty_like_tensor = torch.ones((4096,5050,64),device='cuda')\n",
    "  result_x = x[0,:2,:] * x[0,:2,:]\n",
    "  empty_like_tensor[:,:2,:] = result_x\n",
    "  empty_like_tensor[:,2:,:] = x[0,2:,:] * x[0,2:,:]\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "  return torch.sum(empty_like_tensor, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.14065027236938477, 0.02305010781924466)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "t = torch.empty([4096,5050,64],device=\"cuda\")\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = f_modify_without_reorder64(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile()\n",
    "def f_modify_without_reorder64(x):\n",
    "  empty_like_tensor = torch.ones((4096,5050,64),device='cuda')\n",
    "  result_x = x[0,:100,:] * x[0,:100,:]\n",
    "  empty_like_tensor[:,:100,:] = result_x\n",
    "  empty_like_tensor[:,100:,:] = x[0,100:,:] * x[0,100:,:]\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "  return torch.sum(empty_like_tensor, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.14458179473876953, 0.1812166433182938)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "t = torch.empty([4096,5050,64],device=\"cuda\")\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = f_modify_without_reorder64(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 修改加Reorder，但不是乱序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [i for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile()\n",
    "def f_modify_with_reorder_inorder(x):\n",
    "  empty_like_tensor = torch.ones((4096,100,32))\n",
    "  result_x = x[0,:2,:] * x[0,:2,:]\n",
    "  empty_like_tensor[:,:2,:] = result_x\n",
    "  empty_like_tensor[:,2:,:] = x[0,2:,:] * x[0,2:,:]\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "  return torch.sum(empty_like_tensor[:,l], dim = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 990000.,  990000.,  990000.,  ..., 1000000., 1000000., 1000000.],\n",
       "        [ 990000.,  990000.,  990000.,  ..., 1000000., 1000000., 1000000.],\n",
       "        [ 990000.,  990000.,  990000.,  ..., 1000000., 1000000., 1000000.],\n",
       "        ...,\n",
       "        [ 990000.,  990000.,  990000.,  ..., 1000000., 1000000., 1000000.],\n",
       "        [ 990000.,  990000.,  990000.,  ..., 1000000., 1000000., 1000000.],\n",
       "        [ 990000.,  990000.,  990000.,  ..., 1000000., 1000000., 1000000.]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_modify_with_reorder_inorder(torch.empty([4096,100,32],device = \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.7858591079711914, 263.0580623583901)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "t = torch.empty([4096,100,32],device=\"cpu\")\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = f_modify_with_reorder_inorder(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile()\n",
    "def f_modify_with_reorder_inorder(x):\n",
    "  empty_like_tensor = torch.ones((4096,100,32),device='cuda')\n",
    "  result_x = x[0,:2,:] * x[0,:2,:]\n",
    "  empty_like_tensor[:,:2,:] = result_x\n",
    "  empty_like_tensor[:,2:,:] = x[0,2:,:] * x[0,2:,:]\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "  return torch.sum(empty_like_tensor[:,l], dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[100., 100., 100.,  ..., 100., 100., 100.],\n",
       "        [100., 100., 100.,  ..., 100., 100., 100.],\n",
       "        [100., 100., 100.,  ..., 100., 100., 100.],\n",
       "        ...,\n",
       "        [100., 100., 100.,  ..., 100., 100., 100.],\n",
       "        [100., 100., 100.,  ..., 100., 100., 100.],\n",
       "        [100., 100., 100.,  ..., 100., 100., 100.]], device='cuda:0')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_modify_with_reorder_inorder(torch.empty([4096,100,32],device = \"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.11902570724487305, 0.00773259768607204)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "t = torch.empty([4096,100,32],device=\"cuda\")\n",
    "for i in range(100):\n",
    "    start_time = time.time()  # 开始计时\n",
    "    soutput = f_modify_with_reorder_inorder(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time.append(elapsed_time * 1000)\n",
    "print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_5050 = [i for i in range(5050)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile()\n",
    "def f_modify_with_reorder_inorder64_5050(x):\n",
    "  empty_like_tensor = torch.ones((4096,5050,32),device='cuda')\n",
    "  result_x = x[0,:2,:] * x[0,:2,:]\n",
    "  empty_like_tensor[:,:2,:] = result_x\n",
    "  empty_like_tensor[:,2:,:] = x[0,2:,:] * x[0,2:,:]\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "  return torch.sum(empty_like_tensor[:,l], dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_modify_with_reorder_inorder64_5050(torch.empty([4096,5050,32],device = \"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.14266490936279297, 0.03244515457936359)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "t = torch.empty([4096,5050,32],device=\"cuda\")\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = f_modify_with_reorder_inorder64_5050(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 修改加Reorder，是乱序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "l_shuffle = [i for i in range(100)]\n",
    "random.shuffle(l_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile()\n",
    "def f_modify_with_reorder_shuffle(x):\n",
    "  empty_like_tensor = torch.ones((4096,100,32))\n",
    "  result_x = x[0,:2,:] * x[0,:2,:]\n",
    "  empty_like_tensor[:,:2,:] = result_x\n",
    "  empty_like_tensor[:,2:,:] = x[0,2:,:] * x[0,2:,:]\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "  return torch.sum(empty_like_tensor[:,l_shuffle], dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.2096595764160156, 0.1504357293015346)\n"
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "t = torch.empty([4096,100,32],device=\"cpu\")\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = f_modify_with_reorder_shuffle(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile()\n",
    "def f_modify_with_reorder_shuffle64_5050(x):\n",
    "  empty_like_tensor = torch.ones((4096,5050,64),device='cuda')\n",
    "  result_x = x[0,:2,:] * x[0,:2,:]\n",
    "  empty_like_tensor[:,:2,:] = result_x\n",
    "  empty_like_tensor[:,2:,:] = x[0,2:,:] * x[0,2:,:]\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "  return torch.sum(empty_like_tensor[:,l_shuffle], dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.1744842529296875, 0.4745138627640699)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "total_time = []\n",
    "t = torch.empty([4096,5050,64],device=\"cuda\")\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = f_modify_with_reorder_shuffle64_5050(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile\n",
    "def f(x):\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "  return torch.sum(x * x, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9696149826049805, 0.05414658860445343)\n"
     ]
    }
   ],
   "source": [
    "f(torch.empty([4096,100,64],device = \"cpu\"))\n",
    "total_time = []\n",
    "t = torch.ones([4096,100,64],device=\"cpu\")\n",
    "for i in range(100):\n",
    "    start_time = time.time()  # 开始计时\n",
    "    with torch.no_grad():\n",
    "      soutput = f(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time.append(elapsed_time * 1000)\n",
    "print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile()\n",
    "def f_modify_without_reorder(x):\n",
    "  x = x * x\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "  return torch.sum(x[0,:50],dim = 0)+torch.sum(x[:,50:],dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.3399801254272461, 0.12991782793960738)\n"
     ]
    }
   ],
   "source": [
    "f_modify_without_reorder(torch.empty([4096,100,32],device = \"cpu\"))\n",
    "total_time = []\n",
    "t = torch.ones([4096,100,64],device=\"cpu\")\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = f_modify_without_reorder(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile()\n",
    "def f_modify_without_reorder(x):\n",
    "  x_r = x[0,:50] * x[0,:50]\n",
    "  x_n = x[:,50:] * x[:,50:]\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "  return torch.sum(x_r,dim = 0)+torch.sum(x_n,dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6042313575744629, 0.20809929998790722)\n"
     ]
    }
   ],
   "source": [
    "f_modify_without_reorder(torch.empty([4096,100,32],device = \"cpu\"))\n",
    "total_time = []\n",
    "t = torch.ones([4096,100,64],device=\"cpu\")\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "      for i in range(100):\n",
    "          start_time = time.time()  # 开始计时\n",
    "          with torch.no_grad():\n",
    "            soutput = f_modify_without_reorder(t)\n",
    "          end_time = time.time()  # 结束计时\n",
    "          \n",
    "          # 计算并打印函数执行所需的时间\n",
    "          elapsed_time = end_time - start_time\n",
    "          total_time.append(elapsed_time * 1000)\n",
    "      print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile\n",
    "def f(x):\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "  return torch.sum(x * x, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.13529062271118164, 0.003427034442893273)\n"
     ]
    }
   ],
   "source": [
    "f(torch.empty([4096,1000,64],device = \"cuda\"))\n",
    "total_time = []\n",
    "t = torch.ones([4096,1000,64],device=\"cuda\")\n",
    "for i in range(100):\n",
    "    start_time = time.time()  # 开始计时\n",
    "    with torch.no_grad():\n",
    "      soutput = f(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time.append(elapsed_time * 1000)\n",
    "print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile()\n",
    "def f_modify_without_reorder(x):\n",
    "  x = x * x\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "  return torch.sum(x[0,:500],dim = 0)+torch.sum(x[:,500:],dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.12399911880493164, 0.0004035849713091011)\n"
     ]
    }
   ],
   "source": [
    "f_modify_without_reorder(torch.empty([4096,1000,64],device = \"cuda\"))\n",
    "total_time = []\n",
    "t = torch.ones([4096,1000,64],device=\"cuda\")\n",
    "for i in range(100):\n",
    "    start_time = time.time()  # 开始计时\n",
    "    with torch.no_grad():\n",
    "      soutput = f_modify_without_reorder(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time.append(elapsed_time * 1000)\n",
    "print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile()\n",
    "def f_modify_without_reorder(x):\n",
    "  x_r = x[0,:500] * x[0,:500]\n",
    "  x_n = x[:,500:] * x[:,500:]\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "  return torch.sum(x_r,dim = 0)+torch.sum(x_n,dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.12708425521850586, 0.002094229165550132)\n"
     ]
    }
   ],
   "source": [
    "f_modify_without_reorder(torch.empty([4096,1000,64],device = \"cuda\"))\n",
    "total_time = []\n",
    "t = torch.ones([4096,1000,64],device=\"cuda\")\n",
    "for i in range(100):\n",
    "    start_time = time.time()  # 开始计时\n",
    "    with torch.no_grad():\n",
    "      soutput = f_modify_without_reorder(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time.append(elapsed_time * 1000)\n",
    "print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile()\n",
    "def f_modify_without_reorder(x):\n",
    "    empty_x = torch.empty([4096,1000,64],device=\"cuda\")\n",
    "    empty_x[:,:500] = x[0,:500] * x[0,:500]\n",
    "    empty_x[:,500:] = x[:,500:] * x[:,500:]\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "    return torch.sum(empty_x,dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.09167671203613281, 0.0018779593119688798)\n"
     ]
    }
   ],
   "source": [
    "f_modify_without_reorder(torch.empty([4096,1000,64],device = \"cuda\"))\n",
    "total_time = []\n",
    "t = torch.ones([4096,1000,64],device=\"cuda\")\n",
    "for i in range(100):\n",
    "    start_time = time.time()  # 开始计时\n",
    "    with torch.no_grad():\n",
    "      soutput = f_modify_without_reorder(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time.append(elapsed_time * 1000)\n",
    "print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile()\n",
    "def f_modify_without_reorder(x):\n",
    "    empty_x = torch.empty([4096,1000,64],device=\"cuda\")\n",
    "    empty_x[:,:200] = x[0,:200] * x[0,:200]\n",
    "    empty_x[:,200:] = x[:,200:] * x[:,200:]\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "    return torch.sum(empty_x,dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0942540168762207, 0.001045875768568294)\n"
     ]
    }
   ],
   "source": [
    "f_modify_without_reorder(torch.empty([4096,1000,64],device = \"cuda\"))\n",
    "total_time = []\n",
    "t = torch.ones([4096,1000,64],device=\"cuda\")\n",
    "for i in range(100):\n",
    "    start_time = time.time()  # 开始计时\n",
    "    with torch.no_grad():\n",
    "      soutput = f_modify_without_reorder(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time.append(elapsed_time * 1000)\n",
    "print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目前：\n",
    "1.Element wise算子使用新的改写方法 GPU上有效\n",
    "2.reduce类在CPU GPU上有"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile\n",
    "def f(x):\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "  return torch.sum(x * x, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.1303386688232422, 0.003033825214515673)\n"
     ]
    }
   ],
   "source": [
    "f(torch.empty([4096,100,64],device = \"cuda\"))\n",
    "total_time = []\n",
    "t = torch.ones([4096,100,64],device=\"cuda\")\n",
    "for i in range(100):\n",
    "    start_time = time.time()  # 开始计时\n",
    "    with torch.no_grad():\n",
    "      soutput = f(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time.append(elapsed_time * 1000)\n",
    "print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile()\n",
    "def f_modify_without_reorder(x):\n",
    "  x_r = x[0,:50] * x[0,:50]\n",
    "  x_n = x[:,50:] * x[:,50:]\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "  return torch.sum(x_r,dim = 0)+torch.sum(x_n,dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.15122652053833008, 0.0020803682843961724)\n"
     ]
    }
   ],
   "source": [
    "f_modify_without_reorder(torch.empty([4096,100,64],device = \"cuda\"))\n",
    "total_time = []\n",
    "t = torch.ones([4096,1000,64],device=\"cuda\")\n",
    "for i in range(100):\n",
    "    start_time = time.time()  # 开始计时\n",
    "    with torch.no_grad():\n",
    "      soutput = f_modify_without_reorder(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time.append(elapsed_time * 1000)\n",
    "print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile()\n",
    "def f_modify_without_reorder(x):\n",
    "    empty_x = torch.empty([4096,100,64],device=\"cuda\")\n",
    "    empty_x[:,:50] = x[0,:50] * x[0,:50]\n",
    "    empty_x[:,50:] = x[:,50:] * x[:,50:]\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "    return torch.sum(empty_x,dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.12250185012817383, 0.0013924496840900247)\n"
     ]
    }
   ],
   "source": [
    "f_modify_without_reorder(torch.empty([4096,100,64],device = \"cuda\"))\n",
    "total_time = []\n",
    "t = torch.ones([4096,100,64],device=\"cuda\")\n",
    "for i in range(100):\n",
    "    start_time = time.time()  # 开始计时\n",
    "    with torch.no_grad():\n",
    "      soutput = f_modify_without_reorder(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time.append(elapsed_time * 1000)\n",
    "print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile\n",
    "def f(x):\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "  return torch.sum(x ** 2, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.10809183120727539, 0.0026601431443395995)\n"
     ]
    }
   ],
   "source": [
    "f(torch.empty([4096,1009,64],device = \"cuda\"))\n",
    "total_time = []\n",
    "t = torch.ones([4096,1000,64],device=\"cuda\")\n",
    "for i in range(100):\n",
    "    start_time = time.time()  # 开始计时\n",
    "    with torch.no_grad():\n",
    "      soutput = f(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time.append(elapsed_time * 1000)\n",
    "print(calculate_mean_and_variance_manual(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile()\n",
    "def f_modify_without_reorder(x):\n",
    "    empty_x = torch.empty([4096,1000,64],device=\"cuda\")\n",
    "    empty_x[:,:500] = x[0,:500] **2\n",
    "    empty_x[:,500:] = x[:,500:] **2\n",
    "#   reorder_x =  empty_like_tensor[:,l_100,:]\n",
    "    return torch.sum(empty_x,dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.09702444076538086, 0.003024003234486372)\n"
     ]
    }
   ],
   "source": [
    "f_modify_without_reorder(torch.empty([4096,1000,64],device = \"cuda\"))\n",
    "total_time = []\n",
    "t = torch.ones([4096,1000,64],device=\"cuda\")\n",
    "for i in range(100):\n",
    "    start_time = time.time()  # 开始计时\n",
    "    with torch.no_grad():\n",
    "      soutput = f_modify_without_reorder(t)\n",
    "    end_time = time.time()  # 结束计时\n",
    "    \n",
    "    # 计算并打印函数执行所需的时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time.append(elapsed_time * 1000)\n",
    "print(calculate_mean_and_variance_manual(total_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorrt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
