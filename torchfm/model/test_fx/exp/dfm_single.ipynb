{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../')\n",
    "import time\n",
    "import dfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.fx import subgraph_rewriter, symbolic_trace\n",
    "import utils\n",
    "from torch.fx import Proxy, Graph, GraphModule\n",
    "from torch.fx.passes.utils.matcher_utils import SubgraphMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import time\n",
    "import torch._dynamo as dynamo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pattern_replace_and_matcher_for_SingleMLP(traced,\n",
    "                                                  redency_part_slice,unredency_part_slice,\n",
    "                                                  key_node_name,match_func = None\n",
    "                                                ):\n",
    "  from torch.fx.passes.utils.matcher_utils import SubgraphMatcher\n",
    "\n",
    "\n",
    "  def _match(match,ori,pat):\n",
    "    return True \n",
    "  env  = utils.get_env(traced)\n",
    "  target_node = env[key_node_name]\n",
    "  target_node_mod = utils.get_target_mod(traced,target_node.target)\n",
    "  shape_info = target_node_mod.weight.data.shape\n",
    "  class PatternClass(torch.nn.Module):\n",
    "      def __init__(self):\n",
    "          super().__init__()\n",
    "          self.embed = torch.nn.Embedding(1, 1)\n",
    "          self.embed_output_dim = shape_info[1]\n",
    "          self.mlp = nn.Linear(shape_info[0],shape_info[1])\n",
    "\n",
    "\n",
    "      def forward(self,x):\n",
    "          x = self.embed(x)\n",
    "          square_of_sum = torch.sum(x, dim=1) ** 2\n",
    "          sum_of_square = torch.sum(x ** 2, dim=1)\n",
    "          ix = square_of_sum - sum_of_square    \n",
    "          ix = torch.sum(ix, dim=1, keepdim=True)  \n",
    "          return self.mlp(x.view(-1,self.embed_output_dim)), 0.5 * ix\n",
    "  pattern = PatternClass()  \n",
    "  pattern_trace = symbolic_trace(pattern)\n",
    "  pattern_graph = pattern_trace.graph\n",
    "  original_graph = traced.graph\n",
    "  matcher =  SubgraphMatcher(pattern_graph, match_output=False, match_placeholder=False,\n",
    "                              remove_overlapping_matches=True)\n",
    "  _matches = matcher.match(original_graph)\n",
    "  match_filters = [_match if match_func is None else match_func]\n",
    "  _matches = [\n",
    "      m for m in _matches\n",
    "      if all(match_filter(m, original_graph, pattern_graph)\n",
    "              for match_filter in match_filters)\n",
    "  ]  \n",
    "  # 因为在过滤器中做了限制应该只有一个符合要求的\n",
    "  _matched = _matches[0]\n",
    "  pattern_env = utils.get_env(pattern_trace)\n",
    "  node_map = _matched.nodes_map\n",
    "  \n",
    "  embed_node = node_map[pattern_env['embed']]\n",
    "  embed_node_module = utils.get_target_mod(traced,embed_node.target)\n",
    "  \n",
    "  linear_node = node_map[pattern_env['mlp']]\n",
    "  linear_node_module = utils.get_target_mod(traced,linear_node.target)\n",
    "  linear_node_weight = linear_node_module.weight.data\n",
    "  linear_node_bias = linear_node_module.bias.data\n",
    "  \n",
    "  class ReplacementClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.embed = embed_node_module\n",
    "      self.embed_dim = self.embed.weight.data.shape[1]\n",
    "      self.redency_weight_len = self.embed_dim * redency_part_slice[1].stop\n",
    "      redency_weight = linear_node_weight[:,:self.redency_weight_len]\n",
    "      unredency_weight = linear_node_weight[:,self.redency_weight_len:]\n",
    "      self.unredency_weight_len = unredency_weight.shape[1]\n",
    "      self.redency_linear = nn.Linear(redency_weight.shape[1],redency_weight.shape[0])\n",
    "      self.redency_linear.weight.data.copy_(redency_weight)\n",
    "      self.redency_linear.bias.data.copy_(linear_node_bias)\n",
    "\n",
    "      self.unredency_linear = nn.Linear(unredency_weight.shape[1],unredency_weight.shape[0],bias=False)\n",
    "      self.unredency_linear.weight.data.copy_(unredency_weight)\n",
    "\n",
    "      \n",
    "\n",
    "    def forward(self,x):\n",
    "      emb = self.embed(x)\n",
    "      square_of_sum = torch.sum(emb, dim=1) ** 2\n",
    "      sum_of_square = torch.sum(emb ** 2, dim=1)\n",
    "      ix = square_of_sum - sum_of_square    \n",
    "      ix = torch.sum(ix, dim=1, keepdim=True)  \n",
    "      redency_part = emb[redency_part_slice] \n",
    "      unredency_part = emb[unredency_part_slice] \n",
    "      return self.redency_linear(redency_part.view(-1,self.redency_weight_len)) + self.unredency_linear(unredency_part.view(-1,self.unredency_weight_len)), 0.5 * ix\n",
    "      # return unredency_sum\n",
    "    \n",
    "  \n",
    "  return pattern,ReplacementClass(),_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def workload_dfm(num_field, prefix,dim = 64,l = [1024,512,256]):\n",
    "  print(f\"now gen workload of DFM with config: dim: {dim}, num_field: {num_field}, prefix: {prefix}\")\n",
    "  DFM_model_ori = dfm.DeepFactorizationMachineModel([100 for i in range(num_field)],dim,l,0.1)\n",
    "  ori_traced = symbolic_trace(DFM_model_ori)\n",
    "  \n",
    "  DFM_model_modify = dfm.DeepFactorizationMachineModel([100 for i in range(num_field)],dim,l,0.1)\n",
    "  modify_traced = symbolic_trace(DFM_model_modify)\n",
    "  pattern,replace,match = gen_pattern_replace_and_matcher_for_SingleMLP(modify_traced,\n",
    "                                                                      (0,slice(None,prefix,None)),(slice(None,None,None),slice(prefix,None,None)),\n",
    "                                                                      \"mlp_mlp_0\")\n",
    "  matches = subgraph_rewriter.replace_pattern_with_filters(modify_traced, pattern, replace,[match])\n",
    "  return ori_traced,modify_traced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims= [32]\n",
    "batches = [1024,2048,4096]\n",
    "num_field_and_prefixs = [(34 * 5,29*5),(22 * 5,10 * 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genWorkload(num_field = 34 * 5,prefix = 29 * 5, batch = 4096, dim = 64):\n",
    "  ori_model_name = f'/home/yssun/pytorch-fm/torchfm/model/test_fx/exp/model_repo/dfm_linear/DFM_{batch}_{num_field}_{prefix}_{dim}_ori.onnx'\n",
    "  modify_model_name = f'/home/yssun/pytorch-fm/torchfm/model/test_fx/exp/model_repo/dfm_linear/DFM_{batch}_{num_field}_{prefix}_{dim}_modify.onnx'\n",
    "  ori, modify = workload_dfm(num_field = num_field,prefix = prefix,  dim = dim)\n",
    "  # torch.onnx.export(ori,               # 模型 being run\n",
    "  #                 torch.randint(low=0, high=20, size=(batch,num_field), dtype=torch.long),                  # 模型输入 (or a tuple for multiple inputs)\n",
    "  #                 ori_model_name,        # 导出文件的文件名\n",
    "  #                 export_params=True, # 如果设置为True，则参数也会被导出。注意某些情况下参数可能无法被导出。\n",
    "  #                 opset_version=10,   # ONNX版本\n",
    "  #                 do_constant_folding=True,  # 是否执行常量折叠以优化模型\n",
    "  #                 input_names = ['input'],   # 输入的名称\n",
    "  #                 output_names = ['output'], # 输出的名称\n",
    "  #                 )\n",
    "  torch.onnx.export(modify,               # 模型 being run\n",
    "                  torch.randint(low=0, high=20, size=(batch,num_field), dtype=torch.long),                  # 模型输入 (or a tuple for multiple inputs)\n",
    "                  modify_model_name,        # 导出文件的文件名\n",
    "                  export_params=True, # 如果设置为True，则参数也会被导出。注意某些情况下参数可能无法被导出。\n",
    "                  opset_version=10,   # ONNX版本\n",
    "                  do_constant_folding=True,  # 是否执行常量折叠以优化模型\n",
    "                  input_names = ['input'],   # 输入的名称\n",
    "                  output_names = ['output'], # 输出的名称\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of DFM with config: dim: 32, num_field: 170, prefix: 145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of DFM with config: dim: 32, num_field: 110, prefix: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of DFM with config: dim: 32, num_field: 170, prefix: 145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of DFM with config: dim: 32, num_field: 110, prefix: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of DFM with config: dim: 32, num_field: 170, prefix: 145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of DFM with config: dim: 32, num_field: 110, prefix: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for dim in dims:\n",
    "  for batch in batches:\n",
    "    for num_field,prefix in num_field_and_prefixs:\n",
    "      genWorkload(num_field=num_field,prefix=prefix,batch=batch,dim=dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorrt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
