{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../')\n",
    "import time\n",
    "import wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace success!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.fx import subgraph_rewriter, symbolic_trace\n",
    "import utils\n",
    "from torch.fx import Proxy, Graph, GraphModule\n",
    "from torch.fx.passes.utils.matcher_utils import SubgraphMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import time\n",
    "import torch._dynamo as dynamo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pattern_replace_and_matcher_for_SingleMLP(traced,\n",
    "                                                  redency_part_slice,unredency_part_slice,\n",
    "                                                  key_node_name,match_func = None\n",
    "                                                ):\n",
    "  from torch.fx.passes.utils.matcher_utils import SubgraphMatcher\n",
    "\n",
    "\n",
    "  def _match(match,ori,pat):\n",
    "    return True \n",
    "  env  = utils.get_env(traced)\n",
    "  target_node = env[key_node_name]\n",
    "  target_node_mod = utils.get_target_mod(traced,target_node.target)\n",
    "  shape_info = target_node_mod.weight.data.shape\n",
    "  class PatternClass(torch.nn.Module):\n",
    "      def __init__(self):\n",
    "          super().__init__()\n",
    "          self.embed = torch.nn.Embedding(1, 1)\n",
    "          self.embed_output_dim = shape_info[1]\n",
    "          self.mlp = nn.Linear(shape_info[0],shape_info[1])\n",
    "\n",
    "\n",
    "      def forward(self,x):\n",
    "          x = self.embed(x).view(-1,self.embed_output_dim)\n",
    "          return self.mlp(x)\n",
    "  pattern = PatternClass()  \n",
    "  pattern_trace = symbolic_trace(pattern)\n",
    "  pattern_graph = pattern_trace.graph\n",
    "  original_graph = traced.graph\n",
    "  matcher =  SubgraphMatcher(pattern_graph, match_output=False, match_placeholder=False,\n",
    "                              remove_overlapping_matches=True)\n",
    "  _matches = matcher.match(original_graph)\n",
    "  match_filters = [_match if match_func is None else match_func]\n",
    "  _matches = [\n",
    "      m for m in _matches\n",
    "      if all(match_filter(m, original_graph, pattern_graph)\n",
    "              for match_filter in match_filters)\n",
    "  ]  \n",
    "  # 因为在过滤器中做了限制应该只有一个符合要求的\n",
    "  _matched = _matches[0]\n",
    "  pattern_env = utils.get_env(pattern_trace)\n",
    "  node_map = _matched.nodes_map\n",
    "  \n",
    "  embed_node = node_map[pattern_env['embed']]\n",
    "  embed_node_module = utils.get_target_mod(traced,embed_node.target)\n",
    "  \n",
    "  linear_node = node_map[pattern_env['mlp']]\n",
    "  linear_node_module = utils.get_target_mod(traced,linear_node.target)\n",
    "  linear_node_weight = linear_node_module.weight.data\n",
    "  linear_node_bias = linear_node_module.bias.data\n",
    "  \n",
    "  class ReplacementClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.embed = embed_node_module\n",
    "      self.embed_dim = self.embed.weight.data.shape[1]\n",
    "      self.redency_weight_len = self.embed_dim * redency_part_slice[1].stop\n",
    "      redency_weight = linear_node_weight[:,:self.redency_weight_len]\n",
    "      unredency_weight = linear_node_weight[:,self.redency_weight_len:]\n",
    "      self.unredency_weight_len = unredency_weight.shape[1]\n",
    "      self.redency_linear = nn.Linear(redency_weight.shape[1],redency_weight.shape[0])\n",
    "      self.redency_linear.weight.data.copy_(redency_weight)\n",
    "      self.redency_linear.bias.data.copy_(linear_node_bias)\n",
    "      self.redency_weight = torch.nn.Parameter(redency_weight.T,False)\n",
    "      self.redency_bias = torch.nn.Parameter(linear_node_bias,False)\n",
    "      self.unredency_linear = nn.Linear(unredency_weight.shape[1],unredency_weight.shape[0],bias=False)\n",
    "      self.unredency_linear.weight.data.copy_(unredency_weight)\n",
    "\n",
    "      \n",
    "\n",
    "    def forward(self,x):\n",
    "      emb = self.embed(x)\n",
    "      redency_part = emb[redency_part_slice] \n",
    "      unredency_part = emb[unredency_part_slice] \n",
    "      return  (torch.mm(redency_part.view(-1,self.redency_weight_len),self.redency_weight) + self.redency_bias) + self.unredency_linear(unredency_part.view(-1,self.unredency_weight_len))\n",
    "      # return unredency_sum\n",
    "    \n",
    "  \n",
    "  return pattern,ReplacementClass(),_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def workload_wdl(num_field, prefix,dim = 64,l = [1024,512,256]):\n",
    "  print(f\"now gen workload of wdl with config: dim: {dim}, num_field: {num_field}, prefix: {prefix}\")\n",
    "  wdl_model_ori = wd.WideAndDeepModel([100 for i in range(num_field)],dim,l,0.1)\n",
    "  ori_traced = symbolic_trace(wdl_model_ori)\n",
    "  \n",
    "  wdl_model_modify = wd.WideAndDeepModel([100 for i in range(num_field)],dim,l,0.1)\n",
    "  modify_traced = symbolic_trace(wdl_model_modify)\n",
    "  pattern,replace,match = gen_pattern_replace_and_matcher_for_SingleMLP(modify_traced,\n",
    "                                                                      (0,slice(None,prefix,None)),(slice(None,None,None),slice(prefix,None,None)),\n",
    "                                                                      \"mlp_mlp_0\")\n",
    "  matches = subgraph_rewriter.replace_pattern_with_filters(modify_traced, pattern, replace,[match])\n",
    "  return ori_traced,modify_traced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_and_variance_manual(data):\n",
    "    n = len(data)\n",
    "    mean = sum(data) / n\n",
    "    variance = sum((x - mean) ** 2 for x in data) / n\n",
    "    return mean, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_and_test(num_field = 22,prefix = 10, batch = 4096, dim = 32, workload_func = workload_wdl,l = [1024,512,256]):\n",
    "  def run(model):\n",
    "    traced_model = torch.jit.trace(model, torch.randint(low=0, high=88, size=(batch,num_field), dtype=torch.long))\n",
    "    compiled_model = torch.compile(traced_model, backend=\"inductor\")\n",
    "    compiled_model.eval()\n",
    "    total_time = []\n",
    "    t = torch.randint(low=0, high=88, size=(batch ,num_field), dtype=torch.long)\n",
    "\n",
    "    with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "        with record_function(\"model_inference\"):\n",
    "          for i in range(100):\n",
    "              start_time = time.time()  # 开始计时\n",
    "              with torch.no_grad():\n",
    "                soutput = compiled_model(t)\n",
    "              end_time = time.time()  # 结束计时\n",
    "              \n",
    "              # 计算并打印函数执行所需的时间\n",
    "              elapsed_time = end_time - start_time\n",
    "              total_time.append(elapsed_time * 1000)\n",
    "    print(calculate_mean_and_variance_manual(total_time))\n",
    "    return prof\n",
    "  print(f\"now gen workload of wdl with config: dim: {dim}, num_field: {num_field}, prefix: {prefix}, batch :{batch}\")\n",
    "  ori, modify = workload_func(num_field,prefix,dim,l)\n",
    "  p1 = run(ori)\n",
    "  p2 = run(modify)\n",
    "  return p1, p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pattern_replace_and_matcher_for_embed(traced,\n",
    "                                                  redency_part_slice,unredency_part_slice,\n",
    "                                                  key_node_name,match_func = None, batch = 4096\n",
    "                                                ):\n",
    "  from torch.fx.passes.utils.matcher_utils import SubgraphMatcher\n",
    "\n",
    "\n",
    "  def _match(match,ori,pat):\n",
    "    return True \n",
    "  env  = utils.get_env(traced)\n",
    "  target_node = env[key_node_name]\n",
    "  target_node_mod = utils.get_target_mod(traced,target_node.target)\n",
    "  shape_info = target_node_mod.weight.data.shape\n",
    "  class PatternClass(torch.nn.Module):\n",
    "      def __init__(self):\n",
    "          super().__init__()\n",
    "          self.embed = torch.nn.Embedding(1, 1)\n",
    "          self.embed_output_dim = shape_info[1]\n",
    "          self.mlp = nn.Linear(shape_info[0],shape_info[1])\n",
    "\n",
    "\n",
    "      def forward(self,x):\n",
    "          x = self.embed(x)\n",
    "          return x\n",
    "  pattern = PatternClass()  \n",
    "  pattern_trace = symbolic_trace(pattern)\n",
    "  pattern_graph = pattern_trace.graph\n",
    "  original_graph = traced.graph\n",
    "  matcher =  SubgraphMatcher(pattern_graph, match_output=False, match_placeholder=False,\n",
    "                              remove_overlapping_matches=True)\n",
    "  _matches = matcher.match(original_graph)\n",
    "  match_filters = [_match if match_func is None else match_func]\n",
    "  _matches = [\n",
    "      m for m in _matches\n",
    "      if all(match_filter(m, original_graph, pattern_graph)\n",
    "              for match_filter in match_filters)\n",
    "  ]  \n",
    "  # 因为在过滤器中做了限制应该只有一个符合要求的\n",
    "  _matched = _matches[0]\n",
    "  pattern_env = utils.get_env(pattern_trace)\n",
    "  node_map = _matched.nodes_map\n",
    "  \n",
    "  embed_node = node_map[pattern_env['embed']]\n",
    "  embed_node_module = utils.get_target_mod(traced,embed_node.target)\n",
    "  \n",
    "  # linear_node = node_map[pattern_env['mlp']]\n",
    "  # linear_node_module = utils.get_target_mod(traced,linear_node.target)\n",
    "  # linear_node_weight = linear_node_module.weight.data\n",
    "  # linear_node_bias = linear_node_module.bias.data\n",
    "  \n",
    "  class ReplacementClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.embed = embed_node_module\n",
    "      \n",
    "\n",
    "    def forward(self,x):\n",
    "      r_x = x[redency_part_slice] \n",
    "      n_r = x[unredency_part_slice] \n",
    "      r_emb = self.embed(r_x)\n",
    "      n_emb = self.embed(n_r)\n",
    "      emb = torch.concat([r_emb.repeat(batch,1,1),n_emb], dim = 1)\n",
    "      return emb\n",
    "      # return unredency_sum\n",
    "    \n",
    "  \n",
    "  return pattern,ReplacementClass(),_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def workload_wdl(num_field, prefix,dim = 64,l = [1024,512,256],batch = 4096):\n",
    "  print(f\"now gen workload of wdl with config: dim: {dim}, num_field: {num_field}, prefix: {prefix}\")\n",
    "  wdl_model_ori = wd.WideAndDeepModel([100 for i in range(num_field)],dim,l,0.1)\n",
    "  ori_traced = symbolic_trace(wdl_model_ori)\n",
    "  \n",
    "  wdl_model_modify = wd.WideAndDeepModel([100 for i in range(num_field)],dim,l,0.1)\n",
    "  modify_traced = symbolic_trace(wdl_model_modify)\n",
    "  pattern,replace,match = gen_pattern_replace_and_matcher_for_embed(modify_traced,\n",
    "                                                                      (0,slice(None,prefix,None)),(slice(None,None,None),slice(prefix,None,None)),\n",
    "                                                                      \"mlp_mlp_0\",batch = batch)\n",
    "  matches = subgraph_rewriter.replace_pattern_with_filters(modify_traced, pattern, replace,[match])\n",
    "  return ori_traced,modify_traced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genWorkload(num_field = 34 * 5,prefix = 29 * 5, batch = 4096, dim = 64):\n",
    "  ori_model_name = f'/home/yssun/pytorch-fm/torchfm/model/test_fx/exp/model_repo/wdl_emb/wdl_{batch}_{num_field}_{prefix}_{dim}_ori.onnx'\n",
    "  modify_model_name = f'/home/yssun/pytorch-fm/torchfm/model/test_fx/exp/model_repo/wdl_emb/wdl_{batch}_{num_field}_{prefix}_{dim}_modify.onnx'\n",
    "  ori, modify = workload_wdl(num_field,prefix,dim,batch=batch)\n",
    "  torch.onnx.export(ori,               # 模型 being run\n",
    "                  torch.randint(low=0, high=20, size=(batch,num_field), dtype=torch.long),                  # 模型输入 (or a tuple for multiple inputs)\n",
    "                  ori_model_name,        # 导出文件的文件名\n",
    "                  export_params=True, # 如果设置为True，则参数也会被导出。注意某些情况下参数可能无法被导出。\n",
    "                  opset_version=10,   # ONNX版本\n",
    "                  do_constant_folding=True,  # 是否执行常量折叠以优化模型\n",
    "                  input_names = ['input'],   # 输入的名称\n",
    "                  output_names = ['output'], # 输出的名称\n",
    "                  )\n",
    "  torch.onnx.export(modify,               # 模型 being run\n",
    "                  torch.randint(low=0, high=20, size=(batch,num_field), dtype=torch.long),                  # 模型输入 (or a tuple for multiple inputs)\n",
    "                  modify_model_name,        # 导出文件的文件名\n",
    "                  export_params=True, # 如果设置为True，则参数也会被导出。注意某些情况下参数可能无法被导出。\n",
    "                  opset_version=10,   # ONNX版本\n",
    "                  do_constant_folding=True,  # 是否执行常量折叠以优化模型\n",
    "                  input_names = ['input'],   # 输入的名称\n",
    "                  output_names = ['output'], # 输出的名称\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims= [32]\n",
    "batches = [1024,2048,4096]\n",
    "num_field_and_prefixs = [(34 * 5,29*5),(22 * 5,10 * 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of wdl with config: dim: 32, num_field: 170, prefix: 145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1160: UserWarning: This model contains a squeeze operation on dimension 1. The size of this dimension in the given input is 32. The model will be exported without the squeeze node. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of wdl with config: dim: 32, num_field: 110, prefix: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1160: UserWarning: This model contains a squeeze operation on dimension 1. The size of this dimension in the given input is 32. The model will be exported without the squeeze node. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of wdl with config: dim: 32, num_field: 170, prefix: 145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1160: UserWarning: This model contains a squeeze operation on dimension 1. The size of this dimension in the given input is 32. The model will be exported without the squeeze node. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of wdl with config: dim: 32, num_field: 110, prefix: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1160: UserWarning: This model contains a squeeze operation on dimension 1. The size of this dimension in the given input is 32. The model will be exported without the squeeze node. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of wdl with config: dim: 32, num_field: 170, prefix: 145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1160: UserWarning: This model contains a squeeze operation on dimension 1. The size of this dimension in the given input is 32. The model will be exported without the squeeze node. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of wdl with config: dim: 32, num_field: 110, prefix: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1160: UserWarning: This model contains a squeeze operation on dimension 1. The size of this dimension in the given input is 32. The model will be exported without the squeeze node. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for dim in dims:\n",
    "  for batch in batches:\n",
    "    for num_field,prefix in num_field_and_prefixs:\n",
    "      genWorkload(num_field=num_field,prefix=prefix,batch=batch,dim=dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepctr-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
