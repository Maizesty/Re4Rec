{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../')\n",
    "\n",
    "import fm\n",
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace success!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.fx import subgraph_rewriter, symbolic_trace\n",
    "import utils\n",
    "import torch.fx as fx\n",
    "from torch.fx import Proxy, Graph, GraphModule\n",
    "from torch.fx.passes.utils.matcher_utils import SubgraphMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pattern_replace_and_matcher_for_FM(traced,\n",
    "                                                  redency_part_slice,unredency_part_slice,\n",
    "                                                  match_func = None\n",
    "                                                ):\n",
    "  from torch.fx.passes.utils.matcher_utils import SubgraphMatcher\n",
    "\n",
    "  class PatternClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.embed = torch.nn.Embedding(1, 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "      x = self.embed(x)\n",
    "      square_of_sum = torch.sum(x, dim=1) ** 2\n",
    "      sum_of_square = torch.sum(x ** 2, dim=1)\n",
    "      ix = square_of_sum - sum_of_square    \n",
    "      ix = torch.sum(ix, dim=1, keepdim=True)  \n",
    "      return 0.5 * ix\n",
    "  def _match(match,ori,pat):\n",
    "    return True \n",
    "  # env  = utils.get_env(traced)\n",
    "  # target_node = env[target_node_name]\n",
    "  # target_node_mod = utils.get_target_mod(traced,target_node_name,\"_\")\n",
    "  pattern = PatternClass()  \n",
    "  pattern_trace = symbolic_trace(pattern)\n",
    "  pattern_graph = pattern_trace.graph\n",
    "  original_graph = traced.graph\n",
    "  matcher =  SubgraphMatcher(pattern_graph, match_output=False, match_placeholder=False,\n",
    "                              remove_overlapping_matches=True)\n",
    "  _matches = matcher.match(original_graph)\n",
    "  match_filters = [_match if match_func is None else match_func]\n",
    "  _matches = [\n",
    "      m for m in _matches\n",
    "      if all(match_filter(m, original_graph, pattern_graph)\n",
    "              for match_filter in match_filters)\n",
    "  ]  \n",
    "  # 因为在过滤器中做了限制应该只有一个符合要求的\n",
    "  _matched = _matches[0]\n",
    "  pattern_env = utils.get_env(pattern_trace)\n",
    "  node_map = _matched.nodes_map\n",
    "  \n",
    "  embed_node = node_map[pattern_env['embed']]\n",
    "  embed_node_module = utils.get_target_mod(traced,embed_node.target)\n",
    "  \n",
    "\n",
    "  \n",
    "  \n",
    "  class ReplacementClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      embedding_config = embed_node_module.weight.data.shape\n",
    "      self.embed = nn.Embedding(embedding_config[0],embedding_config[1])\n",
    "      self.embed.weight.data.copy_(embed_node_module.weight.data)\n",
    "    def forward(self,x):\n",
    "      redency_part = x[redency_part_slice] \n",
    "      unredency_part = x[unredency_part_slice] \n",
    "      redency_embed = self.embed(redency_part)\n",
    "      unredency_embed = self.embed(unredency_part)\n",
    "      redency_embed_sum = torch.sum(redency_embed,dim=0)\n",
    "      unredency_embed_sum = torch.sum(unredency_embed,dim=1)\n",
    "      square_of_sum = (redency_embed_sum + unredency_embed_sum) ** 2\n",
    "      redency_embed_square_sum = torch.sum(redency_embed ** 2,dim=0)\n",
    "      unredency_embed_square_sum = torch.sum(unredency_embed ** 2,dim=1)\n",
    "      sum_of_square = redency_embed_square_sum + unredency_embed_square_sum\n",
    "      ix = square_of_sum - sum_of_square\n",
    "      ix = torch.sum(ix,dim = 1,keepdim=True)\n",
    "      return 0.5 * ix\n",
    "    \n",
    "  \n",
    "  return pattern,ReplacementClass(),_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def workload_FM(num_field, prefix,dim = 64):\n",
    "  # print(f\"now gen workload of wdl with config: dim: {dim}, num_field: {num_field}, prefix: {prefix}\")\n",
    "  model_ori = fm.FactorizationMachineModel([100 for i in range(num_field)],dim,)\n",
    "  ori_traced = symbolic_trace(model_ori)\n",
    "  \n",
    "  model_modify = fm.FactorizationMachineModel([100 for i in range(num_field)],dim,)\n",
    "  modify_traced = symbolic_trace(model_modify)\n",
    "  pattern,replace,match = gen_pattern_replace_and_matcher_for_FM(modify_traced,\n",
    "                                                                      (0,slice(None,prefix,None)),(slice(None,None,None),slice(prefix,None,None)),\n",
    "                                                                      )\n",
    "  matches = subgraph_rewriter.replace_pattern_with_filters(modify_traced, pattern, replace,[match])\n",
    "  return ori_traced,modify_traced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_and_variance_manual(data):\n",
    "    n = len(data)\n",
    "    mean = sum(data) / n\n",
    "    variance = sum((x - mean) ** 2 for x in data) / n\n",
    "    return mean, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_and_test(num_field = 22,prefix = 10, batch = 4096, dim = 32, workload_func = workload_FM):\n",
    "  def run(model):\n",
    "    t = torch.randint(low=0, high=88, size=(batch,num_field), dtype=torch.long).cuda()\n",
    "    traced_model = torch.jit.trace(model.cuda(), t)\n",
    "    compiled_model = torch.compile(traced_model, backend=\"inductor\")\n",
    "    compiled_model.eval()\n",
    "    total_time = []\n",
    "    for i in range(100):\n",
    "        start_event = torch.cuda.Event(enable_timing=True)\n",
    "        end_event = torch.cuda.Event(enable_timing=True)  \n",
    "        start_event.record()\n",
    "\n",
    "        with torch.no_grad():\n",
    "          soutput = compiled_model(t)\n",
    "        end_event.record()\n",
    "        torch.cuda.synchronize()\n",
    "        # 计算并打印函数执行所需的时间\n",
    "        elapsed_time = start_event.elapsed_time(end_event)\n",
    "        total_time.append(elapsed_time)\n",
    "    print(calculate_mean_and_variance_manual(total_time[2:]))\n",
    "  print(f\"now gen workload of fm with config: dim: {dim}, num_field: {num_field}, prefix: {prefix}, batch :{batch}\")\n",
    "  ori, modify = workload_func(num_field,prefix,dim)\n",
    "  run(ori)\n",
    "  run(modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 110, prefix: 50, batch :1024\n",
      "(0.24496293965042854, 3.6901617091051304e-05)\n",
      "(0.3211735505230573, 0.00016730831776382073)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 1024, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 110, prefix: 50, batch :2048\n",
      "(0.3712995919037838, 7.78932647711557e-05)\n",
      "(0.31460701841480876, 5.8910828594731324e-05)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 2048, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 110, prefix: 50, batch :4096\n",
      "(0.6269322457362194, 6.004928869995184e-05)\n",
      "(0.46117681690624784, 7.912373543456429e-05)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 110, prefix: 50, batch :8192\n",
      "(1.140207683553501, 0.029961910003152414)\n",
      "(0.7198233470624807, 6.236071498039282e-05)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 8192, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 110, prefix: 50, batch :1024\n",
      "(0.36762840741751146, 4.3714208059248475e-05)\n",
      "(0.31626677543533094, 8.753006318531525e-05)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 1024, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 110, prefix: 50, batch :2048\n",
      "(0.6362145324142612, 0.05322876640533168)\n",
      "(0.4471353453641035, 3.310831655977856e-05)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 2048, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 110, prefix: 50, batch :4096\n",
      "(1.113210772981449, 6.382334816363714e-05)\n",
      "(0.7152097918549363, 5.47502814092311e-05)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 4096, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 110, prefix: 50, batch :8192\n",
      "(2.075804111908893, 0.00012493646271312332)\n",
      "(1.250894044126783, 0.00010837843005160968)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 8192, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 170, prefix: 145, batch :1024\n",
      "(0.3116058792386736, 4.713469793604199e-05)\n",
      "(0.3200287338422269, 0.00018552453583151805)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 1024, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 170, prefix: 145, batch :2048\n",
      "(0.5013750204626395, 7.376683800384242e-05)\n",
      "(0.31763787628436574, 8.58140743072429e-05)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 2048, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 170, prefix: 145, batch :4096\n",
      "(0.8958883249029821, 4.598886072111278e-05)\n",
      "(0.4245485718152961, 0.005489447684038056)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 170, prefix: 145, batch :8192\n",
      "(1.6778252988445514, 0.00021309224665019196)\n",
      "(0.43759020676418225, 2.2458380243482643e-05)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 8192, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 170, prefix: 145, batch :1024\n",
      "(0.5063307771877367, 5.1432123278614074e-05)\n",
      "(0.32165159133015847, 0.0001594177773673537)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 1024, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 170, prefix: 145, batch :2048\n",
      "(0.8833106926509312, 4.89245135826085e-05)\n",
      "(0.3154308549603637, 7.272906586634951e-05)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 2048, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 170, prefix: 145, batch :4096\n",
      "(1.6419542711608264, 3.202589260592929e-05)\n",
      "(0.4081521645492437, 5.06888230663401e-05)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 4096, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 170, prefix: 145, batch :8192\n",
      "(3.1967451621075065, 2.2709015509819746e-05)\n",
      "(0.645053390945707, 1.1632349238021235e-05)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 8192, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 10, batch :4096\n",
      "(0.5595957533437379, 6.193883207898982e-05)\n",
      "(0.5608617152486529, 5.863843150407594e-05)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 10, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 20, batch :4096\n",
      "(0.5620457134684738, 5.6651374792935765e-05)\n",
      "(0.5199281628034553, 5.123814907960637e-05)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 20, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 30, batch :4096\n",
      "(0.5636643268624131, 6.791266955648203e-05)\n",
      "(0.4783232659101486, 8.674929349680784e-05)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 30, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 40, batch :4096\n",
      "(0.5646622077542909, 0.00018410211768763924)\n",
      "(0.4299503677353567, 5.715071718630624e-05)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 40, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 50, batch :4096\n",
      "(0.5591951036939815, 7.220937585863527e-05)\n",
      "(0.38230759027052896, 4.268407517602069e-05)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 50, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 60, batch :4096\n",
      "(0.5582984491270415, 5.9912076457300206e-05)\n",
      "(0.3344013058409399, 5.036184380358841e-05)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 60, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 70, batch :4096\n",
      "(0.5579624492294935, 5.575926001768646e-05)\n",
      "(0.29191020343984875, 0.00013983865455971463)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 70, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 80, batch :4096\n",
      "(0.5561453067526525, 5.214598931123871e-05)\n",
      "(0.2424685707201763, 9.394493032246283e-05)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 80, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 90, batch :4096\n",
      "(0.5556173081300697, 4.294864832436149e-05)\n",
      "(0.23668244891628928, 0.00010493106790542141)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 90, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 99, batch :4096\n",
      "(0.5562044077990006, 8.147495784594371e-05)\n",
      "(0.22071542834140817, 0.00011832999222558469)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 99, batch = 4096, dim = 32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepctr-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
