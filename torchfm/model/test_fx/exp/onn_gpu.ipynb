{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../')\n",
    "import time\n",
    "import onn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.fx import subgraph_rewriter, symbolic_trace\n",
    "import utils\n",
    "from torch.fx import Proxy, Graph, GraphModule\n",
    "from torch.fx.passes.utils.matcher_utils import SubgraphMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import time\n",
    "import torch._dynamo as dynamo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "onn_model = onn.ONN([10 for i in range(10)],32,[200,200,200],0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class ONN(torch.nn.Module):\n",
      "    def forward(self, x):\n",
      "        # No stacktrace found for following nodes\n",
      "        offsets = self.offsets\n",
      "        add = x + offsets;  x = offsets = None\n",
      "        embeddings_0 = getattr(self.embeddings, \"0\")(add)\n",
      "        embeddings_1 = getattr(self.embeddings, \"1\")(add)\n",
      "        embeddings_2 = getattr(self.embeddings, \"2\")(add)\n",
      "        embeddings_3 = getattr(self.embeddings, \"3\")(add)\n",
      "        embeddings_4 = getattr(self.embeddings, \"4\")(add)\n",
      "        embeddings_5 = getattr(self.embeddings, \"5\")(add)\n",
      "        embeddings_6 = getattr(self.embeddings, \"6\")(add)\n",
      "        embeddings_7 = getattr(self.embeddings, \"7\")(add)\n",
      "        embeddings_8 = getattr(self.embeddings, \"8\")(add)\n",
      "        embeddings_9 = getattr(self.embeddings, \"9\")(add);  add = None\n",
      "        flatten = embeddings_0.flatten(start_dim = 1);  embeddings_0 = None\n",
      "        getitem = embeddings_1[(slice(None, None, None), 0, slice(None, None, None))]\n",
      "        getitem_1 = embeddings_1[(slice(None, None, None), 1, slice(None, None, None))]\n",
      "        mul = getitem * getitem_1;  getitem = getitem_1 = None\n",
      "        sum_1 = torch.sum(mul, dim = 1, keepdim = True);  mul = None\n",
      "        getitem_2 = embeddings_2[(slice(None, None, None), 0, slice(None, None, None))]\n",
      "        getitem_3 = embeddings_1[(slice(None, None, None), 2, slice(None, None, None))]\n",
      "        mul_1 = getitem_2 * getitem_3;  getitem_2 = getitem_3 = None\n",
      "        sum_2 = torch.sum(mul_1, dim = 1, keepdim = True);  mul_1 = None\n",
      "        getitem_4 = embeddings_3[(slice(None, None, None), 0, slice(None, None, None))]\n",
      "        getitem_5 = embeddings_1[(slice(None, None, None), 3, slice(None, None, None))]\n",
      "        mul_2 = getitem_4 * getitem_5;  getitem_4 = getitem_5 = None\n",
      "        sum_3 = torch.sum(mul_2, dim = 1, keepdim = True);  mul_2 = None\n",
      "        getitem_6 = embeddings_4[(slice(None, None, None), 0, slice(None, None, None))]\n",
      "        getitem_7 = embeddings_1[(slice(None, None, None), 4, slice(None, None, None))]\n",
      "        mul_3 = getitem_6 * getitem_7;  getitem_6 = getitem_7 = None\n",
      "        sum_4 = torch.sum(mul_3, dim = 1, keepdim = True);  mul_3 = None\n",
      "        getitem_8 = embeddings_5[(slice(None, None, None), 0, slice(None, None, None))]\n",
      "        getitem_9 = embeddings_1[(slice(None, None, None), 5, slice(None, None, None))]\n",
      "        mul_4 = getitem_8 * getitem_9;  getitem_8 = getitem_9 = None\n",
      "        sum_5 = torch.sum(mul_4, dim = 1, keepdim = True);  mul_4 = None\n",
      "        getitem_10 = embeddings_6[(slice(None, None, None), 0, slice(None, None, None))]\n",
      "        getitem_11 = embeddings_1[(slice(None, None, None), 6, slice(None, None, None))]\n",
      "        mul_5 = getitem_10 * getitem_11;  getitem_10 = getitem_11 = None\n",
      "        sum_6 = torch.sum(mul_5, dim = 1, keepdim = True);  mul_5 = None\n",
      "        getitem_12 = embeddings_7[(slice(None, None, None), 0, slice(None, None, None))]\n",
      "        getitem_13 = embeddings_1[(slice(None, None, None), 7, slice(None, None, None))]\n",
      "        mul_6 = getitem_12 * getitem_13;  getitem_12 = getitem_13 = None\n",
      "        sum_7 = torch.sum(mul_6, dim = 1, keepdim = True);  mul_6 = None\n",
      "        getitem_14 = embeddings_8[(slice(None, None, None), 0, slice(None, None, None))]\n",
      "        getitem_15 = embeddings_1[(slice(None, None, None), 8, slice(None, None, None))]\n",
      "        mul_7 = getitem_14 * getitem_15;  getitem_14 = getitem_15 = None\n",
      "        sum_8 = torch.sum(mul_7, dim = 1, keepdim = True);  mul_7 = None\n",
      "        getitem_16 = embeddings_9[(slice(None, None, None), 0, slice(None, None, None))]\n",
      "        getitem_17 = embeddings_1[(slice(None, None, None), 9, slice(None, None, None))];  embeddings_1 = None\n",
      "        mul_8 = getitem_16 * getitem_17;  getitem_16 = getitem_17 = None\n",
      "        sum_9 = torch.sum(mul_8, dim = 1, keepdim = True);  mul_8 = None\n",
      "        getitem_18 = embeddings_2[(slice(None, None, None), 1, slice(None, None, None))]\n",
      "        getitem_19 = embeddings_2[(slice(None, None, None), 2, slice(None, None, None))]\n",
      "        mul_9 = getitem_18 * getitem_19;  getitem_18 = getitem_19 = None\n",
      "        sum_10 = torch.sum(mul_9, dim = 1, keepdim = True);  mul_9 = None\n",
      "        getitem_20 = embeddings_3[(slice(None, None, None), 1, slice(None, None, None))]\n",
      "        getitem_21 = embeddings_2[(slice(None, None, None), 3, slice(None, None, None))]\n",
      "        mul_10 = getitem_20 * getitem_21;  getitem_20 = getitem_21 = None\n",
      "        sum_11 = torch.sum(mul_10, dim = 1, keepdim = True);  mul_10 = None\n",
      "        getitem_22 = embeddings_4[(slice(None, None, None), 1, slice(None, None, None))]\n",
      "        getitem_23 = embeddings_2[(slice(None, None, None), 4, slice(None, None, None))]\n",
      "        mul_11 = getitem_22 * getitem_23;  getitem_22 = getitem_23 = None\n",
      "        sum_12 = torch.sum(mul_11, dim = 1, keepdim = True);  mul_11 = None\n",
      "        getitem_24 = embeddings_5[(slice(None, None, None), 1, slice(None, None, None))]\n",
      "        getitem_25 = embeddings_2[(slice(None, None, None), 5, slice(None, None, None))]\n",
      "        mul_12 = getitem_24 * getitem_25;  getitem_24 = getitem_25 = None\n",
      "        sum_13 = torch.sum(mul_12, dim = 1, keepdim = True);  mul_12 = None\n",
      "        getitem_26 = embeddings_6[(slice(None, None, None), 1, slice(None, None, None))]\n",
      "        getitem_27 = embeddings_2[(slice(None, None, None), 6, slice(None, None, None))]\n",
      "        mul_13 = getitem_26 * getitem_27;  getitem_26 = getitem_27 = None\n",
      "        sum_14 = torch.sum(mul_13, dim = 1, keepdim = True);  mul_13 = None\n",
      "        getitem_28 = embeddings_7[(slice(None, None, None), 1, slice(None, None, None))]\n",
      "        getitem_29 = embeddings_2[(slice(None, None, None), 7, slice(None, None, None))]\n",
      "        mul_14 = getitem_28 * getitem_29;  getitem_28 = getitem_29 = None\n",
      "        sum_15 = torch.sum(mul_14, dim = 1, keepdim = True);  mul_14 = None\n",
      "        getitem_30 = embeddings_8[(slice(None, None, None), 1, slice(None, None, None))]\n",
      "        getitem_31 = embeddings_2[(slice(None, None, None), 8, slice(None, None, None))]\n",
      "        mul_15 = getitem_30 * getitem_31;  getitem_30 = getitem_31 = None\n",
      "        sum_16 = torch.sum(mul_15, dim = 1, keepdim = True);  mul_15 = None\n",
      "        getitem_32 = embeddings_9[(slice(None, None, None), 1, slice(None, None, None))]\n",
      "        getitem_33 = embeddings_2[(slice(None, None, None), 9, slice(None, None, None))];  embeddings_2 = None\n",
      "        mul_16 = getitem_32 * getitem_33;  getitem_32 = getitem_33 = None\n",
      "        sum_17 = torch.sum(mul_16, dim = 1, keepdim = True);  mul_16 = None\n",
      "        getitem_34 = embeddings_3[(slice(None, None, None), 2, slice(None, None, None))]\n",
      "        getitem_35 = embeddings_3[(slice(None, None, None), 3, slice(None, None, None))]\n",
      "        mul_17 = getitem_34 * getitem_35;  getitem_34 = getitem_35 = None\n",
      "        sum_18 = torch.sum(mul_17, dim = 1, keepdim = True);  mul_17 = None\n",
      "        getitem_36 = embeddings_4[(slice(None, None, None), 2, slice(None, None, None))]\n",
      "        getitem_37 = embeddings_3[(slice(None, None, None), 4, slice(None, None, None))]\n",
      "        mul_18 = getitem_36 * getitem_37;  getitem_36 = getitem_37 = None\n",
      "        sum_19 = torch.sum(mul_18, dim = 1, keepdim = True);  mul_18 = None\n",
      "        getitem_38 = embeddings_5[(slice(None, None, None), 2, slice(None, None, None))]\n",
      "        getitem_39 = embeddings_3[(slice(None, None, None), 5, slice(None, None, None))]\n",
      "        mul_19 = getitem_38 * getitem_39;  getitem_38 = getitem_39 = None\n",
      "        sum_20 = torch.sum(mul_19, dim = 1, keepdim = True);  mul_19 = None\n",
      "        getitem_40 = embeddings_6[(slice(None, None, None), 2, slice(None, None, None))]\n",
      "        getitem_41 = embeddings_3[(slice(None, None, None), 6, slice(None, None, None))]\n",
      "        mul_20 = getitem_40 * getitem_41;  getitem_40 = getitem_41 = None\n",
      "        sum_21 = torch.sum(mul_20, dim = 1, keepdim = True);  mul_20 = None\n",
      "        getitem_42 = embeddings_7[(slice(None, None, None), 2, slice(None, None, None))]\n",
      "        getitem_43 = embeddings_3[(slice(None, None, None), 7, slice(None, None, None))]\n",
      "        mul_21 = getitem_42 * getitem_43;  getitem_42 = getitem_43 = None\n",
      "        sum_22 = torch.sum(mul_21, dim = 1, keepdim = True);  mul_21 = None\n",
      "        getitem_44 = embeddings_8[(slice(None, None, None), 2, slice(None, None, None))]\n",
      "        getitem_45 = embeddings_3[(slice(None, None, None), 8, slice(None, None, None))]\n",
      "        mul_22 = getitem_44 * getitem_45;  getitem_44 = getitem_45 = None\n",
      "        sum_23 = torch.sum(mul_22, dim = 1, keepdim = True);  mul_22 = None\n",
      "        getitem_46 = embeddings_9[(slice(None, None, None), 2, slice(None, None, None))]\n",
      "        getitem_47 = embeddings_3[(slice(None, None, None), 9, slice(None, None, None))];  embeddings_3 = None\n",
      "        mul_23 = getitem_46 * getitem_47;  getitem_46 = getitem_47 = None\n",
      "        sum_24 = torch.sum(mul_23, dim = 1, keepdim = True);  mul_23 = None\n",
      "        getitem_48 = embeddings_4[(slice(None, None, None), 3, slice(None, None, None))]\n",
      "        getitem_49 = embeddings_4[(slice(None, None, None), 4, slice(None, None, None))]\n",
      "        mul_24 = getitem_48 * getitem_49;  getitem_48 = getitem_49 = None\n",
      "        sum_25 = torch.sum(mul_24, dim = 1, keepdim = True);  mul_24 = None\n",
      "        getitem_50 = embeddings_5[(slice(None, None, None), 3, slice(None, None, None))]\n",
      "        getitem_51 = embeddings_4[(slice(None, None, None), 5, slice(None, None, None))]\n",
      "        mul_25 = getitem_50 * getitem_51;  getitem_50 = getitem_51 = None\n",
      "        sum_26 = torch.sum(mul_25, dim = 1, keepdim = True);  mul_25 = None\n",
      "        getitem_52 = embeddings_6[(slice(None, None, None), 3, slice(None, None, None))]\n",
      "        getitem_53 = embeddings_4[(slice(None, None, None), 6, slice(None, None, None))]\n",
      "        mul_26 = getitem_52 * getitem_53;  getitem_52 = getitem_53 = None\n",
      "        sum_27 = torch.sum(mul_26, dim = 1, keepdim = True);  mul_26 = None\n",
      "        getitem_54 = embeddings_7[(slice(None, None, None), 3, slice(None, None, None))]\n",
      "        getitem_55 = embeddings_4[(slice(None, None, None), 7, slice(None, None, None))]\n",
      "        mul_27 = getitem_54 * getitem_55;  getitem_54 = getitem_55 = None\n",
      "        sum_28 = torch.sum(mul_27, dim = 1, keepdim = True);  mul_27 = None\n",
      "        getitem_56 = embeddings_8[(slice(None, None, None), 3, slice(None, None, None))]\n",
      "        getitem_57 = embeddings_4[(slice(None, None, None), 8, slice(None, None, None))]\n",
      "        mul_28 = getitem_56 * getitem_57;  getitem_56 = getitem_57 = None\n",
      "        sum_29 = torch.sum(mul_28, dim = 1, keepdim = True);  mul_28 = None\n",
      "        getitem_58 = embeddings_9[(slice(None, None, None), 3, slice(None, None, None))]\n",
      "        getitem_59 = embeddings_4[(slice(None, None, None), 9, slice(None, None, None))];  embeddings_4 = None\n",
      "        mul_29 = getitem_58 * getitem_59;  getitem_58 = getitem_59 = None\n",
      "        sum_30 = torch.sum(mul_29, dim = 1, keepdim = True);  mul_29 = None\n",
      "        getitem_60 = embeddings_5[(slice(None, None, None), 4, slice(None, None, None))]\n",
      "        getitem_61 = embeddings_5[(slice(None, None, None), 5, slice(None, None, None))]\n",
      "        mul_30 = getitem_60 * getitem_61;  getitem_60 = getitem_61 = None\n",
      "        sum_31 = torch.sum(mul_30, dim = 1, keepdim = True);  mul_30 = None\n",
      "        getitem_62 = embeddings_6[(slice(None, None, None), 4, slice(None, None, None))]\n",
      "        getitem_63 = embeddings_5[(slice(None, None, None), 6, slice(None, None, None))]\n",
      "        mul_31 = getitem_62 * getitem_63;  getitem_62 = getitem_63 = None\n",
      "        sum_32 = torch.sum(mul_31, dim = 1, keepdim = True);  mul_31 = None\n",
      "        getitem_64 = embeddings_7[(slice(None, None, None), 4, slice(None, None, None))]\n",
      "        getitem_65 = embeddings_5[(slice(None, None, None), 7, slice(None, None, None))]\n",
      "        mul_32 = getitem_64 * getitem_65;  getitem_64 = getitem_65 = None\n",
      "        sum_33 = torch.sum(mul_32, dim = 1, keepdim = True);  mul_32 = None\n",
      "        getitem_66 = embeddings_8[(slice(None, None, None), 4, slice(None, None, None))]\n",
      "        getitem_67 = embeddings_5[(slice(None, None, None), 8, slice(None, None, None))]\n",
      "        mul_33 = getitem_66 * getitem_67;  getitem_66 = getitem_67 = None\n",
      "        sum_34 = torch.sum(mul_33, dim = 1, keepdim = True);  mul_33 = None\n",
      "        getitem_68 = embeddings_9[(slice(None, None, None), 4, slice(None, None, None))]\n",
      "        getitem_69 = embeddings_5[(slice(None, None, None), 9, slice(None, None, None))];  embeddings_5 = None\n",
      "        mul_34 = getitem_68 * getitem_69;  getitem_68 = getitem_69 = None\n",
      "        sum_35 = torch.sum(mul_34, dim = 1, keepdim = True);  mul_34 = None\n",
      "        getitem_70 = embeddings_6[(slice(None, None, None), 5, slice(None, None, None))]\n",
      "        getitem_71 = embeddings_6[(slice(None, None, None), 6, slice(None, None, None))]\n",
      "        mul_35 = getitem_70 * getitem_71;  getitem_70 = getitem_71 = None\n",
      "        sum_36 = torch.sum(mul_35, dim = 1, keepdim = True);  mul_35 = None\n",
      "        getitem_72 = embeddings_7[(slice(None, None, None), 5, slice(None, None, None))]\n",
      "        getitem_73 = embeddings_6[(slice(None, None, None), 7, slice(None, None, None))]\n",
      "        mul_36 = getitem_72 * getitem_73;  getitem_72 = getitem_73 = None\n",
      "        sum_37 = torch.sum(mul_36, dim = 1, keepdim = True);  mul_36 = None\n",
      "        getitem_74 = embeddings_8[(slice(None, None, None), 5, slice(None, None, None))]\n",
      "        getitem_75 = embeddings_6[(slice(None, None, None), 8, slice(None, None, None))]\n",
      "        mul_37 = getitem_74 * getitem_75;  getitem_74 = getitem_75 = None\n",
      "        sum_38 = torch.sum(mul_37, dim = 1, keepdim = True);  mul_37 = None\n",
      "        getitem_76 = embeddings_9[(slice(None, None, None), 5, slice(None, None, None))]\n",
      "        getitem_77 = embeddings_6[(slice(None, None, None), 9, slice(None, None, None))];  embeddings_6 = None\n",
      "        mul_38 = getitem_76 * getitem_77;  getitem_76 = getitem_77 = None\n",
      "        sum_39 = torch.sum(mul_38, dim = 1, keepdim = True);  mul_38 = None\n",
      "        getitem_78 = embeddings_7[(slice(None, None, None), 6, slice(None, None, None))]\n",
      "        getitem_79 = embeddings_7[(slice(None, None, None), 7, slice(None, None, None))]\n",
      "        mul_39 = getitem_78 * getitem_79;  getitem_78 = getitem_79 = None\n",
      "        sum_40 = torch.sum(mul_39, dim = 1, keepdim = True);  mul_39 = None\n",
      "        getitem_80 = embeddings_8[(slice(None, None, None), 6, slice(None, None, None))]\n",
      "        getitem_81 = embeddings_7[(slice(None, None, None), 8, slice(None, None, None))]\n",
      "        mul_40 = getitem_80 * getitem_81;  getitem_80 = getitem_81 = None\n",
      "        sum_41 = torch.sum(mul_40, dim = 1, keepdim = True);  mul_40 = None\n",
      "        getitem_82 = embeddings_9[(slice(None, None, None), 6, slice(None, None, None))]\n",
      "        getitem_83 = embeddings_7[(slice(None, None, None), 9, slice(None, None, None))];  embeddings_7 = None\n",
      "        mul_41 = getitem_82 * getitem_83;  getitem_82 = getitem_83 = None\n",
      "        sum_42 = torch.sum(mul_41, dim = 1, keepdim = True);  mul_41 = None\n",
      "        getitem_84 = embeddings_8[(slice(None, None, None), 7, slice(None, None, None))]\n",
      "        getitem_85 = embeddings_8[(slice(None, None, None), 8, slice(None, None, None))]\n",
      "        mul_42 = getitem_84 * getitem_85;  getitem_84 = getitem_85 = None\n",
      "        sum_43 = torch.sum(mul_42, dim = 1, keepdim = True);  mul_42 = None\n",
      "        getitem_86 = embeddings_9[(slice(None, None, None), 7, slice(None, None, None))]\n",
      "        getitem_87 = embeddings_8[(slice(None, None, None), 9, slice(None, None, None))];  embeddings_8 = None\n",
      "        mul_43 = getitem_86 * getitem_87;  getitem_86 = getitem_87 = None\n",
      "        sum_44 = torch.sum(mul_43, dim = 1, keepdim = True);  mul_43 = None\n",
      "        getitem_88 = embeddings_9[(slice(None, None, None), 8, slice(None, None, None))]\n",
      "        getitem_89 = embeddings_9[(slice(None, None, None), 9, slice(None, None, None))];  embeddings_9 = None\n",
      "        mul_44 = getitem_88 * getitem_89;  getitem_88 = getitem_89 = None\n",
      "        sum_45 = torch.sum(mul_44, dim = 1, keepdim = True);  mul_44 = None\n",
      "        cat = torch.cat([sum_1, sum_2, sum_3, sum_4, sum_5, sum_6, sum_7, sum_8, sum_9, sum_10, sum_11, sum_12, sum_13, sum_14, sum_15, sum_16, sum_17, sum_18, sum_19, sum_20, sum_21, sum_22, sum_23, sum_24, sum_25, sum_26, sum_27, sum_28, sum_29, sum_30, sum_31, sum_32, sum_33, sum_34, sum_35, sum_36, sum_37, sum_38, sum_39, sum_40, sum_41, sum_42, sum_43, sum_44, sum_45], dim = 1);  sum_1 = sum_2 = sum_3 = sum_4 = sum_5 = sum_6 = sum_7 = sum_8 = sum_9 = sum_10 = sum_11 = sum_12 = sum_13 = sum_14 = sum_15 = sum_16 = sum_17 = sum_18 = sum_19 = sum_20 = sum_21 = sum_22 = sum_23 = sum_24 = sum_25 = sum_26 = sum_27 = sum_28 = sum_29 = sum_30 = sum_31 = sum_32 = sum_33 = sum_34 = sum_35 = sum_36 = sum_37 = sum_38 = sum_39 = sum_40 = sum_41 = sum_42 = sum_43 = sum_44 = sum_45 = None\n",
      "        cat_1 = torch.cat([flatten, cat], dim = 1);  flatten = cat = None\n",
      "        mlp_mlp_0 = getattr(self.mlp.mlp, \"0\")(cat_1);  cat_1 = None\n",
      "        mlp_mlp_1 = getattr(self.mlp.mlp, \"1\")(mlp_mlp_0);  mlp_mlp_0 = None\n",
      "        mlp_mlp_2 = getattr(self.mlp.mlp, \"2\")(mlp_mlp_1);  mlp_mlp_1 = None\n",
      "        mlp_mlp_3 = getattr(self.mlp.mlp, \"3\")(mlp_mlp_2);  mlp_mlp_2 = None\n",
      "        mlp_mlp_4 = getattr(self.mlp.mlp, \"4\")(mlp_mlp_3);  mlp_mlp_3 = None\n",
      "        mlp_mlp_5 = getattr(self.mlp.mlp, \"5\")(mlp_mlp_4);  mlp_mlp_4 = None\n",
      "        mlp_mlp_6 = getattr(self.mlp.mlp, \"6\")(mlp_mlp_5);  mlp_mlp_5 = None\n",
      "        mlp_mlp_7 = getattr(self.mlp.mlp, \"7\")(mlp_mlp_6);  mlp_mlp_6 = None\n",
      "        mlp_mlp_8 = getattr(self.mlp.mlp, \"8\")(mlp_mlp_7);  mlp_mlp_7 = None\n",
      "        mlp_mlp_9 = getattr(self.mlp.mlp, \"9\")(mlp_mlp_8);  mlp_mlp_8 = None\n",
      "        squeeze = mlp_mlp_9.squeeze(1);  mlp_mlp_9 = None\n",
      "        sigmoid = torch.sigmoid(squeeze);  squeeze = None\n",
      "        return sigmoid\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'class ONN(torch.nn.Module):\\n    def forward(self, x):\\n        # No stacktrace found for following nodes\\n        offsets = self.offsets\\n        add = x + offsets;  x = offsets = None\\n        embeddings_0 = getattr(self.embeddings, \"0\")(add)\\n        embeddings_1 = getattr(self.embeddings, \"1\")(add)\\n        embeddings_2 = getattr(self.embeddings, \"2\")(add)\\n        embeddings_3 = getattr(self.embeddings, \"3\")(add)\\n        embeddings_4 = getattr(self.embeddings, \"4\")(add)\\n        embeddings_5 = getattr(self.embeddings, \"5\")(add)\\n        embeddings_6 = getattr(self.embeddings, \"6\")(add)\\n        embeddings_7 = getattr(self.embeddings, \"7\")(add)\\n        embeddings_8 = getattr(self.embeddings, \"8\")(add)\\n        embeddings_9 = getattr(self.embeddings, \"9\")(add);  add = None\\n        flatten = embeddings_0.flatten(start_dim = 1);  embeddings_0 = None\\n        getitem = embeddings_1[(slice(None, None, None), 0, slice(None, None, None))]\\n        getitem_1 = embeddings_1[(slice(None, None, None), 1, slice(None, None, None))]\\n        mul = getitem * getitem_1;  getitem = getitem_1 = None\\n        sum_1 = torch.sum(mul, dim = 1, keepdim = True);  mul = None\\n        getitem_2 = embeddings_2[(slice(None, None, None), 0, slice(None, None, None))]\\n        getitem_3 = embeddings_1[(slice(None, None, None), 2, slice(None, None, None))]\\n        mul_1 = getitem_2 * getitem_3;  getitem_2 = getitem_3 = None\\n        sum_2 = torch.sum(mul_1, dim = 1, keepdim = True);  mul_1 = None\\n        getitem_4 = embeddings_3[(slice(None, None, None), 0, slice(None, None, None))]\\n        getitem_5 = embeddings_1[(slice(None, None, None), 3, slice(None, None, None))]\\n        mul_2 = getitem_4 * getitem_5;  getitem_4 = getitem_5 = None\\n        sum_3 = torch.sum(mul_2, dim = 1, keepdim = True);  mul_2 = None\\n        getitem_6 = embeddings_4[(slice(None, None, None), 0, slice(None, None, None))]\\n        getitem_7 = embeddings_1[(slice(None, None, None), 4, slice(None, None, None))]\\n        mul_3 = getitem_6 * getitem_7;  getitem_6 = getitem_7 = None\\n        sum_4 = torch.sum(mul_3, dim = 1, keepdim = True);  mul_3 = None\\n        getitem_8 = embeddings_5[(slice(None, None, None), 0, slice(None, None, None))]\\n        getitem_9 = embeddings_1[(slice(None, None, None), 5, slice(None, None, None))]\\n        mul_4 = getitem_8 * getitem_9;  getitem_8 = getitem_9 = None\\n        sum_5 = torch.sum(mul_4, dim = 1, keepdim = True);  mul_4 = None\\n        getitem_10 = embeddings_6[(slice(None, None, None), 0, slice(None, None, None))]\\n        getitem_11 = embeddings_1[(slice(None, None, None), 6, slice(None, None, None))]\\n        mul_5 = getitem_10 * getitem_11;  getitem_10 = getitem_11 = None\\n        sum_6 = torch.sum(mul_5, dim = 1, keepdim = True);  mul_5 = None\\n        getitem_12 = embeddings_7[(slice(None, None, None), 0, slice(None, None, None))]\\n        getitem_13 = embeddings_1[(slice(None, None, None), 7, slice(None, None, None))]\\n        mul_6 = getitem_12 * getitem_13;  getitem_12 = getitem_13 = None\\n        sum_7 = torch.sum(mul_6, dim = 1, keepdim = True);  mul_6 = None\\n        getitem_14 = embeddings_8[(slice(None, None, None), 0, slice(None, None, None))]\\n        getitem_15 = embeddings_1[(slice(None, None, None), 8, slice(None, None, None))]\\n        mul_7 = getitem_14 * getitem_15;  getitem_14 = getitem_15 = None\\n        sum_8 = torch.sum(mul_7, dim = 1, keepdim = True);  mul_7 = None\\n        getitem_16 = embeddings_9[(slice(None, None, None), 0, slice(None, None, None))]\\n        getitem_17 = embeddings_1[(slice(None, None, None), 9, slice(None, None, None))];  embeddings_1 = None\\n        mul_8 = getitem_16 * getitem_17;  getitem_16 = getitem_17 = None\\n        sum_9 = torch.sum(mul_8, dim = 1, keepdim = True);  mul_8 = None\\n        getitem_18 = embeddings_2[(slice(None, None, None), 1, slice(None, None, None))]\\n        getitem_19 = embeddings_2[(slice(None, None, None), 2, slice(None, None, None))]\\n        mul_9 = getitem_18 * getitem_19;  getitem_18 = getitem_19 = None\\n        sum_10 = torch.sum(mul_9, dim = 1, keepdim = True);  mul_9 = None\\n        getitem_20 = embeddings_3[(slice(None, None, None), 1, slice(None, None, None))]\\n        getitem_21 = embeddings_2[(slice(None, None, None), 3, slice(None, None, None))]\\n        mul_10 = getitem_20 * getitem_21;  getitem_20 = getitem_21 = None\\n        sum_11 = torch.sum(mul_10, dim = 1, keepdim = True);  mul_10 = None\\n        getitem_22 = embeddings_4[(slice(None, None, None), 1, slice(None, None, None))]\\n        getitem_23 = embeddings_2[(slice(None, None, None), 4, slice(None, None, None))]\\n        mul_11 = getitem_22 * getitem_23;  getitem_22 = getitem_23 = None\\n        sum_12 = torch.sum(mul_11, dim = 1, keepdim = True);  mul_11 = None\\n        getitem_24 = embeddings_5[(slice(None, None, None), 1, slice(None, None, None))]\\n        getitem_25 = embeddings_2[(slice(None, None, None), 5, slice(None, None, None))]\\n        mul_12 = getitem_24 * getitem_25;  getitem_24 = getitem_25 = None\\n        sum_13 = torch.sum(mul_12, dim = 1, keepdim = True);  mul_12 = None\\n        getitem_26 = embeddings_6[(slice(None, None, None), 1, slice(None, None, None))]\\n        getitem_27 = embeddings_2[(slice(None, None, None), 6, slice(None, None, None))]\\n        mul_13 = getitem_26 * getitem_27;  getitem_26 = getitem_27 = None\\n        sum_14 = torch.sum(mul_13, dim = 1, keepdim = True);  mul_13 = None\\n        getitem_28 = embeddings_7[(slice(None, None, None), 1, slice(None, None, None))]\\n        getitem_29 = embeddings_2[(slice(None, None, None), 7, slice(None, None, None))]\\n        mul_14 = getitem_28 * getitem_29;  getitem_28 = getitem_29 = None\\n        sum_15 = torch.sum(mul_14, dim = 1, keepdim = True);  mul_14 = None\\n        getitem_30 = embeddings_8[(slice(None, None, None), 1, slice(None, None, None))]\\n        getitem_31 = embeddings_2[(slice(None, None, None), 8, slice(None, None, None))]\\n        mul_15 = getitem_30 * getitem_31;  getitem_30 = getitem_31 = None\\n        sum_16 = torch.sum(mul_15, dim = 1, keepdim = True);  mul_15 = None\\n        getitem_32 = embeddings_9[(slice(None, None, None), 1, slice(None, None, None))]\\n        getitem_33 = embeddings_2[(slice(None, None, None), 9, slice(None, None, None))];  embeddings_2 = None\\n        mul_16 = getitem_32 * getitem_33;  getitem_32 = getitem_33 = None\\n        sum_17 = torch.sum(mul_16, dim = 1, keepdim = True);  mul_16 = None\\n        getitem_34 = embeddings_3[(slice(None, None, None), 2, slice(None, None, None))]\\n        getitem_35 = embeddings_3[(slice(None, None, None), 3, slice(None, None, None))]\\n        mul_17 = getitem_34 * getitem_35;  getitem_34 = getitem_35 = None\\n        sum_18 = torch.sum(mul_17, dim = 1, keepdim = True);  mul_17 = None\\n        getitem_36 = embeddings_4[(slice(None, None, None), 2, slice(None, None, None))]\\n        getitem_37 = embeddings_3[(slice(None, None, None), 4, slice(None, None, None))]\\n        mul_18 = getitem_36 * getitem_37;  getitem_36 = getitem_37 = None\\n        sum_19 = torch.sum(mul_18, dim = 1, keepdim = True);  mul_18 = None\\n        getitem_38 = embeddings_5[(slice(None, None, None), 2, slice(None, None, None))]\\n        getitem_39 = embeddings_3[(slice(None, None, None), 5, slice(None, None, None))]\\n        mul_19 = getitem_38 * getitem_39;  getitem_38 = getitem_39 = None\\n        sum_20 = torch.sum(mul_19, dim = 1, keepdim = True);  mul_19 = None\\n        getitem_40 = embeddings_6[(slice(None, None, None), 2, slice(None, None, None))]\\n        getitem_41 = embeddings_3[(slice(None, None, None), 6, slice(None, None, None))]\\n        mul_20 = getitem_40 * getitem_41;  getitem_40 = getitem_41 = None\\n        sum_21 = torch.sum(mul_20, dim = 1, keepdim = True);  mul_20 = None\\n        getitem_42 = embeddings_7[(slice(None, None, None), 2, slice(None, None, None))]\\n        getitem_43 = embeddings_3[(slice(None, None, None), 7, slice(None, None, None))]\\n        mul_21 = getitem_42 * getitem_43;  getitem_42 = getitem_43 = None\\n        sum_22 = torch.sum(mul_21, dim = 1, keepdim = True);  mul_21 = None\\n        getitem_44 = embeddings_8[(slice(None, None, None), 2, slice(None, None, None))]\\n        getitem_45 = embeddings_3[(slice(None, None, None), 8, slice(None, None, None))]\\n        mul_22 = getitem_44 * getitem_45;  getitem_44 = getitem_45 = None\\n        sum_23 = torch.sum(mul_22, dim = 1, keepdim = True);  mul_22 = None\\n        getitem_46 = embeddings_9[(slice(None, None, None), 2, slice(None, None, None))]\\n        getitem_47 = embeddings_3[(slice(None, None, None), 9, slice(None, None, None))];  embeddings_3 = None\\n        mul_23 = getitem_46 * getitem_47;  getitem_46 = getitem_47 = None\\n        sum_24 = torch.sum(mul_23, dim = 1, keepdim = True);  mul_23 = None\\n        getitem_48 = embeddings_4[(slice(None, None, None), 3, slice(None, None, None))]\\n        getitem_49 = embeddings_4[(slice(None, None, None), 4, slice(None, None, None))]\\n        mul_24 = getitem_48 * getitem_49;  getitem_48 = getitem_49 = None\\n        sum_25 = torch.sum(mul_24, dim = 1, keepdim = True);  mul_24 = None\\n        getitem_50 = embeddings_5[(slice(None, None, None), 3, slice(None, None, None))]\\n        getitem_51 = embeddings_4[(slice(None, None, None), 5, slice(None, None, None))]\\n        mul_25 = getitem_50 * getitem_51;  getitem_50 = getitem_51 = None\\n        sum_26 = torch.sum(mul_25, dim = 1, keepdim = True);  mul_25 = None\\n        getitem_52 = embeddings_6[(slice(None, None, None), 3, slice(None, None, None))]\\n        getitem_53 = embeddings_4[(slice(None, None, None), 6, slice(None, None, None))]\\n        mul_26 = getitem_52 * getitem_53;  getitem_52 = getitem_53 = None\\n        sum_27 = torch.sum(mul_26, dim = 1, keepdim = True);  mul_26 = None\\n        getitem_54 = embeddings_7[(slice(None, None, None), 3, slice(None, None, None))]\\n        getitem_55 = embeddings_4[(slice(None, None, None), 7, slice(None, None, None))]\\n        mul_27 = getitem_54 * getitem_55;  getitem_54 = getitem_55 = None\\n        sum_28 = torch.sum(mul_27, dim = 1, keepdim = True);  mul_27 = None\\n        getitem_56 = embeddings_8[(slice(None, None, None), 3, slice(None, None, None))]\\n        getitem_57 = embeddings_4[(slice(None, None, None), 8, slice(None, None, None))]\\n        mul_28 = getitem_56 * getitem_57;  getitem_56 = getitem_57 = None\\n        sum_29 = torch.sum(mul_28, dim = 1, keepdim = True);  mul_28 = None\\n        getitem_58 = embeddings_9[(slice(None, None, None), 3, slice(None, None, None))]\\n        getitem_59 = embeddings_4[(slice(None, None, None), 9, slice(None, None, None))];  embeddings_4 = None\\n        mul_29 = getitem_58 * getitem_59;  getitem_58 = getitem_59 = None\\n        sum_30 = torch.sum(mul_29, dim = 1, keepdim = True);  mul_29 = None\\n        getitem_60 = embeddings_5[(slice(None, None, None), 4, slice(None, None, None))]\\n        getitem_61 = embeddings_5[(slice(None, None, None), 5, slice(None, None, None))]\\n        mul_30 = getitem_60 * getitem_61;  getitem_60 = getitem_61 = None\\n        sum_31 = torch.sum(mul_30, dim = 1, keepdim = True);  mul_30 = None\\n        getitem_62 = embeddings_6[(slice(None, None, None), 4, slice(None, None, None))]\\n        getitem_63 = embeddings_5[(slice(None, None, None), 6, slice(None, None, None))]\\n        mul_31 = getitem_62 * getitem_63;  getitem_62 = getitem_63 = None\\n        sum_32 = torch.sum(mul_31, dim = 1, keepdim = True);  mul_31 = None\\n        getitem_64 = embeddings_7[(slice(None, None, None), 4, slice(None, None, None))]\\n        getitem_65 = embeddings_5[(slice(None, None, None), 7, slice(None, None, None))]\\n        mul_32 = getitem_64 * getitem_65;  getitem_64 = getitem_65 = None\\n        sum_33 = torch.sum(mul_32, dim = 1, keepdim = True);  mul_32 = None\\n        getitem_66 = embeddings_8[(slice(None, None, None), 4, slice(None, None, None))]\\n        getitem_67 = embeddings_5[(slice(None, None, None), 8, slice(None, None, None))]\\n        mul_33 = getitem_66 * getitem_67;  getitem_66 = getitem_67 = None\\n        sum_34 = torch.sum(mul_33, dim = 1, keepdim = True);  mul_33 = None\\n        getitem_68 = embeddings_9[(slice(None, None, None), 4, slice(None, None, None))]\\n        getitem_69 = embeddings_5[(slice(None, None, None), 9, slice(None, None, None))];  embeddings_5 = None\\n        mul_34 = getitem_68 * getitem_69;  getitem_68 = getitem_69 = None\\n        sum_35 = torch.sum(mul_34, dim = 1, keepdim = True);  mul_34 = None\\n        getitem_70 = embeddings_6[(slice(None, None, None), 5, slice(None, None, None))]\\n        getitem_71 = embeddings_6[(slice(None, None, None), 6, slice(None, None, None))]\\n        mul_35 = getitem_70 * getitem_71;  getitem_70 = getitem_71 = None\\n        sum_36 = torch.sum(mul_35, dim = 1, keepdim = True);  mul_35 = None\\n        getitem_72 = embeddings_7[(slice(None, None, None), 5, slice(None, None, None))]\\n        getitem_73 = embeddings_6[(slice(None, None, None), 7, slice(None, None, None))]\\n        mul_36 = getitem_72 * getitem_73;  getitem_72 = getitem_73 = None\\n        sum_37 = torch.sum(mul_36, dim = 1, keepdim = True);  mul_36 = None\\n        getitem_74 = embeddings_8[(slice(None, None, None), 5, slice(None, None, None))]\\n        getitem_75 = embeddings_6[(slice(None, None, None), 8, slice(None, None, None))]\\n        mul_37 = getitem_74 * getitem_75;  getitem_74 = getitem_75 = None\\n        sum_38 = torch.sum(mul_37, dim = 1, keepdim = True);  mul_37 = None\\n        getitem_76 = embeddings_9[(slice(None, None, None), 5, slice(None, None, None))]\\n        getitem_77 = embeddings_6[(slice(None, None, None), 9, slice(None, None, None))];  embeddings_6 = None\\n        mul_38 = getitem_76 * getitem_77;  getitem_76 = getitem_77 = None\\n        sum_39 = torch.sum(mul_38, dim = 1, keepdim = True);  mul_38 = None\\n        getitem_78 = embeddings_7[(slice(None, None, None), 6, slice(None, None, None))]\\n        getitem_79 = embeddings_7[(slice(None, None, None), 7, slice(None, None, None))]\\n        mul_39 = getitem_78 * getitem_79;  getitem_78 = getitem_79 = None\\n        sum_40 = torch.sum(mul_39, dim = 1, keepdim = True);  mul_39 = None\\n        getitem_80 = embeddings_8[(slice(None, None, None), 6, slice(None, None, None))]\\n        getitem_81 = embeddings_7[(slice(None, None, None), 8, slice(None, None, None))]\\n        mul_40 = getitem_80 * getitem_81;  getitem_80 = getitem_81 = None\\n        sum_41 = torch.sum(mul_40, dim = 1, keepdim = True);  mul_40 = None\\n        getitem_82 = embeddings_9[(slice(None, None, None), 6, slice(None, None, None))]\\n        getitem_83 = embeddings_7[(slice(None, None, None), 9, slice(None, None, None))];  embeddings_7 = None\\n        mul_41 = getitem_82 * getitem_83;  getitem_82 = getitem_83 = None\\n        sum_42 = torch.sum(mul_41, dim = 1, keepdim = True);  mul_41 = None\\n        getitem_84 = embeddings_8[(slice(None, None, None), 7, slice(None, None, None))]\\n        getitem_85 = embeddings_8[(slice(None, None, None), 8, slice(None, None, None))]\\n        mul_42 = getitem_84 * getitem_85;  getitem_84 = getitem_85 = None\\n        sum_43 = torch.sum(mul_42, dim = 1, keepdim = True);  mul_42 = None\\n        getitem_86 = embeddings_9[(slice(None, None, None), 7, slice(None, None, None))]\\n        getitem_87 = embeddings_8[(slice(None, None, None), 9, slice(None, None, None))];  embeddings_8 = None\\n        mul_43 = getitem_86 * getitem_87;  getitem_86 = getitem_87 = None\\n        sum_44 = torch.sum(mul_43, dim = 1, keepdim = True);  mul_43 = None\\n        getitem_88 = embeddings_9[(slice(None, None, None), 8, slice(None, None, None))]\\n        getitem_89 = embeddings_9[(slice(None, None, None), 9, slice(None, None, None))];  embeddings_9 = None\\n        mul_44 = getitem_88 * getitem_89;  getitem_88 = getitem_89 = None\\n        sum_45 = torch.sum(mul_44, dim = 1, keepdim = True);  mul_44 = None\\n        cat = torch.cat([sum_1, sum_2, sum_3, sum_4, sum_5, sum_6, sum_7, sum_8, sum_9, sum_10, sum_11, sum_12, sum_13, sum_14, sum_15, sum_16, sum_17, sum_18, sum_19, sum_20, sum_21, sum_22, sum_23, sum_24, sum_25, sum_26, sum_27, sum_28, sum_29, sum_30, sum_31, sum_32, sum_33, sum_34, sum_35, sum_36, sum_37, sum_38, sum_39, sum_40, sum_41, sum_42, sum_43, sum_44, sum_45], dim = 1);  sum_1 = sum_2 = sum_3 = sum_4 = sum_5 = sum_6 = sum_7 = sum_8 = sum_9 = sum_10 = sum_11 = sum_12 = sum_13 = sum_14 = sum_15 = sum_16 = sum_17 = sum_18 = sum_19 = sum_20 = sum_21 = sum_22 = sum_23 = sum_24 = sum_25 = sum_26 = sum_27 = sum_28 = sum_29 = sum_30 = sum_31 = sum_32 = sum_33 = sum_34 = sum_35 = sum_36 = sum_37 = sum_38 = sum_39 = sum_40 = sum_41 = sum_42 = sum_43 = sum_44 = sum_45 = None\\n        cat_1 = torch.cat([flatten, cat], dim = 1);  flatten = cat = None\\n        mlp_mlp_0 = getattr(self.mlp.mlp, \"0\")(cat_1);  cat_1 = None\\n        mlp_mlp_1 = getattr(self.mlp.mlp, \"1\")(mlp_mlp_0);  mlp_mlp_0 = None\\n        mlp_mlp_2 = getattr(self.mlp.mlp, \"2\")(mlp_mlp_1);  mlp_mlp_1 = None\\n        mlp_mlp_3 = getattr(self.mlp.mlp, \"3\")(mlp_mlp_2);  mlp_mlp_2 = None\\n        mlp_mlp_4 = getattr(self.mlp.mlp, \"4\")(mlp_mlp_3);  mlp_mlp_3 = None\\n        mlp_mlp_5 = getattr(self.mlp.mlp, \"5\")(mlp_mlp_4);  mlp_mlp_4 = None\\n        mlp_mlp_6 = getattr(self.mlp.mlp, \"6\")(mlp_mlp_5);  mlp_mlp_5 = None\\n        mlp_mlp_7 = getattr(self.mlp.mlp, \"7\")(mlp_mlp_6);  mlp_mlp_6 = None\\n        mlp_mlp_8 = getattr(self.mlp.mlp, \"8\")(mlp_mlp_7);  mlp_mlp_7 = None\\n        mlp_mlp_9 = getattr(self.mlp.mlp, \"9\")(mlp_mlp_8);  mlp_mlp_8 = None\\n        squeeze = mlp_mlp_9.squeeze(1);  mlp_mlp_9 = None\\n        sigmoid = torch.sigmoid(squeeze);  squeeze = None\\n        return sigmoid\\n        '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced = symbolic_trace(onn_model)\n",
    "traced.print_readable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pattern_replace_and_matcher_for_ffm(traced,\n",
    "                                                  redundancy_part_slice,non_redundancy_part_slice,\n",
    "                                                  embed_node_name,getitem_node_names,num_field,batch = 4096,match_func = None\n",
    "                                                ):\n",
    "  from torch.fx.passes.utils.matcher_utils import SubgraphMatcher\n",
    "  def _match(match,ori,pat):\n",
    "    return True \n",
    "  class PatternClass(torch.nn.Module):\n",
    "    def __init__(self,num_fields):\n",
    "      super().__init__()\n",
    "      self.num_fields = num_fields\n",
    "      self.embeddings = torch.nn.ModuleList([\n",
    "              torch.nn.Embedding(1, 1) for _ in range(self.num_fields-1)\n",
    "          ])\n",
    "    def field_aware_interaction(self,field_aware_emb_list):\n",
    "      interaction = []\n",
    "      for i in range(self.num_fields - 1):\n",
    "          for j in range(i + 1, self.num_fields):\n",
    "              v_ij = field_aware_emb_list[j - 1][:, i, :]\n",
    "              v_ji = field_aware_emb_list[i][:, j, :]\n",
    "              dot = torch.sum(v_ij * v_ji, dim=1, keepdim=True)\n",
    "              interaction.append(dot)\n",
    "      return torch.cat(interaction, dim=1)  \n",
    "    def forward(self,x):\n",
    "      field_aware_emb_list = [self.embeddings[i](x) for i in range(self.num_fields-1)]\n",
    "      return self.field_aware_interaction(field_aware_emb_list)\n",
    "  pattern = PatternClass(num_field)  \n",
    "  pattern_trace = symbolic_trace(pattern)\n",
    "  pattern_graph = pattern_trace.graph\n",
    "  original_graph = traced.graph\n",
    "  matcher =  SubgraphMatcher(pattern_graph, match_output=False, match_placeholder=False,\n",
    "                              remove_overlapping_matches=True)\n",
    "  _matches = matcher.match(original_graph)\n",
    "  # 因为在过滤器中做了限制应该只有一个符合要求的\n",
    "  _matched = _matches[0]\n",
    "  pattern_env = utils.get_env(pattern_trace)\n",
    "  node_map = _matched.nodes_map\n",
    "  embed_names = [f'embeddings_{i}' for i in range(num_field-1)]\n",
    "  embed_node_list = [node_map[pattern_env[name]] for name in embed_names]\n",
    "  embed_node_module_list = [utils.get_target_mod(traced,embed_node.target) for embed_node in embed_node_list]\n",
    "  class ReplacementClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.embeddings = torch.nn.ModuleList(embed_node_module_list)\n",
    "      self.num_fields = num_field\n",
    "      self.num_prefix = redundancy_part_slice[1].stop\n",
    "      self.num_sufix = self.num_fields - self.num_prefix\n",
    "    def forward(self,x):\n",
    "      redundancy_part = x[redundancy_part_slice] \n",
    "      non_redundancy_part = x[non_redundancy_part_slice] \n",
    "      redundancy_ffm_embed = [self.embeddings[i](redundancy_part) for i in range(self.num_fields-1)]\n",
    "      non_redundancy_ffm_embed = [self.embeddings[i](non_redundancy_part) for i in range(self.num_fields-1)]\n",
    "      redundancy_interaction = []\n",
    "      for i in range(self.num_prefix - 1):\n",
    "          for j in range(i + 1, self.num_prefix):\n",
    "              v_ij = redundancy_ffm_embed[j - 1][ i, :]\n",
    "              v_ji = redundancy_ffm_embed[i][ j, :]\n",
    "              dot = torch.sum(v_ij * v_ji, dim=-1, keepdim=True)\n",
    "              redundancy_interaction.append(dot)\n",
    "              \n",
    "      non_redundancy_interaction = []\n",
    "      for i in range(self.num_sufix - 1):\n",
    "          for j in range(i + 1, self.num_sufix):\n",
    "              v_ij = non_redundancy_ffm_embed[j - 1+self.num_prefix][:, i, :]\n",
    "              v_ji = non_redundancy_ffm_embed[i+self.num_prefix][:, j, :]\n",
    "              dot = torch.sum(v_ij * v_ji, dim=-1, keepdim=True)\n",
    "              non_redundancy_interaction.append(dot)\n",
    "      mixed_interaction = []\n",
    "      for i in range(self.num_prefix):\n",
    "          for j in range(self.num_sufix):\n",
    "              v_ij = redundancy_ffm_embed[j - 1+self.num_prefix][ i, :]\n",
    "              v_ji = non_redundancy_ffm_embed[i - 1][ :,j, :]\n",
    "              dot = torch.sum(v_ij * v_ji, dim=-1, keepdim=True)\n",
    "              mixed_interaction.append(dot)\n",
    "      mixed = torch.concat(mixed_interaction,dim = -1)\n",
    "      non_redundancy = torch.concat(non_redundancy_interaction,dim = -1)\n",
    "      redundancy = torch.concat(redundancy_interaction,dim = -1).repeat(batch,1)\n",
    "      return torch.concat([redundancy,non_redundancy,mixed],dim = -1)\n",
    "  return pattern,ReplacementClass(),_match    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def workload_onn(num_field, prefix,dim = 64,l = [1024,512,256],batch = 4096):\n",
    "  print(f\"now gen workload of ONN with config: dim: {dim}, num_field: {num_field}, prefix: {prefix}\")\n",
    "  onn_model = onn.ONN([100 for i in range(num_field)],dim,l,0.1)\n",
    "\n",
    "  model_traced_ori = symbolic_trace(onn_model)\n",
    "  \n",
    "  onn_model_modify = onn.ONN([100 for i in range(num_field)],dim,l,0.1)\n",
    "  onn_model_traced_modify = symbolic_trace(onn_model_modify)\n",
    "  pattern,replace,match = gen_pattern_replace_and_matcher_for_ffm(onn_model_traced_modify,\n",
    "                                                                      (0,slice(None,prefix,None)),(slice(None,None,None),slice(prefix,None,None)),\n",
    "                                                                      embed_node_name = \"embedding_embedding\",\n",
    "                                                                      getitem_node_names = [\"getitem\",\"getitem_1\"],num_field=num_field,batch = batch)\n",
    "  matches = subgraph_rewriter.replace_pattern_with_filters(onn_model_traced_modify, pattern, replace,[match])\n",
    "  return model_traced_ori,onn_model_traced_modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_and_variance_manual(data):\n",
    "    n = len(data)\n",
    "    mean = sum(data) / n\n",
    "    variance = sum((x - mean) ** 2 for x in data) / n\n",
    "    return mean, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_and_test(num_field = 22,prefix = 10, batch = 4096, dim = 32, workload_func = workload_onn,l = [1024,512,256]):\n",
    "  def run(model):\n",
    "    t = torch.randint(low=0, high=88, size=(batch,num_field), dtype=torch.long).cuda()\n",
    "    traced_model = torch.jit.trace(model.cuda(), t)\n",
    "    compiled_model = torch.compile(traced_model, backend=\"inductor\")\n",
    "    compiled_model.eval()\n",
    "    total_time = []\n",
    "    for i in range(10):\n",
    "        start_event = torch.cuda.Event(enable_timing=True)\n",
    "        end_event = torch.cuda.Event(enable_timing=True)  \n",
    "        start_event.record()\n",
    "\n",
    "        with torch.no_grad():\n",
    "          soutput = compiled_model(t)\n",
    "        end_event.record()\n",
    "        torch.cuda.synchronize()\n",
    "        # 计算并打印函数执行所需的时间\n",
    "        elapsed_time = start_event.elapsed_time(end_event)\n",
    "        total_time.append(elapsed_time)\n",
    "    print(calculate_mean_and_variance_manual(total_time[2:]))\n",
    "  print(f\"now gen workload of DFM with config: dim: {dim}, num_field: {num_field}, prefix: {prefix}, batch :{batch}\")\n",
    "  ori, modify = workload_func(num_field,prefix,dim,l,batch = batch)\n",
    "  run(ori)\n",
    "  run(modify)\n",
    "  # return p1, p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_and_test(num_field = 22,prefix = 10, batch = 4096, dim = 32, workload_func = workload_onn,l = [1024,512,256]):\n",
    "  def run(model):\n",
    "    t = torch.randint(low=0, high=88, size=(batch,num_field), dtype=torch.long).cuda()\n",
    "    traced_model = torch.jit.trace(model.cuda(), t)\n",
    "    compiled_model = torch.compile(traced_model, backend=\"inductor\")\n",
    "    compiled_model.eval()\n",
    "    total_time = []\n",
    "    for i in range(10):\n",
    "        start_event = torch.cuda.Event(enable_timing=True)\n",
    "        end_event = torch.cuda.Event(enable_timing=True)  \n",
    "        start_event.record()\n",
    "\n",
    "        with torch.no_grad():\n",
    "          soutput = compiled_model(t)\n",
    "        end_event.record()\n",
    "        torch.cuda.synchronize()\n",
    "        # 计算并打印函数执行所需的时间\n",
    "        elapsed_time = start_event.elapsed_time(end_event)\n",
    "        total_time.append(elapsed_time)\n",
    "    print(calculate_mean_and_variance_manual(total_time[2:]))\n",
    "  print(f\"now gen workload of DFM with config: dim: {dim}, num_field: {num_field}, prefix: {prefix}, batch :{batch}\")\n",
    "  ori, modify = workload_func(num_field,prefix,dim,l,batch = batch)\n",
    "  run(ori)\n",
    "  run(modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori, modify = workload_onn(num_field,prefix,dim,l = [1024,512,256],batch = batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genWorkload(num_field = 34 * 5,prefix = 29 * 5, batch = 4096, dim = 64):\n",
    "  ori_model_name = f'/home/yssun/pytorch-fm/torchfm/model/test_fx/exp/model_repo/onn/onn_{batch}_{num_field}_{prefix}_{dim}_ori.onnx'\n",
    "  modify_model_name = f'/home/yssun/pytorch-fm/torchfm/model/test_fx/exp/model_repo/onn/onn_{batch}_{num_field}_{prefix}_{dim}_modify.onnx'\n",
    "  ori, modify = workload_onn(num_field,prefix,dim,l = [1024,512,256],batch = batch)\n",
    "  torch.onnx.export(ori,               # 模型 being run\n",
    "                  torch.randint(low=0, high=20, size=(batch,num_field), dtype=torch.long),                  # 模型输入 (or a tuple for multiple inputs)\n",
    "                  ori_model_name,        # 导出文件的文件名\n",
    "                  export_params=True, # 如果设置为True，则参数也会被导出。注意某些情况下参数可能无法被导出。\n",
    "                  opset_version=10,   # ONNX版本\n",
    "                  do_constant_folding=True,  # 是否执行常量折叠以优化模型\n",
    "                  input_names = ['input'],   # 输入的名称\n",
    "                  output_names = ['output'], # 输出的名称\n",
    "                  )\n",
    "  torch.onnx.export(modify,               # 模型 being run\n",
    "                  torch.randint(low=0, high=20, size=(batch,num_field), dtype=torch.long),                  # 模型输入 (or a tuple for multiple inputs)\n",
    "                  modify_model_name,        # 导出文件的文件名\n",
    "                  export_params=True, # 如果设置为True，则参数也会被导出。注意某些情况下参数可能无法被导出。\n",
    "                  opset_version=10,   # ONNX版本\n",
    "                  do_constant_folding=True,  # 是否执行常量折叠以优化模型\n",
    "                  input_names = ['input'],   # 输入的名称\n",
    "                  output_names = ['output'], # 输出的名称\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims= [32]\n",
    "batches = [1024,2048,4096]\n",
    "num_field_and_prefixs = [(34 * 5,29*5),(22 * 5,10 * 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of ONN with config: dim: 32, num_field: 170, prefix: 145\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[1;32m      3\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m num_field,prefix \u001b[38;5;129;01min\u001b[39;00m num_field_and_prefixs:\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mgenWorkload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_field\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m, in \u001b[0;36mgenWorkload\u001b[0;34m(num_field, prefix, batch, dim)\u001b[0m\n\u001b[1;32m      3\u001b[0m modify_model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/yssun/pytorch-fm/torchfm/model/test_fx/exp/model_repo/onn/onn_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_field\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_modify.onnx\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m ori, modify \u001b[38;5;241m=\u001b[39m workload_onn(num_field,prefix,dim,l \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1024\u001b[39m,\u001b[38;5;241m512\u001b[39m,\u001b[38;5;241m256\u001b[39m],batch \u001b[38;5;241m=\u001b[39m batch)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mori\u001b[49m\u001b[43m,\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;66;43;03m# 模型 being run\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhigh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_field\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;66;43;03m# 模型输入 (or a tuple for multiple inputs)\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m                \u001b[49m\u001b[43mori_model_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 导出文件的文件名\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m                \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 如果设置为True，则参数也会被导出。注意某些情况下参数可能无法被导出。\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m                \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# ONNX版本\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 是否执行常量折叠以优化模型\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m                \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# 输入的名称\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m                \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 输出的名称\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m torch\u001b[38;5;241m.\u001b[39monnx\u001b[38;5;241m.\u001b[39mexport(modify,               \u001b[38;5;66;03m# 模型 being run\u001b[39;00m\n\u001b[1;32m     15\u001b[0m                 torch\u001b[38;5;241m.\u001b[39mrandint(low\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, high\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, size\u001b[38;5;241m=\u001b[39m(batch,num_field), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong),                  \u001b[38;5;66;03m# 模型输入 (or a tuple for multiple inputs)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m                 modify_model_name,        \u001b[38;5;66;03m# 导出文件的文件名\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m                 output_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;66;03m# 输出的名称\u001b[39;00m\n\u001b[1;32m     22\u001b[0m                 )\n",
      "File \u001b[0;32m~/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/utils.py:516\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;129m@_beartype\u001b[39m\u001b[38;5;241m.\u001b[39mbeartype\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexport\u001b[39m(\n\u001b[1;32m    191\u001b[0m     model: Union[torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptFunction],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m     autograd_inlining: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;124;03m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m     \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/utils.py:1612\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m   1609\u001b[0m     dynamic_axes \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1610\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[0;32m-> 1612\u001b[0m graph, params_dict, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_model_to_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1616\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1617\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_do_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[38;5;66;03m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[1;32m   1626\u001b[0m defer_weight_export \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1627\u001b[0m     export_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _exporter_states\u001b[38;5;241m.\u001b[39mExportTypes\u001b[38;5;241m.\u001b[39mPROTOBUF_FILE\n\u001b[1;32m   1628\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/utils.py:1138\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1135\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1138\u001b[0m     graph \u001b[38;5;241m=\u001b[39m \u001b[43m_optimize_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_disable_torch_constant_prop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_disable_torch_constant_prop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1149\u001b[0m     torch\u001b[38;5;241m.\u001b[39monnx\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch IR graph at exception: \u001b[39m\u001b[38;5;124m\"\u001b[39m, graph)\n",
      "File \u001b[0;32m~/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/utils.py:677\u001b[0m, in \u001b[0;36m_optimize_graph\u001b[0;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, dynamic_axes, input_names, module)\u001b[0m\n\u001b[1;32m    674\u001b[0m     _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_set_dynamic_input_shape(graph, dynamic_axes, input_names)\n\u001b[1;32m    675\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[0;32m--> 677\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jit_pass_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    678\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[1;32m    679\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_lint(graph)\n",
      "File \u001b[0;32m~/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/utils.py:1881\u001b[0m, in \u001b[0;36m_run_symbolic_function\u001b[0;34m(graph, block, node, inputs, env, operator_export_type)\u001b[0m\n\u001b[1;32m   1877\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mparse_schema(schema)\u001b[38;5;241m.\u001b[39moverload_name\n\u001b[0;32m-> 1881\u001b[0m \u001b[38;5;129m@_beartype\u001b[39m\u001b[38;5;241m.\u001b[39mbeartype\n\u001b[1;32m   1882\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_symbolic_function\u001b[39m(\n\u001b[1;32m   1883\u001b[0m     graph: _C\u001b[38;5;241m.\u001b[39mGraph,\n\u001b[1;32m   1884\u001b[0m     block: _C\u001b[38;5;241m.\u001b[39mBlock,\n\u001b[1;32m   1885\u001b[0m     node: _C\u001b[38;5;241m.\u001b[39mNode,\n\u001b[1;32m   1886\u001b[0m     inputs: Any,\n\u001b[1;32m   1887\u001b[0m     env: Dict[_C\u001b[38;5;241m.\u001b[39mValue, _C\u001b[38;5;241m.\u001b[39mValue],\n\u001b[1;32m   1888\u001b[0m     operator_export_type\u001b[38;5;241m=\u001b[39m_C_onnx\u001b[38;5;241m.\u001b[39mOperatorExportTypes\u001b[38;5;241m.\u001b[39mONNX,\n\u001b[1;32m   1889\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Union[_C\u001b[38;5;241m.\u001b[39mValue, Sequence[Optional[_C\u001b[38;5;241m.\u001b[39mValue]]]]:\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Runs a symbolic function.\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m \n\u001b[1;32m   1892\u001b[0m \u001b[38;5;124;03m    The function is used in C++ to export the node to ONNX.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1896\u001b[0m \u001b[38;5;124;03m        None when the node gets cloned as is into the new graph.\u001b[39;00m\n\u001b[1;32m   1897\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1899\u001b[0m     opset_version \u001b[38;5;241m=\u001b[39m GLOBALS\u001b[38;5;241m.\u001b[39mexport_onnx_opset_version\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for dim in dims:\n",
    "  for batch in batches:\n",
    "    for num_field,prefix in num_field_and_prefixs:\n",
    "      genWorkload(num_field=num_field,prefix=prefix,batch=batch,dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of ONN with config: dim: 32, num_field: 110, prefix: 50\n"
     ]
    }
   ],
   "source": [
    "ori, modify = workload_onn(22 *5,10 *5,32,[1024,512,256],batch = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.randint(low=0, high=88, size=(1024,22 *5), dtype=torch.long).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/jit/_trace.py:1116: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Tensor-likes are not close!\n",
      "\n",
      "Mismatched elements: 1024 / 1024 (100.0%)\n",
      "Greatest absolute difference: 0.12809452414512634 at index (71,) (up to 1e-05 allowed)\n",
      "Greatest relative difference: 0.23429494558854905 at index (38,) (up to 1e-05 allowed)\n",
      "  _check_trace(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OptimizedModule(\n",
       "  (_orig_mod): ONN(\n",
       "    original_name=ONN\n",
       "    (embeddings): Module(\n",
       "      original_name=Module\n",
       "      (0): Embedding(original_name=Embedding)\n",
       "      (1): Embedding(original_name=Embedding)\n",
       "      (2): Embedding(original_name=Embedding)\n",
       "      (3): Embedding(original_name=Embedding)\n",
       "      (4): Embedding(original_name=Embedding)\n",
       "      (5): Embedding(original_name=Embedding)\n",
       "      (6): Embedding(original_name=Embedding)\n",
       "      (7): Embedding(original_name=Embedding)\n",
       "      (8): Embedding(original_name=Embedding)\n",
       "      (9): Embedding(original_name=Embedding)\n",
       "      (10): Embedding(original_name=Embedding)\n",
       "      (11): Embedding(original_name=Embedding)\n",
       "      (12): Embedding(original_name=Embedding)\n",
       "      (13): Embedding(original_name=Embedding)\n",
       "      (14): Embedding(original_name=Embedding)\n",
       "      (15): Embedding(original_name=Embedding)\n",
       "      (16): Embedding(original_name=Embedding)\n",
       "      (17): Embedding(original_name=Embedding)\n",
       "      (18): Embedding(original_name=Embedding)\n",
       "      (19): Embedding(original_name=Embedding)\n",
       "      (20): Embedding(original_name=Embedding)\n",
       "      (21): Embedding(original_name=Embedding)\n",
       "      (22): Embedding(original_name=Embedding)\n",
       "      (23): Embedding(original_name=Embedding)\n",
       "      (24): Embedding(original_name=Embedding)\n",
       "      (25): Embedding(original_name=Embedding)\n",
       "      (26): Embedding(original_name=Embedding)\n",
       "      (27): Embedding(original_name=Embedding)\n",
       "      (28): Embedding(original_name=Embedding)\n",
       "      (29): Embedding(original_name=Embedding)\n",
       "      (30): Embedding(original_name=Embedding)\n",
       "      (31): Embedding(original_name=Embedding)\n",
       "      (32): Embedding(original_name=Embedding)\n",
       "      (33): Embedding(original_name=Embedding)\n",
       "      (34): Embedding(original_name=Embedding)\n",
       "      (35): Embedding(original_name=Embedding)\n",
       "      (36): Embedding(original_name=Embedding)\n",
       "      (37): Embedding(original_name=Embedding)\n",
       "      (38): Embedding(original_name=Embedding)\n",
       "      (39): Embedding(original_name=Embedding)\n",
       "      (40): Embedding(original_name=Embedding)\n",
       "      (41): Embedding(original_name=Embedding)\n",
       "      (42): Embedding(original_name=Embedding)\n",
       "      (43): Embedding(original_name=Embedding)\n",
       "      (44): Embedding(original_name=Embedding)\n",
       "      (45): Embedding(original_name=Embedding)\n",
       "      (46): Embedding(original_name=Embedding)\n",
       "      (47): Embedding(original_name=Embedding)\n",
       "      (48): Embedding(original_name=Embedding)\n",
       "      (49): Embedding(original_name=Embedding)\n",
       "      (50): Embedding(original_name=Embedding)\n",
       "      (51): Embedding(original_name=Embedding)\n",
       "      (52): Embedding(original_name=Embedding)\n",
       "      (53): Embedding(original_name=Embedding)\n",
       "      (54): Embedding(original_name=Embedding)\n",
       "      (55): Embedding(original_name=Embedding)\n",
       "      (56): Embedding(original_name=Embedding)\n",
       "      (57): Embedding(original_name=Embedding)\n",
       "      (58): Embedding(original_name=Embedding)\n",
       "      (59): Embedding(original_name=Embedding)\n",
       "      (60): Embedding(original_name=Embedding)\n",
       "      (61): Embedding(original_name=Embedding)\n",
       "      (62): Embedding(original_name=Embedding)\n",
       "      (63): Embedding(original_name=Embedding)\n",
       "      (64): Embedding(original_name=Embedding)\n",
       "      (65): Embedding(original_name=Embedding)\n",
       "      (66): Embedding(original_name=Embedding)\n",
       "      (67): Embedding(original_name=Embedding)\n",
       "      (68): Embedding(original_name=Embedding)\n",
       "      (69): Embedding(original_name=Embedding)\n",
       "      (70): Embedding(original_name=Embedding)\n",
       "      (71): Embedding(original_name=Embedding)\n",
       "      (72): Embedding(original_name=Embedding)\n",
       "      (73): Embedding(original_name=Embedding)\n",
       "      (74): Embedding(original_name=Embedding)\n",
       "      (75): Embedding(original_name=Embedding)\n",
       "      (76): Embedding(original_name=Embedding)\n",
       "      (77): Embedding(original_name=Embedding)\n",
       "      (78): Embedding(original_name=Embedding)\n",
       "      (79): Embedding(original_name=Embedding)\n",
       "      (80): Embedding(original_name=Embedding)\n",
       "      (81): Embedding(original_name=Embedding)\n",
       "      (82): Embedding(original_name=Embedding)\n",
       "      (83): Embedding(original_name=Embedding)\n",
       "      (84): Embedding(original_name=Embedding)\n",
       "      (85): Embedding(original_name=Embedding)\n",
       "      (86): Embedding(original_name=Embedding)\n",
       "      (87): Embedding(original_name=Embedding)\n",
       "      (88): Embedding(original_name=Embedding)\n",
       "      (89): Embedding(original_name=Embedding)\n",
       "      (90): Embedding(original_name=Embedding)\n",
       "      (91): Embedding(original_name=Embedding)\n",
       "      (92): Embedding(original_name=Embedding)\n",
       "      (93): Embedding(original_name=Embedding)\n",
       "      (94): Embedding(original_name=Embedding)\n",
       "      (95): Embedding(original_name=Embedding)\n",
       "      (96): Embedding(original_name=Embedding)\n",
       "      (97): Embedding(original_name=Embedding)\n",
       "      (98): Embedding(original_name=Embedding)\n",
       "      (99): Embedding(original_name=Embedding)\n",
       "      (100): Embedding(original_name=Embedding)\n",
       "      (101): Embedding(original_name=Embedding)\n",
       "      (102): Embedding(original_name=Embedding)\n",
       "      (103): Embedding(original_name=Embedding)\n",
       "      (104): Embedding(original_name=Embedding)\n",
       "      (105): Embedding(original_name=Embedding)\n",
       "      (106): Embedding(original_name=Embedding)\n",
       "      (107): Embedding(original_name=Embedding)\n",
       "      (108): Embedding(original_name=Embedding)\n",
       "      (109): Embedding(original_name=Embedding)\n",
       "    )\n",
       "    (mlp): Module(\n",
       "      original_name=Module\n",
       "      (mlp): Module(\n",
       "        original_name=Module\n",
       "        (0): Linear(original_name=Linear)\n",
       "        (1): ReLU(original_name=ReLU)\n",
       "        (2): Dropout(original_name=Dropout)\n",
       "        (3): Linear(original_name=Linear)\n",
       "        (4): ReLU(original_name=ReLU)\n",
       "        (5): Dropout(original_name=Dropout)\n",
       "        (6): Linear(original_name=Linear)\n",
       "        (7): ReLU(original_name=ReLU)\n",
       "        (8): Dropout(original_name=Dropout)\n",
       "        (9): Linear(original_name=Linear)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_model = torch.jit.trace(ori.cuda(), t)\n",
    "compiled_model = torch.compile(traced_model, backend=\"inductor\")\n",
    "compiled_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_compiled = compiled_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.autograd.profiler as profiler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-06 21:33:06 265017:265017 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-06 21:33:06 265017:265017 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-06 21:33:06 265017:265017 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "[W collection.cpp:936] Warning: Failed to recover relationship between all profiler and kineto events: 24238 vs. 0  reassociated. (function reassociate)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      12.551ms        29.04%      12.551ms       2.094us           0 b           0 b           0 b           0 b          5995  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      12.148ms        28.11%      12.148ms       2.026us           0 b           0 b           0 b           0 b          5995  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us      10.713ms        24.79%      10.713ms     227.936us           0 b           0 b           0 b           0 b            47  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us       6.739ms        15.59%       6.739ms      61.264us           0 b           0 b           0 b           0 b           110  \n",
      "                                ampere_sgemm_128x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us     918.000us         2.12%     918.000us     918.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us      73.000us         0.17%      73.000us      73.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us      32.000us         0.07%      32.000us      32.000us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::(anonymous namespace)::fused_dropou...         0.00%       0.000us         0.00%       0.000us       0.000us      21.000us         0.05%      21.000us       7.000us           0 b           0 b           0 b           0 b             3  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      15.000us         0.03%      15.000us       5.000us           0 b           0 b           0 b           0 b             3  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       5.000us         0.01%       5.000us       5.000us           0 b           0 b           0 b           0 b             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 71.028ms\n",
      "Self CUDA time total: 43.220ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.profiler.profile(\n",
    "    activities=[\n",
    "        torch.profiler.ProfilerActivity.CUDA,  # 记录CUDA活动\n",
    "    ],\n",
    "    record_shapes=True,  # 记录操作输入和输出的形状\n",
    "    profile_memory=True,  # 记录内存使用情况\n",
    "    with_stack=True,  # 记录代码堆栈信息\n",
    "    on_trace_ready=torch.profiler.tensorboard_trace_handler('./log')  # 输出TensorBoard日志\n",
    ") as prof:\n",
    "    # 在profiler上下文管理器内执行模型\n",
    "    output = ori_compiled(t)\n",
    "    torch.cuda.synchronize()  # 确保所有CUDA操作都已完成\n",
    "\n",
    "# 输出分析结果\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/jit/_trace.py:1116: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Tensor-likes are not close!\n",
      "\n",
      "Mismatched elements: 1024 / 1024 (100.0%)\n",
      "Greatest absolute difference: 0.13400110602378845 at index (996,) (up to 1e-05 allowed)\n",
      "Greatest relative difference: 0.22258523962326987 at index (131,) (up to 1e-05 allowed)\n",
      "  _check_trace(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OptimizedModule(\n",
       "  (_orig_mod): ONN(\n",
       "    original_name=ONN\n",
       "    (embeddings): Module(\n",
       "      original_name=Module\n",
       "      (0): Embedding(original_name=Embedding)\n",
       "      (1): Embedding(original_name=Embedding)\n",
       "      (2): Embedding(original_name=Embedding)\n",
       "      (3): Embedding(original_name=Embedding)\n",
       "      (4): Embedding(original_name=Embedding)\n",
       "      (5): Embedding(original_name=Embedding)\n",
       "      (6): Embedding(original_name=Embedding)\n",
       "      (7): Embedding(original_name=Embedding)\n",
       "      (8): Embedding(original_name=Embedding)\n",
       "      (9): Embedding(original_name=Embedding)\n",
       "      (10): Embedding(original_name=Embedding)\n",
       "      (11): Embedding(original_name=Embedding)\n",
       "      (12): Embedding(original_name=Embedding)\n",
       "      (13): Embedding(original_name=Embedding)\n",
       "      (14): Embedding(original_name=Embedding)\n",
       "      (15): Embedding(original_name=Embedding)\n",
       "      (16): Embedding(original_name=Embedding)\n",
       "      (17): Embedding(original_name=Embedding)\n",
       "      (18): Embedding(original_name=Embedding)\n",
       "      (19): Embedding(original_name=Embedding)\n",
       "      (20): Embedding(original_name=Embedding)\n",
       "      (21): Embedding(original_name=Embedding)\n",
       "      (22): Embedding(original_name=Embedding)\n",
       "      (23): Embedding(original_name=Embedding)\n",
       "      (24): Embedding(original_name=Embedding)\n",
       "      (25): Embedding(original_name=Embedding)\n",
       "      (26): Embedding(original_name=Embedding)\n",
       "      (27): Embedding(original_name=Embedding)\n",
       "      (28): Embedding(original_name=Embedding)\n",
       "      (29): Embedding(original_name=Embedding)\n",
       "      (30): Embedding(original_name=Embedding)\n",
       "      (31): Embedding(original_name=Embedding)\n",
       "      (32): Embedding(original_name=Embedding)\n",
       "      (33): Embedding(original_name=Embedding)\n",
       "      (34): Embedding(original_name=Embedding)\n",
       "      (35): Embedding(original_name=Embedding)\n",
       "      (36): Embedding(original_name=Embedding)\n",
       "      (37): Embedding(original_name=Embedding)\n",
       "      (38): Embedding(original_name=Embedding)\n",
       "      (39): Embedding(original_name=Embedding)\n",
       "      (40): Embedding(original_name=Embedding)\n",
       "      (41): Embedding(original_name=Embedding)\n",
       "      (42): Embedding(original_name=Embedding)\n",
       "      (43): Embedding(original_name=Embedding)\n",
       "      (44): Embedding(original_name=Embedding)\n",
       "      (45): Embedding(original_name=Embedding)\n",
       "      (46): Embedding(original_name=Embedding)\n",
       "      (47): Embedding(original_name=Embedding)\n",
       "      (48): Embedding(original_name=Embedding)\n",
       "      (49): Embedding(original_name=Embedding)\n",
       "      (50): Embedding(original_name=Embedding)\n",
       "      (51): Embedding(original_name=Embedding)\n",
       "      (52): Embedding(original_name=Embedding)\n",
       "      (53): Embedding(original_name=Embedding)\n",
       "      (54): Embedding(original_name=Embedding)\n",
       "      (55): Embedding(original_name=Embedding)\n",
       "      (56): Embedding(original_name=Embedding)\n",
       "      (57): Embedding(original_name=Embedding)\n",
       "      (58): Embedding(original_name=Embedding)\n",
       "      (59): Embedding(original_name=Embedding)\n",
       "      (60): Embedding(original_name=Embedding)\n",
       "      (61): Embedding(original_name=Embedding)\n",
       "      (62): Embedding(original_name=Embedding)\n",
       "      (63): Embedding(original_name=Embedding)\n",
       "      (64): Embedding(original_name=Embedding)\n",
       "      (65): Embedding(original_name=Embedding)\n",
       "      (66): Embedding(original_name=Embedding)\n",
       "      (67): Embedding(original_name=Embedding)\n",
       "      (68): Embedding(original_name=Embedding)\n",
       "      (69): Embedding(original_name=Embedding)\n",
       "      (70): Embedding(original_name=Embedding)\n",
       "      (71): Embedding(original_name=Embedding)\n",
       "      (72): Embedding(original_name=Embedding)\n",
       "      (73): Embedding(original_name=Embedding)\n",
       "      (74): Embedding(original_name=Embedding)\n",
       "      (75): Embedding(original_name=Embedding)\n",
       "      (76): Embedding(original_name=Embedding)\n",
       "      (77): Embedding(original_name=Embedding)\n",
       "      (78): Embedding(original_name=Embedding)\n",
       "      (79): Embedding(original_name=Embedding)\n",
       "      (80): Embedding(original_name=Embedding)\n",
       "      (81): Embedding(original_name=Embedding)\n",
       "      (82): Embedding(original_name=Embedding)\n",
       "      (83): Embedding(original_name=Embedding)\n",
       "      (84): Embedding(original_name=Embedding)\n",
       "      (85): Embedding(original_name=Embedding)\n",
       "      (86): Embedding(original_name=Embedding)\n",
       "      (87): Embedding(original_name=Embedding)\n",
       "      (88): Embedding(original_name=Embedding)\n",
       "      (89): Embedding(original_name=Embedding)\n",
       "      (90): Embedding(original_name=Embedding)\n",
       "      (91): Embedding(original_name=Embedding)\n",
       "      (92): Embedding(original_name=Embedding)\n",
       "      (93): Embedding(original_name=Embedding)\n",
       "      (94): Embedding(original_name=Embedding)\n",
       "      (95): Embedding(original_name=Embedding)\n",
       "      (96): Embedding(original_name=Embedding)\n",
       "      (97): Embedding(original_name=Embedding)\n",
       "      (98): Embedding(original_name=Embedding)\n",
       "      (99): Embedding(original_name=Embedding)\n",
       "      (100): Embedding(original_name=Embedding)\n",
       "      (101): Embedding(original_name=Embedding)\n",
       "      (102): Embedding(original_name=Embedding)\n",
       "      (103): Embedding(original_name=Embedding)\n",
       "      (104): Embedding(original_name=Embedding)\n",
       "      (105): Embedding(original_name=Embedding)\n",
       "      (106): Embedding(original_name=Embedding)\n",
       "      (107): Embedding(original_name=Embedding)\n",
       "      (108): Embedding(original_name=Embedding)\n",
       "    )\n",
       "    (mlp): Module(\n",
       "      original_name=Module\n",
       "      (mlp): Module(\n",
       "        original_name=Module\n",
       "        (0): Linear(original_name=Linear)\n",
       "        (1): ReLU(original_name=ReLU)\n",
       "        (2): Dropout(original_name=Dropout)\n",
       "        (3): Linear(original_name=Linear)\n",
       "        (4): ReLU(original_name=ReLU)\n",
       "        (5): Dropout(original_name=Dropout)\n",
       "        (6): Linear(original_name=Linear)\n",
       "        (7): ReLU(original_name=ReLU)\n",
       "        (8): Dropout(original_name=Dropout)\n",
       "        (9): Linear(original_name=Linear)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_model = torch.jit.trace(modify.cuda(), t)\n",
    "compiled_model = torch.compile(traced_model, backend=\"inductor\")\n",
    "compiled_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "modify_compiled = compiled_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-06 21:26:10 265017:265017 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-06 21:26:11 265017:265017 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-06 21:26:11 265017:265017 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "[W collection.cpp:936] Warning: Failed to recover relationship between all profiler and kineto events: 24676 vs. 0  reassociated. (function reassociate)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      12.247ms        28.29%      12.247ms       2.043us           0 b           0 b          5995  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us      10.419ms        24.06%      10.419ms      47.794us           0 b           0 b           218  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       9.540ms        22.03%       9.540ms       2.000us           0 b           0 b          4770  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us       7.876ms        18.19%       7.876ms     201.949us           0 b           0 b            39  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.291ms         2.98%       1.291ms       1.054us           0 b           0 b          1225  \n",
      "                                ampere_sgemm_128x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us     916.000us         2.12%     916.000us     916.000us           0 b           0 b             1  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     831.000us         1.92%     831.000us       7.694us           0 b           0 b           108  \n",
      "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us      72.000us         0.17%      72.000us      72.000us           0 b           0 b             1  \n",
      "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us      32.000us         0.07%      32.000us      32.000us           0 b           0 b             1  \n",
      "void at::native::(anonymous namespace)::fused_dropou...         0.00%       0.000us         0.00%       0.000us       0.000us      21.000us         0.05%      21.000us       7.000us           0 b           0 b             3  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 71.658ms\n",
      "Self CUDA time total: 43.296ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.profiler.profile(\n",
    "    activities=[\n",
    "        torch.profiler.ProfilerActivity.CUDA,  # 记录CUDA活动\n",
    "    ],\n",
    "    record_shapes=True,  # 记录操作输入和输出的形状\n",
    "    profile_memory=True,  # 记录内存使用情况\n",
    "    with_stack=True,  # 记录代码堆栈信息\n",
    "    on_trace_ready=torch.profiler.tensorboard_trace_handler('./log')  # 输出TensorBoard日志\n",
    ") as prof:\n",
    "    # 在profiler上下文管理器内执行模型\n",
    "    output = modify_compiled(t)\n",
    "    torch.cuda.synchronize()  # 确保所有CUDA操作都已完成\n",
    "\n",
    "# 输出分析结果\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pattern_replace_and_matcher_for_SingleMLP(traced,\n",
    "                                                  redundancy_part_slice,non_redundancy_part_slice,\n",
    "                                                  key_node_name,getitem_node_names,num_field,dim = 32,batch = 4096,match_func = None\n",
    "                                                ):\n",
    "  from torch.fx.passes.utils.matcher_utils import SubgraphMatcher\n",
    "  def _match(match,ori,pat):\n",
    "    return True \n",
    "  env  = utils.get_env(traced)\n",
    "  target_node = env[key_node_name]\n",
    "  target_node_mod = utils.get_target_mod(traced,target_node.target)\n",
    "  shape_info = target_node_mod.weight.data.shape\n",
    "  class PatternClass(torch.nn.Module):\n",
    "    def __init__(self,num_fields):\n",
    "      super().__init__()\n",
    "      self.num_fields = num_fields\n",
    "      # input_dim = dim * self.num_fields + int(self.num_fields * (self.num_fields - 1) / 2)\n",
    "      self.embeddings = torch.nn.ModuleList([\n",
    "              torch.nn.Embedding(1, 1) for _ in range(self.num_fields)\n",
    "          ])\n",
    "      self.mlp = nn.Linear(shape_info[0],shape_info[1])\n",
    "    def field_aware_interaction(self,field_aware_emb_list):\n",
    "      interaction = []\n",
    "      for i in range(self.num_fields - 1):\n",
    "          for j in range(i + 1, self.num_fields):\n",
    "              v_ij = field_aware_emb_list[j - 1][:, i, :]\n",
    "              v_ji = field_aware_emb_list[i][:, j, :]\n",
    "              dot = torch.sum(v_ij * v_ji, dim=1, keepdim=True)\n",
    "              interaction.append(dot)\n",
    "      return torch.cat(interaction, dim=1)  \n",
    "    def forward(self,x):\n",
    "      field_aware_emb_list = [self.embeddings[i](x) for i in range(self.num_fields)]\n",
    "      diag_embedding = field_aware_emb_list[0].flatten(start_dim=1)\n",
    "      ffm_out = self.field_aware_interaction(field_aware_emb_list[1:])\n",
    "      dnn_input = torch.cat([diag_embedding, ffm_out], dim=1)\n",
    "      return self.mlp(dnn_input)\n",
    "  pattern = PatternClass(num_field)  \n",
    "  pattern_trace = symbolic_trace(pattern)\n",
    "  pattern_graph = pattern_trace.graph\n",
    "  original_graph = traced.graph\n",
    "  matcher =  SubgraphMatcher(pattern_graph, match_output=False, match_placeholder=False,\n",
    "                              remove_overlapping_matches=True)\n",
    "  _matches = matcher.match(original_graph)\n",
    "  # 因为在过滤器中做了限制应该只有一个符合要求的\n",
    "  _matched = _matches[0]\n",
    "  pattern_env = utils.get_env(pattern_trace)\n",
    "  node_map = _matched.nodes_map\n",
    "  embed_names = [f'embeddings_{i}' for i in range(num_field)]\n",
    "  embed_node_list = [node_map[pattern_env[name]] for name in embed_names]\n",
    "  embed_node_module_list = [utils.get_target_mod(traced,embed_node.target) for embed_node in embed_node_list]\n",
    "  linear_node = node_map[pattern_env['mlp']]\n",
    "  linear_node_module = utils.get_target_mod(traced,linear_node.target)\n",
    "  linear_node_weight = linear_node_module.weight.data\n",
    "  linear_node_bias = linear_node_module.bias.data  \n",
    "  \n",
    "  \n",
    "  \n",
    "  class ReplacementClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.embeddings = torch.nn.ModuleList(embed_node_module_list)\n",
    "      self.embed_dim = self.embeddings[0].weight.data.shape[1]\n",
    "      self.num_fields = num_field\n",
    "      self.num_prefix = redundancy_part_slice[1].stop\n",
    "      self.num_sufix = self.num_fields - self.num_prefix\n",
    "      self.redency_weight_len = self.embed_dim * redundancy_part_slice[1].stop + self.num_prefix\n",
    "      redency_weight = linear_node_weight[:,:self.redency_weight_len]\n",
    "      unredency_weight = linear_node_weight[:,self.redency_weight_len:]\n",
    "      self.redency_linear = nn.Linear(redency_weight.shape[1],redency_weight.shape[0])\n",
    "      self.redency_linear.weight.data.copy_(redency_weight)\n",
    "      self.redency_linear.bias.data.copy_(linear_node_bias)\n",
    "      self.unredency_linear = nn.Linear(unredency_weight.shape[1],unredency_weight.shape[0],bias=False)\n",
    "      self.unredency_linear.weight.data.copy_(unredency_weight)\n",
    "    def field_aware_interaction(self,field_aware_emb_list):\n",
    "      interaction = []\n",
    "      for i in range(self.num_fields - 1):\n",
    "          for j in range(i + 1, self.num_fields):\n",
    "              v_ij = field_aware_emb_list[j - 1][:, i, :]\n",
    "              v_ji = field_aware_emb_list[i][:, j, :]\n",
    "              dot = torch.sum(v_ij * v_ji, dim=1, keepdim=True)\n",
    "              interaction.append(dot)\n",
    "      return torch.cat(interaction, dim=1)  \n",
    "    def forward(self,x):\n",
    "      field_aware_emb_list = [self.embeddings[i](x) for i in range(self.num_fields)]\n",
    "      diag_embedding = field_aware_emb_list[0].flatten(start_dim=1)\n",
    "      ffm_out = self.field_aware_interaction(field_aware_emb_list[1:])\n",
    "      dnn_input = torch.cat([diag_embedding, ffm_out], dim=1)\n",
    "      return self.redency_linear(dnn_input[0,:self.redency_weight_len]) + self.unredency_linear(dnn_input[:,self.redency_weight_len:])\n",
    "      \n",
    "  return pattern,ReplacementClass(),_match    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def workload_onn(num_field, prefix,dim = 64,l = [1024,512,256],batch = 4096):\n",
    "  print(f\"now gen workload of ONN with config: dim: {dim}, num_field: {num_field}, prefix: {prefix}\")\n",
    "  onn_model = onn.ONN([100 for i in range(num_field)],dim,l,0.1)\n",
    "\n",
    "  model_traced_ori = symbolic_trace(onn_model)\n",
    "  \n",
    "  onn_model_modify = onn.ONN([100 for i in range(num_field)],dim,l,0.1)\n",
    "  onn_model_traced_modify = symbolic_trace(onn_model_modify)\n",
    "  pattern,replace,match = gen_pattern_replace_and_matcher_for_SingleMLP(onn_model_traced_modify,\n",
    "                                                                      (0,slice(None,prefix,None)),(slice(None,None,None),slice(prefix,None,None)),\n",
    "                                                                      key_node_name = \"mlp_mlp_0\",\n",
    "                                                                      getitem_node_names = [\"getitem\",\"getitem_1\"],num_field=num_field,batch = batch,dim = dim)\n",
    "  matches = subgraph_rewriter.replace_pattern_with_filters(onn_model_traced_modify, pattern, replace,[match])\n",
    "  return model_traced_ori,onn_model_traced_modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genWorkload(num_field = 34 * 5,prefix = 29 * 5, batch = 4096, dim = 64):\n",
    "  ori_model_name = f'/home/yssun/pytorch-fm/torchfm/model/test_fx/exp/model_repo/onn/onn_{batch}_{num_field}_{prefix}_{dim}_ori.onnx'\n",
    "  modify_model_name = f'/home/yssun/pytorch-fm/torchfm/model/test_fx/exp/model_repo/onn_mlp/onn_{batch}_{num_field}_{prefix}_{dim}_modify.onnx'\n",
    "  ori, modify = workload_onn(num_field,prefix,dim,l = [1024,512,256],batch = batch)\n",
    "  # torch.onnx.export(ori,               # 模型 being run\n",
    "  #                 torch.randint(low=0, high=20, size=(batch,num_field), dtype=torch.long),                  # 模型输入 (or a tuple for multiple inputs)\n",
    "  #                 ori_model_name,        # 导出文件的文件名\n",
    "  #                 export_params=True, # 如果设置为True，则参数也会被导出。注意某些情况下参数可能无法被导出。\n",
    "  #                 opset_version=10,   # ONNX版本\n",
    "  #                 do_constant_folding=True,  # 是否执行常量折叠以优化模型\n",
    "  #                 input_names = ['input'],   # 输入的名称\n",
    "  #                 output_names = ['output'], # 输出的名称\n",
    "  #                 )\n",
    "  torch.onnx.export(modify,               # 模型 being run\n",
    "                  torch.randint(low=0, high=20, size=(batch,num_field), dtype=torch.long),                  # 模型输入 (or a tuple for multiple inputs)\n",
    "                  modify_model_name,        # 导出文件的文件名\n",
    "                  export_params=True, # 如果设置为True，则参数也会被导出。注意某些情况下参数可能无法被导出。\n",
    "                  opset_version=10,   # ONNX版本\n",
    "                  do_constant_folding=True,  # 是否执行常量折叠以优化模型\n",
    "                  input_names = ['input'],   # 输入的名称\n",
    "                  output_names = ['output'], # 输出的名称\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims= [32]\n",
    "batches = [1024,2048,4096]\n",
    "num_field_and_prefixs = [(34 ,29),(22 ,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of ONN with config: dim: 32, num_field: 34, prefix: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of ONN with config: dim: 32, num_field: 22, prefix: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of ONN with config: dim: 32, num_field: 34, prefix: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of ONN with config: dim: 32, num_field: 22, prefix: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of ONN with config: dim: 32, num_field: 34, prefix: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of ONN with config: dim: 32, num_field: 22, prefix: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for dim in dims:\n",
    "  for batch in batches:\n",
    "    for num_field,prefix in num_field_and_prefixs:\n",
    "      genWorkload(num_field=num_field,prefix=prefix,batch=batch,dim=dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorrt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
