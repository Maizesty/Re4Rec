{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../')\n",
    "import time\n",
    "import wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace success!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.fx import subgraph_rewriter, symbolic_trace\n",
    "import utils\n",
    "from torch.fx import Proxy, Graph, GraphModule\n",
    "from torch.fx.passes.utils.matcher_utils import SubgraphMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import time\n",
    "import torch._dynamo as dynamo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pattern_replace_and_matcher_for_MLP(traced,\n",
    "                                                  redency_part_slice,unredency_part_slice,\n",
    "                                                  key_node_name,match_func = None\n",
    "                                                ):\n",
    "  from torch.fx.passes.utils.matcher_utils import SubgraphMatcher\n",
    "\n",
    "\n",
    "  def _match(match,ori,pat):\n",
    "    return True \n",
    "  env  = utils.get_env(traced)\n",
    "  target_node = env[key_node_name]\n",
    "  target_node_mod = utils.get_target_mod(traced,target_node.target)\n",
    "  shape_info = target_node_mod.weight.data.shape\n",
    "  class PatternClass(torch.nn.Module):\n",
    "      def __init__(self):\n",
    "          super().__init__()\n",
    "          self.embed = torch.nn.Embedding(1, 1)\n",
    "          self.embed_output_dim = shape_info[1]\n",
    "          self.mlp = nn.Linear(shape_info[0],shape_info[1])\n",
    "\n",
    "\n",
    "      def forward(self,x):\n",
    "          x = self.embed(x).view(-1,self.embed_output_dim)\n",
    "          return self.mlp(x)\n",
    "  pattern = PatternClass()  \n",
    "  pattern_trace = symbolic_trace(pattern)\n",
    "  pattern_graph = pattern_trace.graph\n",
    "  original_graph = traced.graph\n",
    "  matcher =  SubgraphMatcher(pattern_graph, match_output=False, match_placeholder=False,\n",
    "                              remove_overlapping_matches=True)\n",
    "  _matches = matcher.match(original_graph)\n",
    "  match_filters = [_match if match_func is None else match_func]\n",
    "  _matches = [\n",
    "      m for m in _matches\n",
    "      if all(match_filter(m, original_graph, pattern_graph)\n",
    "              for match_filter in match_filters)\n",
    "  ]  \n",
    "  # 因为在过滤器中做了限制应该只有一个符合要求的\n",
    "  _matched = _matches[0]\n",
    "  pattern_env = utils.get_env(pattern_trace)\n",
    "  node_map = _matched.nodes_map\n",
    "  \n",
    "  embed_node = node_map[pattern_env['embed']]\n",
    "  embed_node_module = utils.get_target_mod(traced,embed_node.target)\n",
    "  \n",
    "  linear_node = node_map[pattern_env['mlp']]\n",
    "  linear_node_module = utils.get_target_mod(traced,linear_node.target)\n",
    "  linear_node_weight = linear_node_module.weight.data\n",
    "  linear_node_bias = linear_node_module.bias.data\n",
    "  \n",
    "  class ReplacementClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.embed = embed_node_module\n",
    "      self.embed_dim = self.embed.weight.data.shape[1]\n",
    "      self.redency_weight_len = self.embed_dim * redency_part_slice[1].stop\n",
    "      redency_weight = linear_node_weight[:,:self.redency_weight_len]\n",
    "      unredency_weight = linear_node_weight[:,self.redency_weight_len:]\n",
    "      self.unredency_weight_len = unredency_weight.shape[1]\n",
    "      self.redency_linear = nn.Linear(redency_weight.shape[1],redency_weight.shape[0])\n",
    "      self.redency_linear.weight.data.copy_(redency_weight)\n",
    "      self.redency_linear.bias.data.copy_(linear_node_bias)\n",
    "\n",
    "      self.unredency_linear = nn.Linear(unredency_weight.shape[1],unredency_weight.shape[0],bias=False)\n",
    "      self.unredency_linear.weight.data.copy_(unredency_weight)\n",
    "\n",
    "      \n",
    "\n",
    "    def forward(self,x):\n",
    "      redency_part = x[redency_part_slice] \n",
    "      unredency_part = x[unredency_part_slice] \n",
    "      return self.redency_linear(self.embed(redency_part).view(-1,self.redency_weight_len)) + self.unredency_linear(self.embed(unredency_part).view(-1,self.unredency_weight_len))\n",
    "      # return unredency_sum\n",
    "    \n",
    "  \n",
    "  return pattern,ReplacementClass(),_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def workload_wdl(num_field, prefix,dim = 64,l = [1024,512,256]):\n",
    "  print(f\"now gen workload of wdl with config: dim: {dim}, num_field: {num_field}, prefix: {prefix}\")\n",
    "  wdl_model_ori = wd.WideAndDeepModel([100 for i in range(num_field)],dim,l,0.1)\n",
    "  ori_traced = symbolic_trace(wdl_model_ori)\n",
    "  \n",
    "  wdl_model_modify = wd.WideAndDeepModel([100 for i in range(num_field)],dim,l,0.1)\n",
    "  modify_traced = symbolic_trace(wdl_model_modify)\n",
    "  pattern,replace,match = gen_pattern_replace_and_matcher_for_MLP(modify_traced,\n",
    "                                                                      (0,slice(None,prefix,None)),(slice(None,None,None),slice(prefix,None,None)),\n",
    "                                                                      \"mlp_mlp_0\")\n",
    "  matches = subgraph_rewriter.replace_pattern_with_filters(modify_traced, pattern, replace,[match])\n",
    "  return ori_traced,modify_traced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_and_variance_manual(data):\n",
    "    n = len(data)\n",
    "    mean = sum(data) / n\n",
    "    variance = sum((x - mean) ** 2 for x in data) / n\n",
    "    return mean, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_and_test(num_field = 22,prefix = 10, batch = 4096, dim = 32, workload_func = workload_wdl):\n",
    "  def run(model):\n",
    "    t = torch.randint(low=0, high=88, size=(batch,num_field), dtype=torch.long).cuda()\n",
    "    model.eval()\n",
    "    traced_model = torch.jit.trace(model.cuda(), t)\n",
    "    compiled_model = torch.compile(traced_model, backend=\"inductor\")\n",
    "    compiled_model.eval()\n",
    "    for i in range(10):\n",
    "       soutput = compiled_model(t)\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    for i in range(100):\n",
    "        soutput = compiled_model(t)\n",
    "    end = time.time()        \n",
    "    print(f\"cal time : {(end - start)/100 * 1000}\")\n",
    "  print(f\"now gen workload of fm with config: dim: {dim}, num_field: {num_field}, prefix: {prefix}, batch :{batch}\")\n",
    "  ori, modify = workload_func(num_field,prefix,dim)\n",
    "  run(ori)\n",
    "  run(modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 110, prefix: 50, batch :1024\n",
      "now gen workload of wdl with config: dim: 32, num_field: 110, prefix: 50\n",
      "cal time : 0.3018379211425781\n",
      "cal time : 0.3959083557128906\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 1024, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 110, prefix: 50, batch :2048\n",
      "now gen workload of wdl with config: dim: 32, num_field: 110, prefix: 50\n",
      "cal time : 0.47260522842407227\n",
      "cal time : 0.4111790657043457\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 2048, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 110, prefix: 50, batch :4096\n",
      "now gen workload of wdl with config: dim: 32, num_field: 110, prefix: 50\n",
      "cal time : 0.9473919868469238\n",
      "cal time : 0.8221173286437988\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 110, prefix: 50, batch :1024\n",
      "now gen workload of wdl with config: dim: 64, num_field: 110, prefix: 50\n",
      "cal time : 0.4098963737487793\n",
      "cal time : 0.39061546325683594\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 1024, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 110, prefix: 50, batch :2048\n",
      "now gen workload of wdl with config: dim: 64, num_field: 110, prefix: 50\n",
      "cal time : 0.8155655860900879\n",
      "cal time : 0.6353068351745605\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 2048, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 110, prefix: 50, batch :4096\n",
      "now gen workload of wdl with config: dim: 64, num_field: 110, prefix: 50\n",
      "cal time : 1.7202115058898926\n",
      "cal time : 1.236124038696289\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 4096, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 170, prefix: 145, batch :1024\n",
      "now gen workload of wdl with config: dim: 32, num_field: 170, prefix: 145\n",
      "cal time : 0.3360939025878906\n",
      "cal time : 0.3961062431335449\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 1024, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 170, prefix: 145, batch :2048\n",
      "now gen workload of wdl with config: dim: 32, num_field: 170, prefix: 145\n",
      "cal time : 0.6471657752990723\n",
      "cal time : 0.39620161056518555\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 2048, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 170, prefix: 145, batch :4096\n",
      "now gen workload of wdl with config: dim: 32, num_field: 170, prefix: 145\n",
      "cal time : 1.366870403289795\n",
      "cal time : 0.45939207077026367\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 170, prefix: 145, batch :1024\n",
      "now gen workload of wdl with config: dim: 64, num_field: 170, prefix: 145\n",
      "cal time : 0.6141996383666992\n",
      "cal time : 0.3941512107849121\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 1024, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 170, prefix: 145, batch :2048\n",
      "now gen workload of wdl with config: dim: 64, num_field: 170, prefix: 145\n",
      "cal time : 1.1839914321899414\n",
      "cal time : 0.40170907974243164\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 2048, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 170, prefix: 145, batch :4096\n",
      "now gen workload of wdl with config: dim: 64, num_field: 170, prefix: 145\n",
      "cal time : 2.5402045249938965\n",
      "cal time : 0.6920075416564941\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 4096, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 10, batch :4096\n",
      "now gen workload of wdl with config: dim: 32, num_field: 100, prefix: 10\n",
      "cal time : 0.8940577507019043\n",
      "cal time : 1.0836386680603027\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 10, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 20, batch :4096\n",
      "now gen workload of wdl with config: dim: 32, num_field: 100, prefix: 20\n",
      "cal time : 0.8911347389221191\n",
      "cal time : 0.9838080406188966\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 20, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 30, batch :4096\n",
      "now gen workload of wdl with config: dim: 32, num_field: 100, prefix: 30\n",
      "cal time : 0.8811545372009277\n",
      "cal time : 0.9004735946655273\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 30, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 40, batch :4096\n",
      "now gen workload of wdl with config: dim: 32, num_field: 100, prefix: 40\n",
      "cal time : 0.8764505386352539\n",
      "cal time : 0.8038806915283203\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 40, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 50, batch :4096\n",
      "now gen workload of wdl with config: dim: 32, num_field: 100, prefix: 50\n",
      "cal time : 0.8893251419067383\n",
      "cal time : 0.7136321067810059\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 50, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 60, batch :4096\n",
      "now gen workload of wdl with config: dim: 32, num_field: 100, prefix: 60\n",
      "cal time : 0.8905410766601562\n",
      "cal time : 0.6316924095153809\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 60, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 70, batch :4096\n",
      "now gen workload of wdl with config: dim: 32, num_field: 100, prefix: 70\n",
      "cal time : 0.8832216262817383\n",
      "cal time : 0.49904584884643555\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 70, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 80, batch :4096\n",
      "now gen workload of wdl with config: dim: 32, num_field: 100, prefix: 80\n",
      "cal time : 0.8940815925598145\n",
      "cal time : 0.39601802825927734\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 80, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 90, batch :4096\n",
      "now gen workload of wdl with config: dim: 32, num_field: 100, prefix: 90\n",
      "cal time : 0.9016704559326172\n",
      "cal time : 0.39067983627319336\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 90, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 99, batch :4096\n",
      "now gen workload of wdl with config: dim: 32, num_field: 100, prefix: 99\n",
      "cal time : 0.8880877494812012\n",
      "cal time : 0.3796529769897461\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 99, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genWorkload(num_field = 34 * 5,prefix = 29 * 5, batch = 4096, dim = 64):\n",
    "  ori_model_name = f'/home/yssun/pytorch-fm/torchfm/model/test_fx/exp/model_repo/wdl/wdl_{batch}_{num_field}_{prefix}_{dim}_ori.onnx'\n",
    "  modify_model_name = f'/home/yssun/pytorch-fm/torchfm/model/test_fx/exp/model_repo/wdl/wdl_{batch}_{num_field}_{prefix}_{dim}_modify.onnx'\n",
    "  ori, modify = workload_wdl(num_field = num_field,prefix = prefix,  dim = dim)\n",
    "  torch.onnx.export(ori,               # 模型 being run\n",
    "                  torch.randint(low=0, high=20, size=(batch,num_field), dtype=torch.long),                  # 模型输入 (or a tuple for multiple inputs)\n",
    "                  ori_model_name,        # 导出文件的文件名\n",
    "                  export_params=True, # 如果设置为True，则参数也会被导出。注意某些情况下参数可能无法被导出。\n",
    "                  opset_version=10,   # ONNX版本\n",
    "                  do_constant_folding=True,  # 是否执行常量折叠以优化模型\n",
    "                  input_names = ['input'],   # 输入的名称\n",
    "                  output_names = ['output'], # 输出的名称\n",
    "                  )\n",
    "  torch.onnx.export(modify,               # 模型 being run\n",
    "                  torch.randint(low=0, high=20, size=(batch,num_field), dtype=torch.long),                  # 模型输入 (or a tuple for multiple inputs)\n",
    "                  modify_model_name,        # 导出文件的文件名\n",
    "                  export_params=True, # 如果设置为True，则参数也会被导出。注意某些情况下参数可能无法被导出。\n",
    "                  opset_version=10,   # ONNX版本\n",
    "                  do_constant_folding=True,  # 是否执行常量折叠以优化模型\n",
    "                  input_names = ['input'],   # 输入的名称\n",
    "                  output_names = ['output'], # 输出的名称\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims= [32]\n",
    "batches = [1024,2048,4096]\n",
    "num_field_and_prefixs = [(34 * 5,29*5),(22 * 5,10 * 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of wdl with config: dim: 32, num_field: 170, prefix: 145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1314: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of wdl with config: dim: 32, num_field: 110, prefix: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1314: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of wdl with config: dim: 32, num_field: 170, prefix: 145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1314: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of wdl with config: dim: 32, num_field: 110, prefix: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1314: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of wdl with config: dim: 32, num_field: 170, prefix: 145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1314: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of wdl with config: dim: 32, num_field: 110, prefix: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1314: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for dim in dims:\n",
    "  for batch in batches:\n",
    "    for num_field,prefix in num_field_and_prefixs:\n",
    "      genWorkload(num_field=num_field,prefix=prefix,batch=batch,dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims= [32]\n",
    "batches = [1024,2048,4096]\n",
    "num_field_and_prefixs = [(34 ,29),(22 ,10 ),(34 * 5,29*5),(22 * 5,10 * 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of wdl with config: dim: 32, num_field: 34, prefix: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of wdl with config: dim: 32, num_field: 22, prefix: 10\n",
      "now gen workload of wdl with config: dim: 32, num_field: 34, prefix: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of wdl with config: dim: 32, num_field: 22, prefix: 10\n",
      "now gen workload of wdl with config: dim: 32, num_field: 34, prefix: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of wdl with config: dim: 32, num_field: 22, prefix: 10\n"
     ]
    }
   ],
   "source": [
    "for dim in dims:\n",
    "  for batch in batches:\n",
    "    for num_field,prefix in num_field_and_prefixs:\n",
    "      genWorkload(num_field=num_field,prefix=prefix,batch=batch,dim=dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorrt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
