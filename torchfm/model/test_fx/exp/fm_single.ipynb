{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../')\n",
    "\n",
    "import fm\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace success!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.fx import subgraph_rewriter, symbolic_trace\n",
    "import utils\n",
    "import torch.fx as fx\n",
    "from torch.fx import Proxy, Graph, GraphModule\n",
    "from torch.fx.passes.utils.matcher_utils import SubgraphMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch._dynamo as dynamo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pattern_replace_and_matcher_for_FM_reduce1(traced,\n",
    "                                                  redency_part_slice,unredency_part_slice,\n",
    "                                                  match_func = None\n",
    "                                                ):\n",
    "  from torch.fx.passes.utils.matcher_utils import SubgraphMatcher\n",
    "\n",
    "  class PatternClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.embed = torch.nn.Embedding(1, 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "      x = self.embed(x)\n",
    "      square_of_sum = torch.sum(x, dim=1) ** 2\n",
    "      sum_of_square = torch.sum(x ** 2, dim=1)\n",
    "      ix = square_of_sum - sum_of_square    \n",
    "      ix = torch.sum(ix, dim=1, keepdim=True)  \n",
    "      return 0.5 * ix\n",
    "  def _match(match,ori,pat):\n",
    "    return True \n",
    "  # env  = utils.get_env(traced)\n",
    "  # target_node = env[target_node_name]\n",
    "  # target_node_mod = utils.get_target_mod(traced,target_node_name,\"_\")\n",
    "  pattern = PatternClass()  \n",
    "  pattern_trace = symbolic_trace(pattern)\n",
    "  pattern_graph = pattern_trace.graph\n",
    "  original_graph = traced.graph\n",
    "  matcher =  SubgraphMatcher(pattern_graph, match_output=False, match_placeholder=False,\n",
    "                              remove_overlapping_matches=True)\n",
    "  _matches = matcher.match(original_graph)\n",
    "  match_filters = [_match if match_func is None else match_func]\n",
    "  _matches = [\n",
    "      m for m in _matches\n",
    "      if all(match_filter(m, original_graph, pattern_graph)\n",
    "              for match_filter in match_filters)\n",
    "  ]  \n",
    "  # 因为在过滤器中做了限制应该只有一个符合要求的\n",
    "  _matched = _matches[0]\n",
    "  pattern_env = utils.get_env(pattern_trace)\n",
    "  node_map = _matched.nodes_map\n",
    "  \n",
    "  embed_node = node_map[pattern_env['embed']]\n",
    "  embed_node_module = utils.get_target_mod(traced,embed_node.target)\n",
    "  \n",
    "\n",
    "  \n",
    "  \n",
    "  class ReplacementClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      embedding_config = embed_node_module.weight.data.shape\n",
    "      self.embed = nn.Embedding(embedding_config[0],embedding_config[1])\n",
    "      self.embed.weight.data.copy_(embed_node_module.weight.data)\n",
    "    def forward(self,x):\n",
    "      embed = self.embed(x)\n",
    "      redency_embed = embed[redency_part_slice] \n",
    "      unredency_embed = embed[unredency_part_slice] \n",
    "      redency_embed_sum = torch.sum(redency_embed,dim=0)\n",
    "      unredency_embed_sum = torch.sum(unredency_embed,dim=1)\n",
    "      square_of_sum = (redency_embed_sum + unredency_embed_sum) ** 2\n",
    "      sum_of_square = torch.sum(embed ** 2,dim=1)\n",
    "      ix = square_of_sum - sum_of_square\n",
    "      ix = torch.sum(ix,dim = 1,keepdim=True)\n",
    "      return 0.5 * ix\n",
    "    \n",
    "  \n",
    "  return pattern,ReplacementClass(),_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def workload_FM_reduce1(num_field, prefix,dim = 64):\n",
    "  # print(f\"now gen workload of wdl with config: dim: {dim}, num_field: {num_field}, prefix: {prefix}\")\n",
    "  model_ori = fm.FactorizationMachineModel([100 for i in range(num_field)],dim,)\n",
    "  ori_traced = symbolic_trace(model_ori)\n",
    "  \n",
    "  model_modify = fm.FactorizationMachineModel([100 for i in range(num_field)],dim,)\n",
    "  modify_traced = symbolic_trace(model_modify)\n",
    "  pattern,replace,match = gen_pattern_replace_and_matcher_for_FM_reduce1(modify_traced,\n",
    "                                                                      (0,slice(None,prefix,None)),(slice(None,None,None),slice(prefix,None,None)),\n",
    "                                                                      )\n",
    "  matches = subgraph_rewriter.replace_pattern_with_filters(modify_traced, pattern, replace,[match])\n",
    "  return ori_traced,modify_traced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_and_variance_manual(data):\n",
    "    n = len(data)\n",
    "    mean = sum(data) / n\n",
    "    variance = sum((x - mean) ** 2 for x in data) / n\n",
    "    return mean, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_and_test(num_field = 22,prefix = 10, batch = 4096, dim = 32, workload_func = workload_FM_reduce1):\n",
    "  def run(model):\n",
    "    traced_model = torch.jit.trace(model, torch.randint(low=0, high=88, size=(batch,num_field), dtype=torch.long))\n",
    "    compiled_model = torch.compile(traced_model, backend=\"inductor\")\n",
    "    compiled_model.eval()\n",
    "    total_time = 0\n",
    "    total_time = []\n",
    "    t = torch.randint(low=0, high=88, size=(batch ,num_field), dtype=torch.long)\n",
    "\n",
    "    with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "        with record_function(\"model_inference\"):\n",
    "          for i in range(100):\n",
    "              start_time = time.time()  # 开始计时\n",
    "              with torch.no_grad():\n",
    "                soutput = compiled_model(t)\n",
    "              end_time = time.time()  # 结束计时\n",
    "              \n",
    "              # 计算并打印函数执行所需的时间\n",
    "              elapsed_time = end_time - start_time\n",
    "              total_time.append(elapsed_time * 1000)\n",
    "    print(calculate_mean_and_variance_manual(total_time))\n",
    "  print(f\"now gen workload of fm with config: dim: {dim}, num_field: {num_field}, prefix: {prefix}, batch :{batch}\")\n",
    "  ori, modify = workload_func(num_field,prefix,dim)\n",
    "  run(ori)\n",
    "  run(modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 22, prefix: 10, batch :1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:08 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:08 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:08 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9221982955932617, 0.1963539204780318)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:09 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:09 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:09 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9056496620178223, 0.1058287719558848)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 1024, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 22, prefix: 10, batch :2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:09 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:10 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:10 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0509753227233887, 0.08340551391370354)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:10 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:10 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:10 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.099252700805664, 0.08868707595865999)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 2048, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 22, prefix: 10, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:10 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:11 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:11 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.617271900177002, 0.18122039938930357)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:11 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:11 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:11 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.1252918243408203, 0.3433405939631484)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 22, prefix: 10, batch :8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:12 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:12 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:12 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.2750005722045898, 0.22652618852134765)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:12 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:12 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:12 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.3448858261108398, 0.3367337490317368)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 8192, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 22, prefix: 10, batch :1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:13 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:13 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:13 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9659194946289062, 0.06108847574068932)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:13 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:14 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:14 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9805941581726074, 0.10028525832126434)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 1024, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 22, prefix: 10, batch :2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:14 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:14 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:14 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9278750419616699, 0.06255252434925751)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:15 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:15 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:15 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.996551513671875, 0.13302601100804168)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 2048, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 22, prefix: 10, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:15 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:15 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:15 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.2411952018737793, 0.14192630303000442)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:16 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:16 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.28767728805542, 0.17845468971131595)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:16 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 4096, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 22, prefix: 10, batch :8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:16 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:17 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:17 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.1631598472595215, 0.3482404149224294)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:17 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:18 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:18 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13.188176155090332, 0.3715262796276875)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 8192, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 34, prefix: 29, batch :1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:19 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:19 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:19 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9094405174255371, 0.050859313722639854)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:19 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:19 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:19 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8609294891357422, 0.08673561637806415)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34,prefix = 29, batch = 1024, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 34, prefix: 29, batch :2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:20 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:20 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:20 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9444642066955566, 0.1342105561604967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:20 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:20 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:20 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9727883338928223, 0.19623622626454562)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34,prefix = 29, batch = 2048, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 34, prefix: 29, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:21 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:21 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:21 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.080317497253418, 0.08150507185291644)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:22 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:22 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:22 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.1264276504516602, 0.23350949070390925)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34,prefix = 29, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 34, prefix: 29, batch :8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:22 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:23 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:23 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2025-02-07 20:04:23 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.6370749473571777, 0.3104480423360201)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:23 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:23 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.4743781089782715, 0.30109305100154415)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34,prefix = 29, batch = 8192, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 34, prefix: 29, batch :1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:24 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:24 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:24 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0626029968261719, 0.08127375881485932)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:24 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:24 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:24 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9855031967163086, 0.08799419845217926)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34,prefix = 29, batch = 1024, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 34, prefix: 29, batch :2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:25 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:25 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:25 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0665202140808105, 0.07897910074348147)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:25 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:25 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:25 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0752272605895996, 0.11434115669430867)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34,prefix = 29, batch = 2048, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 34, prefix: 29, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:26 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:26 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:26 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.585986614227295, 0.22572190220557786)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:26 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:26 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:26 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.573479175567627, 0.22574380338369338)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34,prefix = 29, batch = 4096, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 34, prefix: 29, batch :8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:27 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:29 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:29 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20.481374263763428, 0.30896100826680595)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:30 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:32 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:32 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20.51579713821411, 1.462477009107488)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34,prefix = 29, batch = 8192, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 110, prefix: 50, batch :1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:32 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:32 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:32 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.3286662101745605, 0.12576482965300784)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:33 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:33 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:33 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.3161301612854004, 0.1737726647377258)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 1024, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 110, prefix: 50, batch :2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:33 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:34 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:34 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2025-02-07 20:04:34 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.467900276184082, 0.2783992833656157)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:34 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:34 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.4834928512573242, 0.11883949307502917)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 2048, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 110, prefix: 50, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:35 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:36 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:36 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17.618253231048584, 1.3054100301076232)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:37 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:38 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:38 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17.115893363952637, 0.6386744367091524)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 110, prefix: 50, batch :8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:39 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:43 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:43 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33.158440589904785, 1.5412550705832473)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:43 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32.68824815750122, 0.7578509398342703)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:46 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:46 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 8192, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 110, prefix: 50, batch :1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:47 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:47 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:47 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.1198248863220215, 0.09256259283461077)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:47 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:48 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:48 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.8766355514526367, 0.2289112357857448)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 1024, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 110, prefix: 50, batch :2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:48 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:50 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:50 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17.4284029006958, 0.24008303737446113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:50 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:52 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:52 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16.99333667755127, 0.2922679659377536)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 2048, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 110, prefix: 50, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:53 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:04:56 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:04:56 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32.55747079849243, 0.587663886625478)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:04:57 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:05:00 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:05:00 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32.880237102508545, 1.5573242345624294)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 4096, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 110, prefix: 50, batch :8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:05:01 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:05:07 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:05:07 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61.17898225784302, 2.87885077270289)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:05:08 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:05:14 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:05:14 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61.0917329788208, 1.1074108789443926)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 8192, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 170, prefix: 145, batch :1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:05:14 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:05:14 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:05:14 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.9487357139587402, 0.2523714955430023)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:05:15 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:05:15 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:05:15 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.5735507011413574, 0.2062227251542481)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 1024, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 170, prefix: 145, batch :2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:05:15 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:05:16 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:05:16 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.4594712257385254, 1.9155059486081427)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:05:16 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:05:18 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:05:18 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12.804210186004639, 0.7020408069990935)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 2048, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 170, prefix: 145, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:05:18 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:05:21 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:05:21 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25.080430507659912, 0.8914135950988111)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:05:21 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:05:24 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:05:24 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24.24811601638794, 1.0595212341456772)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 170, prefix: 145, batch :8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:05:24 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:05:29 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:05:29 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47.20960855484009, 1.6093451772292156)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:05:30 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46.67426824569702, 1.5613369774371222)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:05:35 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:05:35 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 8192, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 170, prefix: 145, batch :1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:05:35 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:05:36 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:05:36 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13.247509002685547, 0.5384152048918622)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:05:37 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:05:38 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:05:38 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12.751352787017822, 0.19957413698534765)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 1024, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 170, prefix: 145, batch :2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:05:39 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:05:41 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:05:41 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25.359666347503662, 0.5181861767766804)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:05:42 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:05:44 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:05:44 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25.23780107498169, 0.7164086531417979)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 2048, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 170, prefix: 145, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:05:45 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:05:50 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:05:50 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48.39134216308594, 1.8857420684526005)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:05:50 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:05:55 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:05:55 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47.80450105667114, 1.3540197470490511)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 4096, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 170, prefix: 145, batch :8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:05:56 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:06:05 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:06:05 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91.73617124557495, 2.8407068895091925)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:06:06 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91.968092918396, 1.929563070484619)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:06:15 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:06:15 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 8192, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pattern_replace_and_matcher_for_FM_reduce2(traced,\n",
    "                                                  redency_part_slice,unredency_part_slice,\n",
    "                                                  match_func = None\n",
    "                                                ):\n",
    "  from torch.fx.passes.utils.matcher_utils import SubgraphMatcher\n",
    "\n",
    "  class PatternClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.embed = torch.nn.Embedding(1, 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "      x = self.embed(x)\n",
    "      square_of_sum = torch.sum(x, dim=1) ** 2\n",
    "      sum_of_square = torch.sum(x ** 2, dim=1)\n",
    "      ix = square_of_sum - sum_of_square    \n",
    "      ix = torch.sum(ix, dim=1, keepdim=True)  \n",
    "      return 0.5 * ix\n",
    "  def _match(match,ori,pat):\n",
    "    return True \n",
    "  # env  = utils.get_env(traced)\n",
    "  # target_node = env[target_node_name]\n",
    "  # target_node_mod = utils.get_target_mod(traced,target_node_name,\"_\")\n",
    "  pattern = PatternClass()  \n",
    "  pattern_trace = symbolic_trace(pattern)\n",
    "  pattern_graph = pattern_trace.graph\n",
    "  original_graph = traced.graph\n",
    "  matcher =  SubgraphMatcher(pattern_graph, match_output=False, match_placeholder=False,\n",
    "                              remove_overlapping_matches=True)\n",
    "  _matches = matcher.match(original_graph)\n",
    "  match_filters = [_match if match_func is None else match_func]\n",
    "  _matches = [\n",
    "      m for m in _matches\n",
    "      if all(match_filter(m, original_graph, pattern_graph)\n",
    "              for match_filter in match_filters)\n",
    "  ]  \n",
    "  # 因为在过滤器中做了限制应该只有一个符合要求的\n",
    "  _matched = _matches[0]\n",
    "  pattern_env = utils.get_env(pattern_trace)\n",
    "  node_map = _matched.nodes_map\n",
    "  \n",
    "  embed_node = node_map[pattern_env['embed']]\n",
    "  embed_node_module = utils.get_target_mod(traced,embed_node.target)\n",
    "  \n",
    "\n",
    "  \n",
    "  \n",
    "  class ReplacementClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      embedding_config = embed_node_module.weight.data.shape\n",
    "      self.embed = nn.Embedding(embedding_config[0],embedding_config[1])\n",
    "      self.embed.weight.data.copy_(embed_node_module.weight.data)\n",
    "    def forward(self,x):\n",
    "      embed = self.embed(x)\n",
    "      square_of_sum = torch.sum(embed,dim=1) ** 2\n",
    "      square = embed ** 2\n",
    "      r_square = square[redency_part_slice] \n",
    "      n_square = square[unredency_part_slice] \n",
    "      \n",
    "      sum_of_square = torch.sum(r_square,dim=0) + torch.sum(n_square,dim=1)\n",
    "      ix = square_of_sum - sum_of_square\n",
    "      ix = torch.sum(ix,dim = 1,keepdim=True)\n",
    "      return 0.5 * ix\n",
    "    \n",
    "  \n",
    "  return pattern,ReplacementClass(),_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def workload_FM_reduce2(num_field, prefix,dim = 64):\n",
    "  # print(f\"now gen workload of wdl with config: dim: {dim}, num_field: {num_field}, prefix: {prefix}\")\n",
    "  model_ori = fm.FactorizationMachineModel([100 for i in range(num_field)],dim,)\n",
    "  ori_traced = symbolic_trace(model_ori)\n",
    "  \n",
    "  model_modify = fm.FactorizationMachineModel([100 for i in range(num_field)],dim,)\n",
    "  modify_traced = symbolic_trace(model_modify)\n",
    "  pattern,replace,match = gen_pattern_replace_and_matcher_for_FM_reduce2(modify_traced,\n",
    "                                                                      (0,slice(None,prefix,None)),(slice(None,None,None),slice(prefix,None,None)),\n",
    "                                                                      )\n",
    "  matches = subgraph_rewriter.replace_pattern_with_filters(modify_traced, pattern, replace,[match])\n",
    "  return ori_traced,modify_traced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 22, prefix: 10, batch :1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:11:34 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:11:34 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:11:34 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.844719409942627, 0.07318978020407485)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:11:34 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:11:35 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:11:35 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8950543403625488, 0.11791012827302438)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 1024, dim = 32,workload_func = workload_FM_reduce2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 22, prefix: 10, batch :2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:11:38 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:11:38 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:11:38 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0619401931762695, 0.11835994030207075)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:11:38 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:11:38 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:11:38 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0939526557922363, 0.13465284570770564)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 2048, dim = 32,workload_func = workload_FM_reduce2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 22, prefix: 10, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:11:40 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:11:40 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:11:40 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.08062744140625, 0.1380503698328539)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:11:41 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:11:41 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:11:41 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.1834907531738281, 0.21335662686396972)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 4096, dim = 32,workload_func = workload_FM_reduce2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 22, prefix: 10, batch :8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:11:42 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:11:42 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:11:42 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.2988734245300293, 0.5169148785796551)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:11:42 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:11:43 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:11:43 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.3092923164367676, 0.32555031254446476)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 8192, dim = 32,workload_func = workload_FM_reduce2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 22, prefix: 10, batch :1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:11:45 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:11:45 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:11:45 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9556055068969727, 0.09794485947622888)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:11:46 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:11:46 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:11:46 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.1289572715759277, 0.10035044021492467)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 1024, dim = 64,workload_func = workload_FM_reduce2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 22, prefix: 10, batch :2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:11:48 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:11:48 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:11:48 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.144254207611084, 0.46603278676116133)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:11:48 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:11:48 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:11:48 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.1577343940734863, 0.1289890097893931)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 2048, dim = 64,workload_func = workload_FM_reduce2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 22, prefix: 10, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:11:50 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:11:50 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:11:50 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2025-02-07 20:11:51 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.4400434494018555, 0.42019236727810494)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:11:51 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:11:51 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3.9150476455688477, 0.13524026996947214)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 4096, dim = 64,workload_func = workload_FM_reduce2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 22, prefix: 10, batch :8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:11:52 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:11:54 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:11:54 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11.83910608291626, 0.3466949188975832)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:11:54 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:11:55 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:11:55 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10.040671825408936, 15.84861094403891)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 8192, dim = 64,workload_func = workload_FM_reduce2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 34, prefix: 29, batch :1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:13:12 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:13:12 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:13:12 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.928804874420166, 0.07339051841768196)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:13:12 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:13:12 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:13:12 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9196305274963379, 0.09307828497071569)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34,prefix = 29, batch = 1024, dim = 32,workload_func = workload_FM_reduce2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 34, prefix: 29, batch :2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:13:15 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:13:15 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:13:15 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9540772438049316, 0.11285542620385058)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:13:15 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:13:15 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:13:15 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0531353950500488, 0.16871785311991516)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34,prefix = 29, batch = 2048, dim = 32,workload_func = workload_FM_reduce2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 34, prefix: 29, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:13:17 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:13:17 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:13:17 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.2390708923339844, 0.21112961908329453)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:13:17 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:13:18 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:13:18 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.1996960639953613, 0.18160925480401602)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34,prefix = 29, batch = 4096, dim = 32,workload_func = workload_FM_reduce2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 34, prefix: 29, batch :8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:13:19 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:13:19 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:13:19 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "STAGE:2025-02-07 20:13:19 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.6350722312927246, 0.2452254744810034)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:13:20 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:13:20 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7.730302810668945, 11.33169947265742)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34,prefix = 29, batch = 8192, dim = 32,workload_func = workload_FM_reduce2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 34, prefix: 29, batch :1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:13:22 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:13:22 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:13:22 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0845088958740234, 0.07830757695046486)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:13:22 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:13:22 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:13:22 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.1223959922790527, 0.20863201036149803)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34,prefix = 29, batch = 1024, dim = 64,workload_func = workload_FM_reduce2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 34, prefix: 29, batch :2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:13:25 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:13:25 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:13:25 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.1208415031433105, 0.19271494508643627)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:13:26 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:13:26 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:13:26 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.1440587043762207, 0.17530421638980442)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34,prefix = 29, batch = 2048, dim = 64,workload_func = workload_FM_reduce2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 34, prefix: 29, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:14:57 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:14:58 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:14:58 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9.788069725036621, 5.194651737406275)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:14:58 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:14:59 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:14:59 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10.40283203125, 0.22005791097399197)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34,prefix = 29, batch = 4096, dim = 64,workload_func = workload_FM_reduce2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 34, prefix: 29, batch :8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:13:31 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:13:33 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:13:33 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19.318530559539795, 22.69540414806086)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:13:34 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:13:36 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:13:36 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21.52268409729004, 2.0825404998049635)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 34,prefix = 29, batch = 8192, dim = 64,workload_func = workload_FM_reduce2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pattern_replace_and_matcher_for_FM_reduce(traced,\n",
    "                                                  redency_part_slice,unredency_part_slice,\n",
    "                                                  match_func = None\n",
    "                                                ):\n",
    "  from torch.fx.passes.utils.matcher_utils import SubgraphMatcher\n",
    "\n",
    "  class PatternClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.embed = torch.nn.Embedding(1, 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "      x = self.embed(x)\n",
    "      square_of_sum = torch.sum(x, dim=1) ** 2\n",
    "      sum_of_square = torch.sum(x ** 2, dim=1)\n",
    "      ix = square_of_sum - sum_of_square    \n",
    "      ix = torch.sum(ix, dim=1, keepdim=True)  \n",
    "      return 0.5 * ix\n",
    "  def _match(match,ori,pat):\n",
    "    return True \n",
    "  # env  = utils.get_env(traced)\n",
    "  # target_node = env[target_node_name]\n",
    "  # target_node_mod = utils.get_target_mod(traced,target_node_name,\"_\")\n",
    "  pattern = PatternClass()  \n",
    "  pattern_trace = symbolic_trace(pattern)\n",
    "  pattern_graph = pattern_trace.graph\n",
    "  original_graph = traced.graph\n",
    "  matcher =  SubgraphMatcher(pattern_graph, match_output=False, match_placeholder=False,\n",
    "                              remove_overlapping_matches=True)\n",
    "  _matches = matcher.match(original_graph)\n",
    "  match_filters = [_match if match_func is None else match_func]\n",
    "  _matches = [\n",
    "      m for m in _matches\n",
    "      if all(match_filter(m, original_graph, pattern_graph)\n",
    "              for match_filter in match_filters)\n",
    "  ]  \n",
    "  # 因为在过滤器中做了限制应该只有一个符合要求的\n",
    "  _matched = _matches[0]\n",
    "  pattern_env = utils.get_env(pattern_trace)\n",
    "  node_map = _matched.nodes_map\n",
    "  \n",
    "  embed_node = node_map[pattern_env['embed']]\n",
    "  embed_node_module = utils.get_target_mod(traced,embed_node.target)\n",
    "  \n",
    "\n",
    "  \n",
    "  \n",
    "  class ReplacementClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      embedding_config = embed_node_module.weight.data.shape\n",
    "      self.embed = nn.Embedding(embedding_config[0],embedding_config[1])\n",
    "      self.embed.weight.data.copy_(embed_node_module.weight.data)\n",
    "    def forward(self,x):\n",
    "      embed = self.embed(x)\n",
    "      redency_embed = embed[redency_part_slice] \n",
    "      unredency_embed = embed[unredency_part_slice] \n",
    "      redency_embed_sum = torch.sum(redency_embed,dim=0)\n",
    "      unredency_embed_sum = torch.sum(unredency_embed,dim=1)\n",
    "      square_of_sum = (redency_embed_sum + unredency_embed_sum) ** 2\n",
    "      square = embed ** 2\n",
    "      r_square = square[redency_part_slice] \n",
    "      n_square = square[unredency_part_slice] \n",
    "      \n",
    "      sum_of_square = torch.sum(r_square,dim=0) + torch.sum(n_square,dim=1)\n",
    "      ix = square_of_sum - sum_of_square\n",
    "      ix = torch.sum(ix,dim = 1,keepdim=True)\n",
    "      return 0.5 * ix\n",
    "    \n",
    "  \n",
    "  return pattern,ReplacementClass(),_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def workload_FM_reduce(num_field, prefix,dim = 64):\n",
    "  # print(f\"now gen workload of wdl with config: dim: {dim}, num_field: {num_field}, prefix: {prefix}\")\n",
    "  model_ori = fm.FactorizationMachineModel([100 for i in range(num_field)],dim,)\n",
    "  ori_traced = symbolic_trace(model_ori)\n",
    "  \n",
    "  model_modify = fm.FactorizationMachineModel([100 for i in range(num_field)],dim,)\n",
    "  modify_traced = symbolic_trace(model_modify)\n",
    "  pattern,replace,match = gen_pattern_replace_and_matcher_for_FM_reduce(modify_traced,\n",
    "                                                                      (0,slice(None,prefix,None)),(slice(None,None,None),slice(prefix,None,None)),\n",
    "                                                                      )\n",
    "  matches = subgraph_rewriter.replace_pattern_with_filters(modify_traced, pattern, replace,[match])\n",
    "  return ori_traced,modify_traced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genWorkload(num_field = 34 * 5,prefix = 29 * 5, batch = 4096, dim = 64):\n",
    "  ori_model_name = f'/home/yssun/pytorch-fm/torchfm/model/test_fx/exp/model_repo/fm_single/fm_{batch}_{num_field}_{prefix}_{dim}_ori.onnx'\n",
    "  modify_model_name = f'/home/yssun/pytorch-fm/torchfm/model/test_fx/exp/model_repo/fm_single/fm_{batch}_{num_field}_{prefix}_{dim}_modify.onnx'\n",
    "  ori, modify = workload_FM_reduce(num_field,prefix,dim)\n",
    "  torch.onnx.export(ori,               # 模型 being run\n",
    "                  torch.randint(low=0, high=20, size=(batch,num_field), dtype=torch.long),                  # 模型输入 (or a tuple for multiple inputs)\n",
    "                  ori_model_name,        # 导出文件的文件名\n",
    "                  export_params=True, # 如果设置为True，则参数也会被导出。注意某些情况下参数可能无法被导出。\n",
    "                  opset_version=10,   # ONNX版本\n",
    "                  do_constant_folding=True,  # 是否执行常量折叠以优化模型\n",
    "                  input_names = ['input'],   # 输入的名称\n",
    "                  output_names = ['output'], # 输出的名称\n",
    "                  )\n",
    "  torch.onnx.export(modify,               # 模型 being run\n",
    "                  torch.randint(low=0, high=20, size=(batch,num_field), dtype=torch.long),                  # 模型输入 (or a tuple for multiple inputs)\n",
    "                  modify_model_name,        # 导出文件的文件名\n",
    "                  export_params=True, # 如果设置为True，则参数也会被导出。注意某些情况下参数可能无法被导出。\n",
    "                  opset_version=10,   # ONNX版本\n",
    "                  do_constant_folding=True,  # 是否执行常量折叠以优化模型\n",
    "                  input_names = ['input'],   # 输入的名称\n",
    "                  output_names = ['output'], # 输出的名称\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims= [32]\n",
    "batches = [1024,2048,4096]\n",
    "num_field_and_prefixs = [(34 * 5,29*5),(22 * 5,10 * 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1314: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1314: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1314: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1314: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1314: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1314: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dims= [32]\n",
    "batches = [1024,2048,4096]\n",
    "num_field_and_prefixs = [(34 * 5,29*5),(22 * 5,10 * 5)]\n",
    "for dim in dims:\n",
    "  for batch in batches:\n",
    "    for num_field,prefix in num_field_and_prefixs:\n",
    "      genWorkload(num_field=num_field,prefix=prefix,batch=batch,dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 22, prefix: 10, batch :1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:16:05 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:16:05 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:16:05 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9169554710388184, 0.07943132970353872)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:16:06 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:16:06 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:16:06 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0442233085632324, 0.12344684284357754)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 1024, dim = 32,workload_func = workload_FM_reduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 22, prefix: 10, batch :2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:16:47 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:16:47 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:16:47 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0610270500183105, 0.1236391072495735)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:16:47 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:16:47 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:16:47 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.1726069450378418, 0.19102155517316532)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 2048, dim = 32,workload_func = workload_FM_reduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 22, prefix: 10, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:16:49 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:16:49 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:16:49 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.092071533203125, 0.08844105250318535)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:16:50 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:16:50 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.1979436874389648, 0.13238038538929686)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:16:50 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 4096, dim = 32,workload_func = workload_FM_reduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 22, prefix: 10, batch :8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:16:58 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:16:58 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:16:58 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.4666962623596191, 0.1865717113730625)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:16:59 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:16:59 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:16:59 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.3505244255065918, 0.18103512445009073)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 8192, dim = 32,workload_func = workload_FM_reduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 22, prefix: 10, batch :1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:16:55 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:16:55 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:16:55 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.964806079864502, 0.07223012596000444)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:16:55 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:16:55 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:16:55 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0060453414916992, 0.1514336068112243)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 1024, dim = 64,workload_func = workload_FM_reduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 22, prefix: 10, batch :2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:17:01 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:17:01 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:17:01 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0033392906188965, 0.08831823230934788)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:17:02 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:17:02 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:17:02 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0421347618103027, 0.11528772626547834)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 2048, dim = 64,workload_func = workload_FM_reduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 22, prefix: 10, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:17:04 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:17:04 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:17:04 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.7316913604736328, 0.18753690383164212)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:17:04 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:17:05 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:17:05 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.1911191940307617, 0.11400780247186049)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 4096, dim = 64,workload_func = workload_FM_reduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 22, prefix: 10, batch :8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:17:06 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:17:08 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:17:08 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14.165246486663818, 3.3072387934396374)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:17:08 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:17:09 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:17:09 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14.394018650054932, 0.5530460178931662)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 22,prefix = 10, batch = 8192, dim = 64,workload_func = workload_FM_reduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 110, prefix: 50, batch :8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:17:26 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:17:32 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:17:32 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58.990938663482666, 2.01896630330225)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:17:33 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:17:39 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:17:39 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57.015204429626465, 1.5228789374077678)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "gen_and_test(num_field = 22 * 5,prefix = 10 * 5, batch = 8192, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 170, prefix: 145, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:17:49 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:17:54 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:17:54 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47.62192249298096, 1.2350552644647905)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:17:54 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:17:59 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:17:59 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47.41093635559082, 0.9631288245145697)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "gen_and_test(num_field = 34 * 5,prefix = 29 * 5, batch = 4096, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 80, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:34:45 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:34:46 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:34:46 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15.614936351776123, 0.41849366118071885)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:34:47 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:34:48 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:34:48 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15.272209644317627, 0.8856696721238677)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test(num_field = 100,prefix = 80, batch = 4096, dim = 32,workload_func = workload_FM_reduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pattern_replace_and_matcher_for_FM_pow(traced,\n",
    "                                                  redency_part_slice,unredency_part_slice,\n",
    "                                                  match_func = None,batch = 4096\n",
    "                                                ):\n",
    "  from torch.fx.passes.utils.matcher_utils import SubgraphMatcher\n",
    "\n",
    "  class PatternClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.embed = torch.nn.Embedding(1, 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "      x = self.embed(x)\n",
    "      square_of_sum = torch.sum(x, dim=1) ** 2\n",
    "      sum_of_square = torch.sum(x ** 2, dim=1)\n",
    "      ix = square_of_sum - sum_of_square    \n",
    "      ix = torch.sum(ix, dim=1, keepdim=True)  \n",
    "      return 0.5 * ix\n",
    "  def _match(match,ori,pat):\n",
    "    return True \n",
    "  # env  = utils.get_env(traced)\n",
    "  # target_node = env[target_node_name]\n",
    "  # target_node_mod = utils.get_target_mod(traced,target_node_name,\"_\")\n",
    "  pattern = PatternClass()  \n",
    "  pattern_trace = symbolic_trace(pattern)\n",
    "  pattern_graph = pattern_trace.graph\n",
    "  original_graph = traced.graph\n",
    "  matcher =  SubgraphMatcher(pattern_graph, match_output=False, match_placeholder=False,\n",
    "                              remove_overlapping_matches=True)\n",
    "  _matches = matcher.match(original_graph)\n",
    "  match_filters = [_match if match_func is None else match_func]\n",
    "  _matches = [\n",
    "      m for m in _matches\n",
    "      if all(match_filter(m, original_graph, pattern_graph)\n",
    "              for match_filter in match_filters)\n",
    "  ]  \n",
    "  # 因为在过滤器中做了限制应该只有一个符合要求的\n",
    "  _matched = _matches[0]\n",
    "  pattern_env = utils.get_env(pattern_trace)\n",
    "  node_map = _matched.nodes_map\n",
    "  \n",
    "  embed_node = node_map[pattern_env['embed']]\n",
    "  embed_node_module = utils.get_target_mod(traced,embed_node.target)\n",
    "  \n",
    "\n",
    "  \n",
    "  \n",
    "  class ReplacementClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      embedding_config = embed_node_module.weight.data.shape\n",
    "      self.embed = nn.Embedding(embedding_config[0],embedding_config[1])\n",
    "      self.embed.weight.data.copy_(embed_node_module.weight.data)\n",
    "    def forward(self,x):\n",
    "      embed = self.embed(x)\n",
    "      square_of_sum = torch.sum(embed,dim=1) ** 2\n",
    "      # square = embed ** 2\n",
    "      r_embed = embed[redency_part_slice] \n",
    "      n_embed = embed[unredency_part_slice] \n",
    "      r_square = r_embed ** 2\n",
    "      n_square = n_embed ** 2\n",
    "      square = torch.concat([r_square.repeat(batch,1,1),n_square],dim = 1)\n",
    "      sum_of_square = torch.sum(square,dim=1)\n",
    "      ix = square_of_sum - sum_of_square\n",
    "      ix = torch.sum(ix,dim = 1,keepdim=True)\n",
    "      return 0.5 * ix\n",
    "    \n",
    "  \n",
    "  return pattern,ReplacementClass(),_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def workload_FM_pow(num_field, prefix,dim = 64,batch = 4096):\n",
    "  # print(f\"now gen workload of wdl with config: dim: {dim}, num_field: {num_field}, prefix: {prefix}\")\n",
    "  model_ori = fm.FactorizationMachineModel([100 for i in range(num_field)],dim,)\n",
    "  ori_traced = symbolic_trace(model_ori)\n",
    "  \n",
    "  model_modify = fm.FactorizationMachineModel([100 for i in range(num_field)],dim,)\n",
    "  modify_traced = symbolic_trace(model_modify)\n",
    "  pattern,replace,match = gen_pattern_replace_and_matcher_for_FM_pow(modify_traced,\n",
    "                                                                      (0,slice(None,prefix,None)),(slice(None,None,None),slice(prefix,None,None)),\n",
    "                                                                      batch = batch)\n",
    "  matches = subgraph_rewriter.replace_pattern_with_filters(modify_traced, pattern, replace,[match])\n",
    "  return ori_traced,modify_traced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genWorkload(num_field = 34 * 5,prefix = 29 * 5, batch = 4096, dim = 64):\n",
    "  ori_model_name = f'/home/yssun/pytorch-fm/torchfm/model/test_fx/exp/model_repo/fm_pow/fm_{batch}_{num_field}_{prefix}_{dim}_ori.onnx'\n",
    "  modify_model_name = f'/home/yssun/pytorch-fm/torchfm/model/test_fx/exp/model_repo/fm_pow/fm_{batch}_{num_field}_{prefix}_{dim}_modify.onnx'\n",
    "  ori, modify = workload_FM_pow(num_field,prefix,dim,batch = batch)\n",
    "  torch.onnx.export(ori,               # 模型 being run\n",
    "                  torch.randint(low=0, high=20, size=(batch,num_field), dtype=torch.long),                  # 模型输入 (or a tuple for multiple inputs)\n",
    "                  ori_model_name,        # 导出文件的文件名\n",
    "                  export_params=True, # 如果设置为True，则参数也会被导出。注意某些情况下参数可能无法被导出。\n",
    "                  opset_version=10,   # ONNX版本\n",
    "                  do_constant_folding=True,  # 是否执行常量折叠以优化模型\n",
    "                  input_names = ['input'],   # 输入的名称\n",
    "                  output_names = ['output'], # 输出的名称\n",
    "                  )\n",
    "  torch.onnx.export(modify,               # 模型 being run\n",
    "                  torch.randint(low=0, high=20, size=(batch,num_field), dtype=torch.long),                  # 模型输入 (or a tuple for multiple inputs)\n",
    "                  modify_model_name,        # 导出文件的文件名\n",
    "                  export_params=True, # 如果设置为True，则参数也会被导出。注意某些情况下参数可能无法被导出。\n",
    "                  opset_version=10,   # ONNX版本\n",
    "                  do_constant_folding=True,  # 是否执行常量折叠以优化模型\n",
    "                  input_names = ['input'],   # 输入的名称\n",
    "                  output_names = ['output'], # 输出的名称\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dims= [32]\n",
    "batches = [1024,2048,4096]\n",
    "num_field_and_prefixs = [(34 * 5,29*5),(22 * 5,10 * 5)]\n",
    "for dim in dims:\n",
    "  for batch in batches:\n",
    "    for num_field,prefix in num_field_and_prefixs:\n",
    "      genWorkload(num_field=num_field,prefix=prefix,batch=batch,dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_and_test_pow(num_field = 22,prefix = 10, batch = 4096, dim = 32, workload_func = workload_FM_pow):\n",
    "  def run(model):\n",
    "    traced_model = torch.jit.trace(model, torch.randint(low=0, high=88, size=(batch,num_field), dtype=torch.long))\n",
    "    compiled_model = torch.compile(traced_model, backend=\"inductor\")\n",
    "    compiled_model.eval()\n",
    "    total_time = 0\n",
    "    total_time = []\n",
    "    t = torch.randint(low=0, high=88, size=(batch ,num_field), dtype=torch.long)\n",
    "\n",
    "    with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "        with record_function(\"model_inference\"):\n",
    "          for i in range(100):\n",
    "              start_time = time.time()  # 开始计时\n",
    "              with torch.no_grad():\n",
    "                soutput = compiled_model(t)\n",
    "              end_time = time.time()  # 结束计时\n",
    "              \n",
    "              # 计算并打印函数执行所需的时间\n",
    "              elapsed_time = end_time - start_time\n",
    "              total_time.append(elapsed_time * 1000)\n",
    "    print(calculate_mean_and_variance_manual(total_time))\n",
    "  print(f\"now gen workload of fm with config: dim: {dim}, num_field: {num_field}, prefix: {prefix}, batch :{batch}\")\n",
    "  ori, modify = workload_func(num_field,prefix,dim,batch = batch)\n",
    "  run(ori)\n",
    "  run(modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 80, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:41:05 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:41:07 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:41:07 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16.88987970352173, 0.6170826296681753)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:41:07 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:41:09 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:41:09 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17.24506378173828, 0.7780305803862575)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test_pow(num_field = 100,prefix = 80, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 64, num_field: 100, prefix: 80, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:41:21 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:41:24 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:41:24 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30.05770444869995, 1.0351907103256508)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:41:24 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:41:29 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:41:29 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42.503089904785156, 3.0521515921918763)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test_pow(num_field = 100,prefix = 80, batch = 4096, dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now gen workload of fm with config: dim: 32, num_field: 100, prefix: 80, batch :4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:43:15 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:43:17 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:43:17 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15.491724014282227, 0.26896194412984187)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-02-07 20:43:17 2636347:2636347 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-02-07 20:43:19 2636347:2636347 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-02-07 20:43:19 2636347:2636347 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16.30260944366455, 0.6717198715477934)\n"
     ]
    }
   ],
   "source": [
    "gen_and_test_pow(num_field = 100,prefix = 80, batch = 4096, dim = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pattern_replace_and_matcher_for_FM_embed(traced,\n",
    "                                                  redency_part_slice,unredency_part_slice,\n",
    "                                                  match_func = None,batch = 4096\n",
    "                                                ):\n",
    "  from torch.fx.passes.utils.matcher_utils import SubgraphMatcher\n",
    "\n",
    "  class PatternClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.embed = torch.nn.Embedding(1, 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "      x = self.embed(x)\n",
    "      square_of_sum = torch.sum(x, dim=1) ** 2\n",
    "      sum_of_square = torch.sum(x ** 2, dim=1)\n",
    "      ix = square_of_sum - sum_of_square    \n",
    "      ix = torch.sum(ix, dim=1, keepdim=True)  \n",
    "      return 0.5 * ix\n",
    "  def _match(match,ori,pat):\n",
    "    return True \n",
    "  # env  = utils.get_env(traced)\n",
    "  # target_node = env[target_node_name]\n",
    "  # target_node_mod = utils.get_target_mod(traced,target_node_name,\"_\")\n",
    "  pattern = PatternClass()  \n",
    "  pattern_trace = symbolic_trace(pattern)\n",
    "  pattern_graph = pattern_trace.graph\n",
    "  original_graph = traced.graph\n",
    "  matcher =  SubgraphMatcher(pattern_graph, match_output=False, match_placeholder=False,\n",
    "                              remove_overlapping_matches=True)\n",
    "  _matches = matcher.match(original_graph)\n",
    "  match_filters = [_match if match_func is None else match_func]\n",
    "  _matches = [\n",
    "      m for m in _matches\n",
    "      if all(match_filter(m, original_graph, pattern_graph)\n",
    "              for match_filter in match_filters)\n",
    "  ]  \n",
    "  # 因为在过滤器中做了限制应该只有一个符合要求的\n",
    "  _matched = _matches[0]\n",
    "  pattern_env = utils.get_env(pattern_trace)\n",
    "  node_map = _matched.nodes_map\n",
    "  \n",
    "  embed_node = node_map[pattern_env['embed']]\n",
    "  embed_node_module = utils.get_target_mod(traced,embed_node.target)\n",
    "  \n",
    "\n",
    "  \n",
    "  \n",
    "  class ReplacementClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      embedding_config = embed_node_module.weight.data.shape\n",
    "      self.embed = nn.Embedding(embedding_config[0],embedding_config[1])\n",
    "      self.embed.weight.data.copy_(embed_node_module.weight.data)\n",
    "    def forward(self,x):\n",
    "      #r_embed = embed[redency_part_slice] \n",
    "      #n_embed = embed[unredency_part_slice] \n",
    "      r_x = x[redency_part_slice] \n",
    "      n_x = x[unredency_part_slice] \n",
    "      embed_r = self.embed(r_x)\n",
    "      embed_n = self.embed(n_x)\n",
    "      x = torch.concat([embed_r.repeat(batch,1,1),embed_n],dim = 1)\n",
    "      square_of_sum = torch.sum(x, dim=1) ** 2\n",
    "      sum_of_square = torch.sum(x ** 2, dim=1)\n",
    "      ix = square_of_sum - sum_of_square    \n",
    "      ix = torch.sum(ix, dim=1, keepdim=True)  \n",
    "      return 0.5 * ix\n",
    "    \n",
    "  \n",
    "  return pattern,ReplacementClass(),_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def workload_FM_embed(num_field, prefix,dim = 64,batch = 4096):\n",
    "  # print(f\"now gen workload of wdl with config: dim: {dim}, num_field: {num_field}, prefix: {prefix}\")\n",
    "  model_ori = fm.FactorizationMachineModel([100 for i in range(num_field)],dim,)\n",
    "  ori_traced = symbolic_trace(model_ori)\n",
    "  \n",
    "  model_modify = fm.FactorizationMachineModel([100 for i in range(num_field)],dim,)\n",
    "  modify_traced = symbolic_trace(model_modify)\n",
    "  pattern,replace,match = gen_pattern_replace_and_matcher_for_FM_embed(modify_traced,\n",
    "                                                                      (0,slice(None,prefix,None)),(slice(None,None,None),slice(prefix,None,None)),\n",
    "                                                                      batch = batch)\n",
    "  matches = subgraph_rewriter.replace_pattern_with_filters(modify_traced, pattern, replace,[match])\n",
    "  return ori_traced,modify_traced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genWorkload(num_field = 34 * 5,prefix = 29 * 5, batch = 4096, dim = 64):\n",
    "  ori_model_name = f'/home/yssun/pytorch-fm/torchfm/model/test_fx/exp/model_repo/fm_emb/fm_{batch}_{num_field}_{prefix}_{dim}_ori.onnx'\n",
    "  modify_model_name = f'/home/yssun/pytorch-fm/torchfm/model/test_fx/exp/model_repo/fm_emb/fm_{batch}_{num_field}_{prefix}_{dim}_modify.onnx'\n",
    "  ori, modify = workload_FM_embed(num_field,prefix,dim,batch = batch)\n",
    "  torch.onnx.export(ori,               # 模型 being run\n",
    "                  torch.randint(low=0, high=20, size=(batch,num_field), dtype=torch.long),                  # 模型输入 (or a tuple for multiple inputs)\n",
    "                  ori_model_name,        # 导出文件的文件名\n",
    "                  export_params=True, # 如果设置为True，则参数也会被导出。注意某些情况下参数可能无法被导出。\n",
    "                  opset_version=10,   # ONNX版本\n",
    "                  do_constant_folding=True,  # 是否执行常量折叠以优化模型\n",
    "                  input_names = ['input'],   # 输入的名称\n",
    "                  output_names = ['output'], # 输出的名称\n",
    "                  )\n",
    "  torch.onnx.export(modify,               # 模型 being run\n",
    "                  torch.randint(low=0, high=20, size=(batch,num_field), dtype=torch.long),                  # 模型输入 (or a tuple for multiple inputs)\n",
    "                  modify_model_name,        # 导出文件的文件名\n",
    "                  export_params=True, # 如果设置为True，则参数也会被导出。注意某些情况下参数可能无法被导出。\n",
    "                  opset_version=10,   # ONNX版本\n",
    "                  do_constant_folding=True,  # 是否执行常量折叠以优化模型\n",
    "                  input_names = ['input'],   # 输入的名称\n",
    "                  output_names = ['output'], # 输出的名称\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dims= [32]\n",
    "batches = [1024,2048,4096]\n",
    "num_field_and_prefixs = [(34 * 5,29*5),(22 * 5,10 * 5)]\n",
    "for dim in dims:\n",
    "  for batch in batches:\n",
    "    for num_field,prefix in num_field_and_prefixs:\n",
    "      genWorkload(num_field=num_field,prefix=prefix,batch=batch,dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pattern_replace_and_matcher_for_FM_full(traced,\n",
    "                                                  redency_part_slice,unredency_part_slice,\n",
    "                                                  match_func = None,batch = 4096\n",
    "                                                ):\n",
    "  from torch.fx.passes.utils.matcher_utils import SubgraphMatcher\n",
    "\n",
    "  class PatternClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.embed = torch.nn.Embedding(1, 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "      x = self.embed(x)\n",
    "      square_of_sum = torch.sum(x, dim=1) ** 2\n",
    "      sum_of_square = torch.sum(x ** 2, dim=1)\n",
    "      ix = square_of_sum - sum_of_square    \n",
    "      ix = torch.sum(ix, dim=1, keepdim=True)  \n",
    "      return 0.5 * ix\n",
    "  def _match(match,ori,pat):\n",
    "    return True \n",
    "  # env  = utils.get_env(traced)\n",
    "  # target_node = env[target_node_name]\n",
    "  # target_node_mod = utils.get_target_mod(traced,target_node_name,\"_\")\n",
    "  pattern = PatternClass()  \n",
    "  pattern_trace = symbolic_trace(pattern)\n",
    "  pattern_graph = pattern_trace.graph\n",
    "  original_graph = traced.graph\n",
    "  matcher =  SubgraphMatcher(pattern_graph, match_output=False, match_placeholder=False,\n",
    "                              remove_overlapping_matches=True)\n",
    "  _matches = matcher.match(original_graph)\n",
    "  match_filters = [_match if match_func is None else match_func]\n",
    "  _matches = [\n",
    "      m for m in _matches\n",
    "      if all(match_filter(m, original_graph, pattern_graph)\n",
    "              for match_filter in match_filters)\n",
    "  ]  \n",
    "  # 因为在过滤器中做了限制应该只有一个符合要求的\n",
    "  _matched = _matches[0]\n",
    "  pattern_env = utils.get_env(pattern_trace)\n",
    "  node_map = _matched.nodes_map\n",
    "  \n",
    "  embed_node = node_map[pattern_env['embed']]\n",
    "  embed_node_module = utils.get_target_mod(traced,embed_node.target)\n",
    "  \n",
    "\n",
    "  \n",
    "  \n",
    "  class ReplacementClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      embedding_config = embed_node_module.weight.data.shape\n",
    "      self.embed = nn.Embedding(embedding_config[0],embedding_config[1])\n",
    "      self.embed.weight.data.copy_(embed_node_module.weight.data)\n",
    "    def forward(self,x):\n",
    "      #r_embed = embed[redency_part_slice] \n",
    "      #n_embed = embed[unredency_part_slice] \n",
    "      r_x = x[redency_part_slice] \n",
    "      n_x = x[unredency_part_slice] \n",
    "      embed_r = self.embed(r_x)\n",
    "      embed_n = self.embed(n_x)\n",
    "      embed = torch.concat([embed_r.repeat(batch,1,1),embed_n],dim = 1)\n",
    "      r_embed = embed[redency_part_slice] \n",
    "      n_embed = embed[unredency_part_slice] \n",
    "      r_square = r_embed ** 2\n",
    "      n_square = n_embed ** 2\n",
    "      square = torch.concat([r_square.repeat(batch,1,1),n_square],dim = 1)\n",
    "      redency_embed = embed[redency_part_slice] \n",
    "      unredency_embed = embed[unredency_part_slice] \n",
    "      redency_embed_sum = torch.sum(redency_embed,dim=0)\n",
    "      unredency_embed_sum = torch.sum(unredency_embed,dim=1)\n",
    "      square_of_sum = (redency_embed_sum + unredency_embed_sum) ** 2\n",
    "      r_square = square[redency_part_slice] \n",
    "      n_square = square[unredency_part_slice] \n",
    "      \n",
    "      sum_of_square = torch.sum(r_square,dim=0) + torch.sum(n_square,dim=1)\n",
    "      ix = square_of_sum - sum_of_square\n",
    "      ix = torch.sum(ix,dim = 1,keepdim=True)\n",
    "      return 0.5 * ix\n",
    "    \n",
    "  \n",
    "  return pattern,ReplacementClass(),_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def workload_FM_full(num_field, prefix,dim = 64,batch = 4096):\n",
    "  # print(f\"now gen workload of wdl with config: dim: {dim}, num_field: {num_field}, prefix: {prefix}\")\n",
    "  model_ori = fm.FactorizationMachineModel([100 for i in range(num_field)],dim,)\n",
    "  ori_traced = symbolic_trace(model_ori)\n",
    "  \n",
    "  model_modify = fm.FactorizationMachineModel([100 for i in range(num_field)],dim,)\n",
    "  modify_traced = symbolic_trace(model_modify)\n",
    "  pattern,replace,match = gen_pattern_replace_and_matcher_for_FM_full(modify_traced,\n",
    "                                                                      (0,slice(None,prefix,None)),(slice(None,None,None),slice(prefix,None,None)),\n",
    "                                                                      batch = batch)\n",
    "  matches = subgraph_rewriter.replace_pattern_with_filters(modify_traced, pattern, replace,[match])\n",
    "  return ori_traced,modify_traced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genWorkload(num_field = 34 * 5,prefix = 29 * 5, batch = 4096, dim = 64):\n",
    "  ori_model_name = f'/home/yssun/pytorch-fm/torchfm/model/test_fx/exp/model_repo/fm_full/fm_{batch}_{num_field}_{prefix}_{dim}_ori.onnx'\n",
    "  modify_model_name = f'/home/yssun/pytorch-fm/torchfm/model/test_fx/exp/model_repo/fm_full/fm_{batch}_{num_field}_{prefix}_{dim}_modify.onnx'\n",
    "  ori, modify = workload_FM_full(num_field,prefix,dim,batch = batch)\n",
    "  # torch.onnx.export(ori,               # 模型 being run\n",
    "  #                 torch.randint(low=0, high=20, size=(batch,num_field), dtype=torch.long),                  # 模型输入 (or a tuple for multiple inputs)\n",
    "  #                 ori_model_name,        # 导出文件的文件名\n",
    "  #                 export_params=True, # 如果设置为True，则参数也会被导出。注意某些情况下参数可能无法被导出。\n",
    "  #                 opset_version=10,   # ONNX版本\n",
    "  #                 do_constant_folding=True,  # 是否执行常量折叠以优化模型\n",
    "  #                 input_names = ['input'],   # 输入的名称\n",
    "  #                 output_names = ['output'], # 输出的名称\n",
    "  #                 )\n",
    "  torch.onnx.export(modify,               # 模型 being run\n",
    "                  torch.randint(low=0, high=20, size=(batch,num_field), dtype=torch.long),                  # 模型输入 (or a tuple for multiple inputs)\n",
    "                  modify_model_name,        # 导出文件的文件名\n",
    "                  export_params=True, # 如果设置为True，则参数也会被导出。注意某些情况下参数可能无法被导出。\n",
    "                  opset_version=10,   # ONNX版本\n",
    "                  do_constant_folding=True,  # 是否执行常量折叠以优化模型\n",
    "                  input_names = ['input'],   # 输入的名称\n",
    "                  output_names = ['output'], # 输出的名称\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/yssun/miniconda3/envs/tensorrt/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:1173: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dims= [32]\n",
    "batches = [1024,2048,4096]\n",
    "num_field_and_prefixs = [(34 * 5,29*5),(22 * 5,10 * 5)]\n",
    "for dim in dims:\n",
    "  for batch in batches:\n",
    "    for num_field,prefix in num_field_and_prefixs:\n",
    "      genWorkload(num_field=num_field,prefix=prefix,batch=batch,dim=dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorrt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
