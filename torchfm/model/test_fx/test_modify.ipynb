{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.fx as fx\n",
    "import operator\n",
    "from torch.fx import Proxy, Graph, GraphModule\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "  index = torch.triu_indices(10, 10, offset=1)\n",
    "  return torch.index_select(x,1,index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = fx.symbolic_trace(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name               target                                                           args                       kwargs\n",
      "-------------  -----------------  ---------------------------------------------------------------  -------------------------  --------\n",
      "placeholder    x                  x                                                                ()                         {}\n",
      "get_attr       _tensor_constant0  _tensor_constant0                                                ()                         {}\n",
      "call_function  index_select       <built-in method index_select of type object at 0x7f1f87214760>  (x, 1, _tensor_constant0)  {}\n",
      "output         output             output                                                           (index_select,)            {}\n"
     ]
    }
   ],
   "source": [
    "graph.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel(torch.nn.Module):\n",
    "  \n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super().__init__()\n",
    "    self.mlp = torch.nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    \n",
    "  def forward(self,x):\n",
    "    return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TestModel(100,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = fx.symbolic_trace(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.register_module(\"modifiy\",torch.nn.Linear(300,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestModel(\n",
       "  (mlp): Linear(in_features=100, out_features=300, bias=True)\n",
       "  (modifiy): Linear(in_features=300, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode       name    target    args    kwargs\n",
      "-----------  ------  --------  ------  --------\n",
      "placeholder  x       x         ()      {}\n",
      "call_module  mlp     mlp       (x,)    {}\n",
      "output       output  output    (mlp,)  {}\n"
     ]
    }
   ],
   "source": [
    "graph.graph.print_tabular()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel2(torch.nn.Module):\n",
    "  \n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super().__init__()\n",
    "    self.mlp1 = torch.nn.Linear(input_dim//2, output_dim)\n",
    "    self.mlp2 = torch.nn.Linear(input_dim//2, output_dim)\n",
    "    \n",
    "  def forward(self,x):\n",
    "    return self.mlp1(x[:,:50]) + self.mlp2(x[:,50:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TestModel2(100,300)\n",
    "graph = fx.symbolic_trace(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name       target                       args                                                   kwargs\n",
      "-------------  ---------  ---------------------------  -----------------------------------------------------  --------\n",
      "placeholder    x          x                            ()                                                     {}\n",
      "call_function  getitem    <built-in function getitem>  (x, (slice(None, None, None), slice(None, 50, None)))  {}\n",
      "call_module    mlp1       mlp1                         (getitem,)                                             {}\n",
      "call_function  getitem_1  <built-in function getitem>  (x, (slice(None, None, None), slice(50, None, None)))  {}\n",
      "call_module    mlp2       mlp2                         (getitem_1,)                                           {}\n",
      "call_function  add        <built-in function add>      (mlp1, mlp2)                                           {}\n",
      "output         output     output                       (add,)                                                 {}\n"
     ]
    }
   ],
   "source": [
    "graph.graph.print_tabular()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2284, -0.1840, -1.8463,  ...,  0.0370,  0.1516,  1.0195],\n",
       "        [-0.2284, -0.1840, -1.8463,  ...,  0.0370,  0.1516,  1.0195],\n",
       "        [-0.2284, -0.1840, -1.8463,  ...,  0.0370,  0.1516,  1.0195],\n",
       "        ...,\n",
       "        [-0.2284, -0.1840, -1.8463,  ...,  0.0370,  0.1516,  1.0195],\n",
       "        [-0.2284, -0.1840, -1.8463,  ...,  0.0370,  0.1516,  1.0195],\n",
       "        [-0.2284, -0.1840, -1.8463,  ...,  0.0370,  0.1516,  1.0195]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = torch.ones((4096,100))\n",
    "model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model,sample,f'TestModel2.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model,sample,f'TestModel2.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel3(torch.nn.Module):\n",
    "  \n",
    "  def __init__(self, input_dim, output_dim,prefix):\n",
    "    super().__init__()\n",
    "    self.mlp1 = torch.nn.Linear(prefix, output_dim)\n",
    "    self.mlp2 = torch.nn.Linear(input_dim - prefix, output_dim)\n",
    "    self.prefix = prefix\n",
    "    \n",
    "  def forward(self,x):\n",
    "    return self.mlp1(x[0,:self.prefix]) + self.mlp2(x[:,self.prefix:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TestModel3(100,300,50)\n",
    "graph = fx.symbolic_trace(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name       target                       args                                                   kwargs\n",
      "-------------  ---------  ---------------------------  -----------------------------------------------------  --------\n",
      "placeholder    x          x                            ()                                                     {}\n",
      "call_function  getitem    <built-in function getitem>  (x, (0, slice(None, 50, None)))                        {}\n",
      "call_module    mlp1       mlp1                         (getitem,)                                             {}\n",
      "call_function  getitem_1  <built-in function getitem>  (x, (slice(None, None, None), slice(50, None, None)))  {}\n",
      "call_module    mlp2       mlp2                         (getitem_1,)                                           {}\n",
      "call_function  add        <built-in function add>      (mlp1, mlp2)                                           {}\n",
      "output         output     output                       (add,)                                                 {}\n"
     ]
    }
   ],
   "source": [
    "graph.graph.print_tabular()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model,sample,f'TestModel3.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMModel(torch.nn.Module):\n",
    "  \n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    # self.mlp = torch.nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    \n",
    "  def forward(self,x):\n",
    "    return torch.sum(x ** 2,dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMModel2(torch.nn.Module):\n",
    "  \n",
    "  def __init__(self,prefix):\n",
    "    super().__init__()\n",
    "    # self.mlp = torch.nn.Linear(input_dim, output_dim)\n",
    "    self.prefix = prefix\n",
    "    \n",
    "  def forward(self,x):\n",
    "    return torch.sum(x[0,:self.prefix] ** 2,dim = 0) + torch.sum(x[:,self.prefix:] ** 2,dim = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics, tabulate, time\n",
    "from typing import Any, Dict, List\n",
    "from torch.fx import Interpreter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProfilingInterpreter(Interpreter):\n",
    "    def __init__(self, mod : torch.nn.Module):\n",
    "        # Rather than have the user symbolically trace their model,\n",
    "        # we're going to do it in the constructor. As a result, the\n",
    "        # user can pass in any ``Module`` without having to worry about\n",
    "        # symbolic tracing APIs\n",
    "        gm = torch.fx.symbolic_trace(mod)\n",
    "        super().__init__(gm)\n",
    "\n",
    "        # We are going to store away two things here:\n",
    "        #\n",
    "        # 1. A list of total runtimes for ``mod``. In other words, we are\n",
    "        #    storing away the time ``mod(...)`` took each time this\n",
    "        #    interpreter is called.\n",
    "        self.total_runtime_sec : List[float] = []\n",
    "        # 2. A map from ``Node`` to a list of times (in seconds) that\n",
    "        #    node took to run. This can be seen as similar to (1) but\n",
    "        #    for specific sub-parts of the model.\n",
    "        self.runtimes_sec : Dict[torch.fx.Node, List[float]] = {}\n",
    "\n",
    "    ######################################################################\n",
    "    # Next, let's override our first method: ``run()``. ``Interpreter``'s ``run``\n",
    "    # method is the top-level entrypoint for execution of the model. We will\n",
    "    # want to intercept this so that we can record the total runtime of the\n",
    "    # model.\n",
    "\n",
    "    def run(self, *args) -> Any:\n",
    "        # Record the time we started running the model\n",
    "        t_start = time.time()\n",
    "        # Run the model by delegating back into Interpreter.run()\n",
    "        return_val = super().run(*args)\n",
    "        # Record the time we finished running the model\n",
    "        t_end = time.time()\n",
    "        # Store the total elapsed time this model execution took in the\n",
    "        # ProfilingInterpreter\n",
    "        self.total_runtime_sec.append(t_end - t_start)\n",
    "        return return_val\n",
    "\n",
    "    ######################################################################\n",
    "    # Now, let's override ``run_node``. ``Interpreter`` calls ``run_node`` each\n",
    "    # time it executes a single node. We will intercept this so that we\n",
    "    # can measure and record the time taken for each individual call in\n",
    "    # the model.\n",
    "\n",
    "    def run_node(self, n : torch.fx.Node) -> Any:\n",
    "        # Record the time we started running the op\n",
    "        t_start = time.time()\n",
    "        # Run the op by delegating back into Interpreter.run_node()\n",
    "        return_val = super().run_node(n)\n",
    "        # Record the time we finished running the op\n",
    "        t_end = time.time()\n",
    "        # If we don't have an entry for this node in our runtimes_sec\n",
    "        # data structure, add one with an empty list value.\n",
    "        self.runtimes_sec.setdefault(n, [])\n",
    "        # Record the total elapsed time for this single invocation\n",
    "        # in the runtimes_sec data structure\n",
    "        self.runtimes_sec[n].append(t_end - t_start)\n",
    "        return return_val\n",
    "\n",
    "    ######################################################################\n",
    "    # Finally, we are going to define a method (one which doesn't override\n",
    "    # any ``Interpreter`` method) that provides us a nice, organized view of\n",
    "    # the data we have collected.\n",
    "\n",
    "    def summary(self, should_sort : bool = False) -> str:\n",
    "        # Build up a list of summary information for each node\n",
    "        node_summaries : List[List[Any]] = []\n",
    "        # Calculate the mean runtime for the whole network. Because the\n",
    "        # network may have been called multiple times during profiling,\n",
    "        # we need to summarize the runtimes. We choose to use the\n",
    "        # arithmetic mean for this.\n",
    "        mean_total_runtime = statistics.mean(self.total_runtime_sec)\n",
    "\n",
    "        # For each node, record summary statistics\n",
    "        for node, runtimes in self.runtimes_sec.items():\n",
    "            # Similarly, compute the mean runtime for ``node``\n",
    "            mean_runtime = statistics.mean(runtimes)\n",
    "            # For easier understanding, we also compute the percentage\n",
    "            # time each node took with respect to the whole network.\n",
    "            pct_total = mean_runtime / mean_total_runtime * 100\n",
    "            # Record the node's type, name of the node, mean runtime, and\n",
    "            # percent runtim\n",
    "            node_summaries.append(\n",
    "                [node.op, str(node), mean_runtime, pct_total])\n",
    "\n",
    "        # One of the most important questions to answer when doing performance\n",
    "        # profiling is \"Which op(s) took the longest?\". We can make this easy\n",
    "        # to see by providing sorting functionality in our summary view\n",
    "        if should_sort:\n",
    "            node_summaries.sort(key=lambda s: s[2], reverse=True)\n",
    "\n",
    "        # Use the ``tabulate`` library to create a well-formatted table\n",
    "        # presenting our summary information\n",
    "        headers : List[str] = [\n",
    "            'Op type', 'Op', 'Average runtime (s)', 'Pct total runtime'\n",
    "        ]\n",
    "        print(f\"total time: {mean_total_runtime * 1000} ms\")\n",
    "        return tabulate.tabulate(node_summaries, headers=headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Op type        Op           Average runtime (s)    Pct total runtime\n",
      "-------------  ---------  ---------------------  -------------------\n",
      "call_module    mlp2                 0.00571775             24.9586\n",
      "call_module    mlp1                 0.000508547             2.21986\n",
      "call_function  add                  0.000267506             1.16769\n",
      "call_function  getitem              0.000145912             0.636923\n",
      "call_function  getitem_1            7.79629e-05             0.340317\n",
      "placeholder    x                    4.55379e-05             0.198778\n",
      "output         output               3.26633e-05             0.142579\n"
     ]
    }
   ],
   "source": [
    "interp = ProfilingInterpreter(model)\n",
    "interp.run(sample)\n",
    "print(interp.summary(True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 6.9980621337890625 ms\n",
      "Op type      Op        Average runtime (s)    Pct total runtime\n",
      "-----------  ------  ---------------------  -------------------\n",
      "call_module  mlp               0.00671077             95.8947\n",
      "output       output            6.34193e-05             0.906241\n",
      "placeholder  x                 3.76701e-05             0.538294\n"
     ]
    }
   ],
   "source": [
    "interp = ProfilingInterpreter(TestModel(3000,400))\n",
    "interp.run(torch.ones((4096,3000)))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 6.140232086181641 ms\n",
      "Op type        Op           Average runtime (s)    Pct total runtime\n",
      "-------------  ---------  ---------------------  -------------------\n",
      "call_module    mlp2                 0.00518847             84.4995\n",
      "call_function  add                  0.000342131             5.57195\n",
      "call_module    mlp1                 0.000214577             3.4946\n",
      "call_function  getitem              8.44002e-05             1.37454\n",
      "placeholder    x                    3.45707e-05             0.563019\n",
      "call_function  getitem_1            3.38554e-05             0.551371\n",
      "output         output               2.28882e-05             0.372758\n"
     ]
    }
   ],
   "source": [
    "interp = ProfilingInterpreter(TestModel3(3000,400,640))\n",
    "interp.run(torch.ones((4096,3000)))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 3.6537647247314453 ms\n",
      "Op type        Op           Average runtime (s)    Pct total runtime\n",
      "-------------  ---------  ---------------------  -------------------\n",
      "call_module    mlp2                 0.00242901             66.4796\n",
      "call_function  add                  0.000707626            19.367\n",
      "call_module    mlp1                 0.000216961             5.93801\n",
      "call_function  getitem              6.91414e-05             1.89233\n",
      "call_function  getitem_1            3.05176e-05             0.835237\n",
      "placeholder    x                    2.6226e-05              0.717781\n",
      "output         output               1.50204e-05             0.411093\n"
     ]
    }
   ],
   "source": [
    "interp = ProfilingInterpreter(TestModel3(3000,400,2000))\n",
    "interp.run(torch.ones((4096,3000)))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Op type      Op        Average runtime (s)    Pct total runtime\n",
      "-----------  ------  ---------------------  -------------------\n",
      "call_module  mlp               0.00800776             96.5949\n",
      "output       output            6.67572e-05             0.805269\n",
      "placeholder  x                 3.14713e-05             0.379627\n"
     ]
    }
   ],
   "source": [
    "interp = ProfilingInterpreter(TestModel(3000,400))\n",
    "interp.run(torch.ones((4096,3000)))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 4.163026809692383 ms\n",
      "Op type        Op        Average runtime (s)    Pct total runtime\n",
      "-------------  ------  ---------------------  -------------------\n",
      "call_function  pow_1             0.00340557             81.8052\n",
      "call_function  sum_1             0.000416994            10.0166\n",
      "placeholder    x                 5.03063e-05             1.20841\n",
      "output         output            3.38554e-05             0.813241\n"
     ]
    }
   ],
   "source": [
    "fmModel = FMModel()\n",
    "interp = ProfilingInterpreter(fmModel)\n",
    "\n",
    "interp.run(torch.ones((4096,22,64)))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 2.0377635955810547 ms\n",
      "Op type        Op           Average runtime (s)    Pct total runtime\n",
      "-------------  ---------  ---------------------  -------------------\n",
      "call_function  pow_2                0.000626802             30.7593\n",
      "call_function  sum_2                0.000417709             20.4984\n",
      "call_function  add                  0.000173807              8.52931\n",
      "call_function  getitem              0.000145435              7.13701\n",
      "call_function  pow_1                9.60827e-05              4.7151\n",
      "call_function  sum_1                8.13007e-05              3.9897\n",
      "call_function  getitem_1            6.67572e-05              3.276\n",
      "placeholder    x                    6.41346e-05              3.1473\n",
      "output         output               3.12328e-05              1.5327\n"
     ]
    }
   ],
   "source": [
    "interp = ProfilingInterpreter(FMModel2(10))\n",
    "interp.run(torch.ones((4096,22,64)))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 15.61594009399414 ms\n",
      "Op type        Op        Average runtime (s)    Pct total runtime\n",
      "-------------  ------  ---------------------  -------------------\n",
      "call_function  pow_1             0.00800657             51.2718\n",
      "call_function  sum_1             0.00134611              8.62011\n",
      "output         output            6.36578e-05             0.407646\n",
      "placeholder    x                 4.91142e-05             0.314513\n"
     ]
    }
   ],
   "source": [
    "fmModel = FMModel()\n",
    "interp = ProfilingInterpreter(fmModel)\n",
    "\n",
    "interp.run(torch.ones((4096,100,64)))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 14.735221862792969 ms\n",
      "Op type        Op           Average runtime (s)    Pct total runtime\n",
      "-------------  ---------  ---------------------  -------------------\n",
      "call_function  pow_2                0.0070467              47.8221\n",
      "call_function  sum_2                0.00118017              8.00919\n",
      "call_function  add                  0.000461817             3.1341\n",
      "call_function  getitem              0.00011158              0.757233\n",
      "call_function  pow_1                6.24657e-05             0.423921\n",
      "call_function  sum_1                6.24657e-05             0.423921\n",
      "placeholder    x                    4.79221e-05             0.325222\n",
      "call_function  getitem_1            3.50475e-05             0.237849\n",
      "output         output               2.40803e-05             0.16342\n"
     ]
    }
   ],
   "source": [
    "interp = ProfilingInterpreter(FMModel2(10))\n",
    "interp.run(torch.ones((4096,100,64)))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 1.9943714141845703 ms\n",
      "Op type        Op           Average runtime (s)    Pct total runtime\n",
      "-------------  ---------  ---------------------  -------------------\n",
      "call_function  pow_2                0.000996351            49.9582\n",
      "call_function  sum_2                0.000235081            11.7872\n",
      "call_function  add                  0.000131845             6.61088\n",
      "call_function  getitem              0.000113487             5.69038\n",
      "call_function  pow_1                7.72476e-05             3.87328\n",
      "call_function  sum_1                6.48499e-05             3.25164\n",
      "placeholder    x                    4.93526e-05             2.4746\n",
      "call_function  getitem_1            3.55244e-05             1.78123\n",
      "output         output               1.83582e-05             0.920502\n"
     ]
    }
   ],
   "source": [
    "interp = ProfilingInterpreter(FMModel2(90))\n",
    "interp.run(torch.ones((4096,100,64)))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 1.1610984802246094 ms\n",
      "Op type        Op        Average runtime (s)    Pct total runtime\n",
      "-------------  ------  ---------------------  -------------------\n",
      "call_function  pow_1             0.000542164             46.694\n",
      "call_function  sum_1             0.000258446             22.2587\n",
      "placeholder    x                 6.22272e-05              5.35934\n",
      "output         output            3.93391e-05              3.38809\n"
     ]
    }
   ],
   "source": [
    "fmModel = FMModel()\n",
    "interp = ProfilingInterpreter(fmModel)\n",
    "\n",
    "interp.run(torch.ones((4096,100,8)))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 1.8224716186523438 ms\n",
      "Op type        Op           Average runtime (s)    Pct total runtime\n",
      "-------------  ---------  ---------------------  -------------------\n",
      "call_function  sum_1                0.00037694              20.6829\n",
      "call_function  pow_2                0.000323057             17.7263\n",
      "call_function  pow_1                0.000257254             14.1156\n",
      "call_function  sum_2                0.000201702             11.0675\n",
      "call_function  add                  0.000175953              9.65463\n",
      "call_function  getitem              0.000116348              6.38409\n",
      "call_function  getitem_1            5.74589e-05              3.1528\n",
      "placeholder    x                    4.3869e-05               2.40712\n",
      "output         output               2.07424e-05              1.13815\n"
     ]
    }
   ],
   "source": [
    "interp = ProfilingInterpreter(FMModel2(10))\n",
    "interp.run(torch.ones((4096,100,8)))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 1.802206039428711 ms\n",
      "Op type        Op           Average runtime (s)    Pct total runtime\n",
      "-------------  ---------  ---------------------  -------------------\n",
      "call_function  pow_2                0.000377893             20.9684\n",
      "call_function  pow_1                0.000282288             15.6634\n",
      "call_function  sum_2                0.00018549              10.2924\n",
      "call_function  add                  0.000177383              9.84257\n",
      "call_function  sum_1                0.000141859              7.87141\n",
      "call_function  getitem              0.00012207               6.77338\n",
      "call_function  getitem_1            9.29832e-05              5.15941\n",
      "placeholder    x                    6.1512e-05               3.41315\n",
      "output         output               4.62532e-05              2.56648\n"
     ]
    }
   ],
   "source": [
    "interp = ProfilingInterpreter(FMModel2(90))\n",
    "interp.run(torch.ones((4096,100,8)))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test_moidfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "modify_model = FMModel()\n",
    "graph = fx.symbolic_trace(modify_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name    target                                                  args      kwargs\n",
      "-------------  ------  ------------------------------------------------------  --------  ----------\n",
      "placeholder    x       x                                                       ()        {}\n",
      "call_function  pow_1   <built-in function pow>                                 (x, 2)    {}\n",
      "call_function  sum_1   <built-in method sum of type object at 0x7f7974c1d760>  (pow_1,)  {'dim': 1}\n",
      "output         output  output                                                  (sum_1,)  {}\n"
     ]
    }
   ],
   "source": [
    "graph.graph.print_tabular()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = {}\n",
    "for node in graph.graph.nodes:\n",
    "  env[node.name] = node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': x, 'pow_1': pow_1, 'sum_1': sum_1, 'output': output}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "output_1"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.graph.output(env['pow_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.graph.erase_node(env['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name      target                                                  args      kwargs\n",
      "-------------  --------  ------------------------------------------------------  --------  ----------\n",
      "placeholder    x         x                                                       ()        {}\n",
      "call_function  pow_1     <built-in function pow>                                 (x, 2)    {}\n",
      "call_function  sum_1     <built-in method sum of type object at 0x7f7974c1d760>  (pow_1,)  {'dim': 1}\n",
      "output         output_1  output                                                  (pow_1,)  {}\n"
     ]
    }
   ],
   "source": [
    "graph.graph.print_tabular()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.graph.lint() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonCode(src='\\n\\n\\ndef forward(self, x):\\n    pow_1 = x ** 2;  x = None\\n    sum_1 = torch.sum(pow_1, dim = 1)\\n    return pow_1\\n    ', globals={'inf': inf, 'nan': nan, 'NoneType': <class 'NoneType'>, 'torch': <module 'torch' from '/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/__init__.py'>, 'device': <class 'torch.device'>, 'fx_pytree': <module 'torch.fx._pytree' from '/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/fx/_pytree.py'>, 'pytree': <module 'torch.utils._pytree' from '/home/yssun/miniconda3/envs/deepctr-torch/lib/python3.9/site-packages/torch/utils/_pytree.py'>}, _lineno_map={1: 1, 2: 2, 3: 3, 4: 3})"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.recompile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name      target                                                  args      kwargs\n",
      "-------------  --------  ------------------------------------------------------  --------  ----------\n",
      "placeholder    x         x                                                       ()        {}\n",
      "call_function  pow_1     <built-in function pow>                                 (x, 2)    {}\n",
      "call_function  sum_1     <built-in method sum of type object at 0x7f7974c1d760>  (pow_1,)  {'dim': 1}\n",
      "output         output_1  output                                                  (pow_1,)  {}\n"
     ]
    }
   ],
   "source": [
    "graph.graph.print_tabular()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    pow_1 = x ** 2;  x = None\n",
      "    sum_1 = torch.sum(pow_1, dim = 1)\n",
      "    return pow_1\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(graph.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "modify_mod = GraphModule(torch.nn.Module(), graph.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(modify_mod,torch.ones((4096,10,22)),f'modify_mod.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMModel(torch.nn.Module):\n",
    "  \n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    # self.mlp = torch.nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    \n",
    "  def forward(self,x):\n",
    "    return torch.sum(x ** 2,dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 捕获模型的IR\n",
    "traced = fx.symbolic_trace(FMModel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : placeholder target = x args = ()\n",
      "pow_1 : call_function target = <built-in function pow> args = (x, 2)\n",
      "sum_1 : call_function target = <built-in method sum of type object at 0x7f7974c1d760> args = (pow_1,)\n",
      "output : output target = output args = (sum_1,)\n"
     ]
    }
   ],
   "source": [
    "# 打印IR\n",
    "for n in traced.graph.nodes:\n",
    "  print(f\"{n.name} : {n.op} target = {n.target} args = {n.args}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    pow_1 = x ** 2;  x = None\n",
      "    sum_1 = torch.sum(pow_1, dim = 1);  pow_1 = None\n",
      "    return sum_1\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# 打印基于IR的Python 代码\n",
    "print(traced.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReduceSum(torch.nn.Module):\n",
    "  \n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "        \n",
    "  def forward(self,x):\n",
    "    return torch.sum(x,dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReduceSum2(torch.nn.Module):\n",
    "  \n",
    "  def __init__(self,prefix):\n",
    "    super().__init__()\n",
    "    self.prefix = prefix\n",
    "    \n",
    "  def forward(self,x):\n",
    "    return torch.sum(x[0,:self.prefix] ,dim = 0) + torch.sum(x[:,self.prefix:],dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name    target                                                  args      kwargs\n",
      "-------------  ------  ------------------------------------------------------  --------  ----------\n",
      "placeholder    x       x                                                       ()        {}\n",
      "call_function  sum_1   <built-in method sum of type object at 0x7f7974c1d760>  (x,)      {'dim': 1}\n",
      "output         output  output                                                  (sum_1,)  {}\n"
     ]
    }
   ],
   "source": [
    "traced = fx.symbolic_trace(ReduceSum())\n",
    "traced.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = traced.graph\n",
    "env = {}\n",
    "for node in graph.nodes:\n",
    "  env[node.name] = node\n",
    "input_node = env['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_redency_extract_node = graph.call_function(operator.getitem,(input_node,(0,slice(None,10,None))))\n",
    "new_redency_sum_node = graph.call_function(torch.sum,(new_redency_extract_node,),{'dim':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_unredency_extract_node = graph.call_function(operator.getitem,(input_node,(slice(None,None,None),slice(10,None,None))))\n",
    "new_unredency_sum_node = graph.call_function(torch.sum,(new_unredency_extract_node,),{'dim':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "output_1"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_add_node = graph.call_function(torch.add,(new_redency_sum_node,new_unredency_sum_node))\n",
    "graph.erase_node(env['output'])\n",
    "graph.output(new_add_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name       target                                                  args                                                   kwargs\n",
      "-------------  ---------  ------------------------------------------------------  -----------------------------------------------------  ----------\n",
      "placeholder    x          x                                                       ()                                                     {}\n",
      "call_function  sum_1      <built-in method sum of type object at 0x7f7974c1d760>  (x,)                                                   {'dim': 1}\n",
      "call_function  getitem    <built-in function getitem>                             (x, (0, slice(None, 10, None)))                        {}\n",
      "call_function  sum_2      <built-in method sum of type object at 0x7f7974c1d760>  (getitem,)                                             {'dim': 0}\n",
      "call_function  getitem_1  <built-in function getitem>                             (x, (slice(None, None, None), slice(10, None, None)))  {}\n",
      "call_function  sum_3      <built-in method sum of type object at 0x7f7974c1d760>  (getitem_1,)                                           {'dim': 1}\n",
      "call_function  add        <built-in method add of type object at 0x7f7974c1d760>  (sum_2, sum_3)                                         {}\n",
      "output         output_1   output                                                  (add,)                                                 {}\n"
     ]
    }
   ],
   "source": [
    "graph.lint() \n",
    "graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "modify_mod = GraphModule(torch.nn.Module(), graph)\n",
    "torch.onnx.export(modify_mod,torch.ones((4096,10,22)),f'reduce_modify_mod.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name       target                                                  args                                                   kwargs\n",
      "-------------  ---------  ------------------------------------------------------  -----------------------------------------------------  ----------\n",
      "placeholder    x          x                                                       ()                                                     {}\n",
      "call_function  getitem    <built-in function getitem>                             (x, (0, slice(None, 10, None)))                        {}\n",
      "call_function  sum_1      <built-in method sum of type object at 0x7f7974c1d760>  (getitem,)                                             {'dim': 0}\n",
      "call_function  getitem_1  <built-in function getitem>                             (x, (slice(None, None, None), slice(10, None, None)))  {}\n",
      "call_function  sum_2      <built-in method sum of type object at 0x7f7974c1d760>  (getitem_1,)                                           {'dim': 1}\n",
      "call_function  add        <built-in function add>                                 (sum_1, sum_2)                                         {}\n",
      "output         output     output                                                  (add,)                                                 {}\n"
     ]
    }
   ],
   "source": [
    "traced = fx.symbolic_trace(ReduceSum2(10))\n",
    "traced.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = traced.graph\n",
    "env = {}\n",
    "for node in graph.nodes:\n",
    "  env[node.name] = node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function _operator.getitem(a, b, /)>"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env['getitem'].target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducesum_func(x):\n",
    "  return torch.sum(x,dim = 1)\n",
    "traced = fx.symbolic_trace(reducesum_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name    target                                                  args      kwargs\n",
      "-------------  ------  ------------------------------------------------------  --------  ----------\n",
      "placeholder    x       x                                                       ()        {}\n",
      "call_function  sum_1   <built-in method sum of type object at 0x7f7974c1d760>  (x,)      {'dim': 1}\n",
      "output         output  output                                                  (sum_1,)  {}\n"
     ]
    }
   ],
   "source": [
    "traced.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(traced,redency_part_slice,unredency_part_slice,input_node_name):\n",
    "  graph = traced.graph\n",
    "  env = {}\n",
    "  for node in graph.nodes:\n",
    "    env[node.name] = node\n",
    "  input_node = env[input_node_name]\n",
    "  # 冗余数据提取\n",
    "  new_redency_extract_node = graph.call_function(operator.getitem,(input_node,redency_part_slice))\n",
    "  # 冗余部分计算\n",
    "  new_redency_sum_node = graph.call_function(torch.sum,(new_redency_extract_node,),{'dim':0})\n",
    "  # 非冗余数据提取\n",
    "  new_unredency_extract_node = graph.call_function(operator.getitem,(input_node,unredency_part_slice))\n",
    "  # 非冗余数据计算\n",
    "  new_unredency_sum_node = graph.call_function(torch.sum,(new_unredency_extract_node,),{'dim':1})\n",
    "  # 操作还原\n",
    "  new_add_node = graph.call_function(torch.add,(new_redency_sum_node,new_unredency_sum_node))\n",
    "  \n",
    "  \n",
    "  graph.erase_node(env['output'])\n",
    "  graph.output(new_add_node)\n",
    "  graph.eliminate_dead_code()\n",
    "\n",
    "  graph.lint() \n",
    "  return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_successors_map(traced):\n",
    "  graph = traced.graph\n",
    "  map = dict()\n",
    "  for node in graph.nodes:\n",
    "    map[node.name] = []\n",
    "  \n",
    "  for node in graph.nodes:\n",
    "    args = node.args\n",
    "    for pre in args:\n",
    "      if hasattr(pre,'name') and pre.name in map:\n",
    "        map[pre.name].append(node.name)\n",
    "  return map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rewrite(traced,redency_part_slice,unredency_part_slice,input_node_name):\n",
    "#   graph = traced.graph\n",
    "#   env = {}\n",
    "#   for node in graph.nodes:\n",
    "#     env[node.name] = node\n",
    "#   input_node = env[input_node_name]\n",
    "#   # 冗余数据提取\n",
    "#   new_redency_extract_node = graph.call_function(operator.getitem,(input_node,redency_part_slice))\n",
    "#   # 非冗余数据提取\n",
    "#   new_unredency_extract_node = graph.call_function(operator.getitem,(input_node,unredency_part_slice))\n",
    "  \n",
    "#   # 冗余部分计算\n",
    "#   new_redency_sum_node = graph.call_function(torch.sum,(new_redency_extract_node,),{'dim':0})\n",
    "#   # 非冗余数据计算\n",
    "#   new_unredency_sum_node = graph.call_function(torch.sum,(new_unredency_extract_node,),{'dim':1})\n",
    "#   # 操作还原\n",
    "#   new_add_node = graph.call_function(torch.add,(new_redency_sum_node,new_unredency_sum_node))\n",
    "  \n",
    "#   map_dict = get_successors_map(traced)\n",
    "#   graph.erase_node(env['output'])\n",
    "#   graph.output(new_add_node)\n",
    "#   graph.eliminate_dead_code()\n",
    "#   graph.lint() \n",
    "#   return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(traced,redency_part_slice,unredency_part_slice,input_node_name,target_node_name):\n",
    "  graph = traced.graph\n",
    "  env = {}\n",
    "  for node in graph.nodes:\n",
    "    env[node.name] = node\n",
    "  input_node = env[input_node_name]\n",
    "  # 冗余数据提取\n",
    "  new_redency_extract_node = graph.call_function(operator.getitem,(input_node,redency_part_slice))\n",
    "  # 非冗余数据提取\n",
    "  new_unredency_extract_node = graph.call_function(operator.getitem,(input_node,unredency_part_slice))\n",
    "  \n",
    "  # 冗余部分计算\n",
    "  new_redency_sum_node = graph.call_function(torch.sum,(new_redency_extract_node,),{'dim':0})\n",
    "  # 非冗余数据计算\n",
    "  new_unredency_sum_node = graph.call_function(torch.sum,(new_unredency_extract_node,),{'dim':1})\n",
    "  # 操作还原\n",
    "  new_add_node = graph.call_function(torch.add,(new_redency_sum_node,new_unredency_sum_node))\n",
    "  \n",
    "  map_dict = get_successors_map(traced)\n",
    "  successors = map_dict[target_node_name]\n",
    "  for successor in successors:\n",
    "    successor_node = env[successor]\n",
    "    arg_tuple = successor_node.args\n",
    "    new_tuple = list(arg_tuple)\n",
    "    \n",
    "  graph.erase_node(env['output'])\n",
    "  graph.output(new_add_node)\n",
    "  graph.eliminate_dead_code()\n",
    "  graph.lint() \n",
    "  return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FMModel()\n",
    "traced = fx.symbolic_trace(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    pow_1 = x ** 2;  x = None\n",
      "    sum_1 = torch.sum(pow_1, dim = 1);  pow_1 = None\n",
      "    return sum_1\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(traced.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def func(self, x):\n",
      "    pow_1 = x ** 2;  x = None\n",
      "    sum_1 = torch.sum(pow_1, dim = 1);  pow_1 = None\n",
      "    return sum_1\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "s = traced.code\n",
    "new_s = s.replace(\"forward\",\"func\")\n",
    "print(new_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(new_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(new_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced = fx.symbolic_trace(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\ndef forward(self, x):\\n    pow_1 = x ** 2;  x = None\\n    sum_1 = torch.sum(pow_1, dim = 1);  pow_1 = None\\n    return sum_1\\n    '"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': ['pow_1'], 'pow_1': ['sum_1'], 'sum_1': ['output'], 'output': []}"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = rewrite(traced,(0,slice(None,10,None)),(slice(None,None,None),slice(10,None,None)),'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name       target                                                  args                                                   kwargs\n",
      "-------------  ---------  ------------------------------------------------------  -----------------------------------------------------  ----------\n",
      "placeholder    x          x                                                       ()                                                     {}\n",
      "call_function  getitem    <built-in function getitem>                             (x, (0, slice(None, 10, None)))                        {}\n",
      "call_function  getitem_1  <built-in function getitem>                             (x, (slice(None, None, None), slice(10, None, None)))  {}\n",
      "call_function  sum_2      <built-in method sum of type object at 0x7f7974c1d760>  (getitem,)                                             {'dim': 0}\n",
      "call_function  sum_3      <built-in method sum of type object at 0x7f7974c1d760>  (getitem_1,)                                           {'dim': 1}\n",
      "call_function  add        <built-in method add of type object at 0x7f7974c1d760>  (sum_2, sum_3)                                         {}\n",
      "output         output_1   output                                                  (add,)                                                 {}\n"
     ]
    }
   ],
   "source": [
    "graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "modify_mod = GraphModule(torch.nn.Module(), graph)\n",
    "torch.onnx.export(modify_mod,torch.ones((4096,10,8)),f'modify_mod.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 0.5046, 0.6537, 0.9155, 0.8738, 0.2819],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 0.9443, 0.5074, 0.5621, 0.7699, 0.6492],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 0.2387, 0.8049, 0.4836, 0.2890, 0.4419],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 0.2564, 0.5322, 0.3480, 0.8487, 0.3537],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 0.0928, 0.6242, 0.3772, 0.5356, 0.8618],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 0.9347, 0.7616, 0.0289, 0.7610, 0.0067],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 0.5948, 0.6504, 0.7251, 0.5338, 0.1614],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 0.1544, 0.2425, 0.4806, 0.9940, 0.2246]])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个8x15的torch张量\n",
    "tensor = torch.zeros(8, 15)\n",
    "\n",
    "# 前十列设置为1\n",
    "tensor[:, :10] = 1\n",
    "\n",
    "# 后五列设置为随机数\n",
    "tensor[:, 10:] = torch.rand(8, 5)\n",
    "\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def sum(x):\n",
    "  # 输入 x\n",
    "  # n行m列的数据\n",
    "  # 返回:\n",
    "  # n行1列的数据\n",
    "  # 每一行的数据是某一行列的和\n",
    "  output = [0 for i in range(x.shape(0))]\n",
    "  for row_number,row in enumerate(x):\n",
    "    output[row_number] = reduce(lambda x, y : x + y,row)\n",
    "  \n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefix_sum(x,prefix):\n",
    "  # 输入 x\n",
    "  # n行m列的数据\n",
    "  # 输入 prefix\n",
    "  # 冗余数据的前缀\n",
    "  # 返回:\n",
    "  # n行1列的数据\n",
    "  # 每一行的数据是某一行列的和\n",
    "  redency_prefix_sum = reduce(lambda x, y : x + y,x[0,:prefix])\n",
    "  output = [0 for i in range(x.shape(0))]\n",
    "  for row_number,row in enumerate(x):\n",
    "    output[row_number] = reduce(lambda x, y : x + y,row[prefix:])\n",
    "    output[row_number] = output[row_number] + redency_prefix_sum\n",
    "  \n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(graph):\n",
    "    dot = Digraph(comment='graph')\n",
    "    root = graph._root\n",
    "    cur = root._next\n",
    "    while cur is not root:\n",
    "        if not cur._erased:\n",
    "            dot.node(cur.name,cur.name,style='filled',\n",
    "                    shape='box',\n",
    "                    align='left',\n",
    "                    fontsize='10',\n",
    "                    ranksep='0.1',\n",
    "                    height='0.2',\n",
    "                    fontname='monospace',fillcolor='Orange')\n",
    "            for arg in cur.args:\n",
    "                if isinstance(arg,torch.fx.node.Node):\n",
    "                    dot.edge(arg.name,cur.name)\n",
    "                if isinstance(arg,list):\n",
    "                    for item in arg:\n",
    "                        dot.edge(item.name,cur.name)\n",
    "        cur = cur._next\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"62pt\" height=\"137pt\"\n",
       " viewBox=\"0.00 0.00 62.00 137.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 133)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-133 58,-133 58,4 -4,4\"/>\n",
       "<!-- x -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>x</title>\n",
       "<polygon fill=\"Orange\" stroke=\"black\" points=\"54,-129 0,-129 0,-110 54,-110 54,-129\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-117\" font-family=\"monospace\" font-size=\"10.00\">x</text>\n",
       "</g>\n",
       "<!-- sum_1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>sum_1</title>\n",
       "<polygon fill=\"Orange\" stroke=\"black\" points=\"54,-74 0,-74 0,-55 54,-55 54,-74\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-62\" font-family=\"monospace\" font-size=\"10.00\">sum_1</text>\n",
       "</g>\n",
       "<!-- x&#45;&gt;sum_1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x&#45;&gt;sum_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M27,-109.75C27,-102.8 27,-92.85 27,-84.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"30.5,-84.09 27,-74.09 23.5,-84.09 30.5,-84.09\"/>\n",
       "</g>\n",
       "<!-- output -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>output</title>\n",
       "<polygon fill=\"Orange\" stroke=\"black\" points=\"54,-19 0,-19 0,0 54,0 54,-19\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\">output</text>\n",
       "</g>\n",
       "<!-- sum_1&#45;&gt;output -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>sum_1&#45;&gt;output</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M27,-54.75C27,-47.8 27,-37.85 27,-29.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"30.5,-29.09 27,-19.09 23.5,-29.09 30.5,-29.09\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f781035ae80>"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw(fx.symbolic_trace(reducesum_func).graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReduceSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"156pt\" height=\"247pt\"\n",
       " viewBox=\"0.00 0.00 156.00 247.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 243)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-243 152,-243 152,4 -4,4\"/>\n",
       "<!-- x -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>x</title>\n",
       "<polygon fill=\"Orange\" stroke=\"black\" points=\"97.5,-239 43.5,-239 43.5,-220 97.5,-220 97.5,-239\"/>\n",
       "<text text-anchor=\"middle\" x=\"70.5\" y=\"-227\" font-family=\"monospace\" font-size=\"10.00\">x</text>\n",
       "</g>\n",
       "<!-- getitem -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>getitem</title>\n",
       "<polygon fill=\"Orange\" stroke=\"black\" points=\"59,-184 0,-184 0,-165 59,-165 59,-184\"/>\n",
       "<text text-anchor=\"middle\" x=\"29.5\" y=\"-172\" font-family=\"monospace\" font-size=\"10.00\">getitem</text>\n",
       "</g>\n",
       "<!-- x&#45;&gt;getitem -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x&#45;&gt;getitem</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M63.73,-219.75C57.94,-212.26 49.44,-201.28 42.36,-192.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"45.03,-189.86 36.14,-184.09 39.49,-194.14 45.03,-189.86\"/>\n",
       "</g>\n",
       "<!-- getitem_1 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>getitem_1</title>\n",
       "<polygon fill=\"Orange\" stroke=\"black\" points=\"148,-184 77,-184 77,-165 148,-165 148,-184\"/>\n",
       "<text text-anchor=\"middle\" x=\"112.5\" y=\"-172\" font-family=\"monospace\" font-size=\"10.00\">getitem_1</text>\n",
       "</g>\n",
       "<!-- x&#45;&gt;getitem_1 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>x&#45;&gt;getitem_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M77.44,-219.75C83.37,-212.26 92.07,-201.28 99.32,-192.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"102.23,-194.1 105.69,-184.09 96.74,-189.75 102.23,-194.1\"/>\n",
       "</g>\n",
       "<!-- sum_1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>sum_1</title>\n",
       "<polygon fill=\"Orange\" stroke=\"black\" points=\"59.5,-129 5.5,-129 5.5,-110 59.5,-110 59.5,-129\"/>\n",
       "<text text-anchor=\"middle\" x=\"32.5\" y=\"-117\" font-family=\"monospace\" font-size=\"10.00\">sum_1</text>\n",
       "</g>\n",
       "<!-- getitem&#45;&gt;sum_1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>getitem&#45;&gt;sum_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M30,-164.75C30.39,-157.8 30.95,-147.85 31.45,-139.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"34.94,-139.27 32.01,-129.09 27.95,-138.88 34.94,-139.27\"/>\n",
       "</g>\n",
       "<!-- add -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>add</title>\n",
       "<polygon fill=\"Orange\" stroke=\"black\" points=\"97.5,-74 43.5,-74 43.5,-55 97.5,-55 97.5,-74\"/>\n",
       "<text text-anchor=\"middle\" x=\"70.5\" y=\"-62\" font-family=\"monospace\" font-size=\"10.00\">add</text>\n",
       "</g>\n",
       "<!-- sum_1&#45;&gt;add -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>sum_1&#45;&gt;add</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M38.77,-109.75C44.09,-102.34 51.86,-91.5 58.38,-82.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"61.36,-84.26 64.34,-74.09 55.67,-80.18 61.36,-84.26\"/>\n",
       "</g>\n",
       "<!-- sum_2 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>sum_2</title>\n",
       "<polygon fill=\"Orange\" stroke=\"black\" points=\"136.5,-129 82.5,-129 82.5,-110 136.5,-110 136.5,-129\"/>\n",
       "<text text-anchor=\"middle\" x=\"109.5\" y=\"-117\" font-family=\"monospace\" font-size=\"10.00\">sum_2</text>\n",
       "</g>\n",
       "<!-- getitem_1&#45;&gt;sum_2 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>getitem_1&#45;&gt;sum_2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M112,-164.75C111.61,-157.8 111.05,-147.85 110.55,-139.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"114.05,-138.88 109.99,-129.09 107.06,-139.27 114.05,-138.88\"/>\n",
       "</g>\n",
       "<!-- sum_2&#45;&gt;add -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>sum_2&#45;&gt;add</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103.06,-109.75C97.61,-102.34 89.64,-91.5 82.94,-82.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"85.57,-80.07 76.82,-74.09 79.93,-84.22 85.57,-80.07\"/>\n",
       "</g>\n",
       "<!-- output -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>output</title>\n",
       "<polygon fill=\"Orange\" stroke=\"black\" points=\"97.5,-19 43.5,-19 43.5,0 97.5,0 97.5,-19\"/>\n",
       "<text text-anchor=\"middle\" x=\"70.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\">output</text>\n",
       "</g>\n",
       "<!-- add&#45;&gt;output -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>add&#45;&gt;output</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M70.5,-54.75C70.5,-47.8 70.5,-37.85 70.5,-29.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"74,-29.09 70.5,-19.09 67,-29.09 74,-29.09\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f78107e1850>"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw(fx.symbolic_trace(ReduceSum2(10)).graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 1.9207000732421875 ms\n",
      "Op type        Op        Average runtime (s)    Pct total runtime\n",
      "-------------  ------  ---------------------  -------------------\n",
      "call_function  sum_1             0.00160837              83.7388\n",
      "placeholder    x                 4.55379e-05              2.3709\n",
      "output         output            4.41074e-05              2.29643\n"
     ]
    }
   ],
   "source": [
    "interp = ProfilingInterpreter(ReduceSum())\n",
    "interp.run(torch.ones((4096,100,64)))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 2.293825149536133 ms\n",
      "Op type        Op           Average runtime (s)    Pct total runtime\n",
      "-------------  ---------  ---------------------  -------------------\n",
      "call_function  sum_2                0.00151348             65.9807\n",
      "call_function  add                  0.000243425            10.6122\n",
      "call_function  getitem              0.000112772             4.91633\n",
      "call_function  sum_1                6.62804e-05             2.88951\n",
      "placeholder    x                    4.50611e-05             1.96445\n",
      "call_function  getitem_1            2.98023e-05             1.29924\n",
      "output         output               1.74046e-05             0.758757\n"
     ]
    }
   ],
   "source": [
    "interp = ProfilingInterpreter(ReduceSum2(10))\n",
    "interp.run(torch.ones((4096,100,64)))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 2.5224685668945312 ms\n",
      "Op type        Op           Average runtime (s)    Pct total runtime\n",
      "-------------  ---------  ---------------------  -------------------\n",
      "call_function  sum_2                0.00163412             64.7826\n",
      "call_function  add                  0.000206947             8.20416\n",
      "call_function  getitem              0.000155449             6.16257\n",
      "call_function  sum_1                7.65324e-05             3.03403\n",
      "placeholder    x                    6.05583e-05             2.40076\n",
      "call_function  getitem_1            3.09944e-05             1.22873\n",
      "output         output               1.78814e-05             0.708885\n"
     ]
    }
   ],
   "source": [
    "interp = ProfilingInterpreter(ReduceSum2(30))\n",
    "interp.run(torch.ones((4096,100,64)))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 1.550436019897461 ms\n",
      "Op type        Op           Average runtime (s)    Pct total runtime\n",
      "-------------  ---------  ---------------------  -------------------\n",
      "call_function  sum_2                0.000878096             56.6354\n",
      "call_function  add                  0.000147581              9.51868\n",
      "call_function  getitem              0.000106096              6.843\n",
      "call_function  sum_1                6.36578e-05              4.1058\n",
      "placeholder    x                    4.95911e-05              3.19852\n",
      "call_function  getitem_1            3.02792e-05              1.95294\n",
      "output         output               1.69277e-05              1.0918\n"
     ]
    }
   ],
   "source": [
    "interp = ProfilingInterpreter(ReduceSum2(50))\n",
    "interp.run(torch.ones((4096,100,64)))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 1.5528202056884766 ms\n",
      "Op type        Op           Average runtime (s)    Pct total runtime\n",
      "-------------  ---------  ---------------------  -------------------\n",
      "call_function  sum_2                0.000640392             41.2406\n",
      "call_function  getitem              0.000158787             10.2257\n",
      "call_function  add                  0.000153303              9.87256\n",
      "call_function  sum_1                9.53674e-05              6.14156\n",
      "placeholder    x                    7.86781e-05              5.06679\n",
      "call_function  getitem_1            3.05176e-05              1.9653\n",
      "output         output               1.64509e-05              1.05942\n"
     ]
    }
   ],
   "source": [
    "interp = ProfilingInterpreter(ReduceSum2(70))\n",
    "interp.run(torch.ones((4096,100,64)))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 0.9617805480957031 ms\n",
      "Op type        Op           Average runtime (s)    Pct total runtime\n",
      "-------------  ---------  ---------------------  -------------------\n",
      "call_function  sum_2                0.000333071             34.6306\n",
      "call_function  add                  0.000117064             12.1715\n",
      "call_function  getitem              0.000106812             11.1056\n",
      "call_function  sum_1                6.41346e-05              6.66832\n",
      "placeholder    x                    4.86374e-05              5.05702\n",
      "call_function  getitem_1            3.05176e-05              3.17303\n",
      "output         output               1.45435e-05              1.51215\n"
     ]
    }
   ],
   "source": [
    "interp = ProfilingInterpreter(ReduceSum2(90))\n",
    "interp.run(torch.ones((4096,100,64)))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PowModel(torch.nn.Module):\n",
    "  \n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "        \n",
    "  def forward(self,x):\n",
    "    return x** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PowModel2(torch.nn.Module):\n",
    "  \n",
    "  def __init__(self,prefix):\n",
    "    super().__init__()\n",
    "    self.prefix = prefix\n",
    "        \n",
    "  def forward(self,x):\n",
    "    prefix_x = x[0,:self.prefix] ** 2\n",
    "    suf_x = x[:,self.prefix:] ** 2\n",
    "    batch = x.shape[0]\n",
    "    \n",
    "    return torch.concat([prefix_x.unsqueeze(0).expand(batch, -1, -1),suf_x],dim = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 8.81505012512207 ms\n",
      "Op type        Op        Average runtime (s)    Pct total runtime\n",
      "-------------  ------  ---------------------  -------------------\n",
      "call_function  pow_1             0.0084641              96.0187\n",
      "output         output            5.74589e-05             0.651827\n",
      "placeholder    x                 4.57764e-05             0.519298\n"
     ]
    }
   ],
   "source": [
    "interp = ProfilingInterpreter(PowModel())\n",
    "interp.run(torch.ones((4096,100,64)))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 43.656349182128906 ms\n",
      "Op type        Op           Average runtime (s)    Pct total runtime\n",
      "-------------  ---------  ---------------------  -------------------\n",
      "call_method    expand               0.0200114             45.8385\n",
      "call_function  concat               0.00998378            22.869\n",
      "call_function  pow_2                0.00773883            17.7267\n",
      "call_function  getitem              0.00011754             0.26924\n",
      "call_method    unsqueeze            0.000117302            0.268694\n",
      "call_function  pow_1                7.10487e-05            0.162745\n",
      "call_function  getattr_1            6.67572e-05            0.152915\n",
      "output         output               5.14984e-05            0.117963\n",
      "placeholder    x                    4.93526e-05            0.113048\n",
      "call_function  getitem_1            4.31538e-05            0.0988488\n",
      "call_function  getitem_2            1.66893e-05            0.0382288\n"
     ]
    }
   ],
   "source": [
    "interp = ProfilingInterpreter(PowModel2(10))\n",
    "interp.run(torch.ones((4096,100,64)))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 16.831398010253906 ms\n",
      "Op type        Op           Average runtime (s)    Pct total runtime\n",
      "-------------  ---------  ---------------------  -------------------\n",
      "call_function  concat               0.00654864            38.9073\n",
      "call_function  pow_2                0.0053122             31.5613\n",
      "call_function  getitem              0.000133753            0.794663\n",
      "call_function  pow_1                6.7234e-05             0.399456\n",
      "call_function  getattr_1            6.69956e-05            0.39804\n",
      "output         output               6.53267e-05            0.388124\n",
      "call_method    unsqueeze            6.03199e-05            0.358377\n",
      "placeholder    x                    5.14984e-05            0.305966\n",
      "call_method    expand               4.88758e-05            0.290385\n",
      "call_function  getitem_1            4.14848e-05            0.246473\n",
      "call_function  getitem_2            1.64509e-05            0.0977392\n"
     ]
    }
   ],
   "source": [
    "interp = ProfilingInterpreter(PowModel2(30))\n",
    "interp.run(torch.ones((4096,100,64)))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 14.839410781860352 ms\n",
      "Op type        Op           Average runtime (s)    Pct total runtime\n",
      "-------------  ---------  ---------------------  -------------------\n",
      "call_function  concat               0.00646448             43.5629\n",
      "call_function  pow_2                0.00459886             30.9908\n",
      "call_function  getitem              0.00010848              0.731029\n",
      "call_function  pow_1                6.58035e-05             0.443438\n",
      "call_function  getattr_1            6.31809e-05             0.425764\n",
      "output         output               5.60284e-05             0.377565\n",
      "call_method    unsqueeze            4.93526e-05             0.332578\n",
      "call_method    expand               4.64916e-05             0.313298\n",
      "placeholder    x                    4.60148e-05             0.310085\n",
      "call_function  getitem_1            4.33922e-05             0.292412\n",
      "call_function  getitem_2            1.64509e-05             0.110859\n"
     ]
    }
   ],
   "source": [
    "interp = ProfilingInterpreter(PowModel2(50))\n",
    "interp.run(torch.ones((4096,100,64)))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 8.581399917602539 ms\n",
      "Op type        Op           Average runtime (s)    Pct total runtime\n",
      "-------------  ---------  ---------------------  -------------------\n",
      "call_function  concat               0.00681329             79.396\n",
      "call_function  pow_2                0.00101066             11.7773\n",
      "call_function  getitem              0.000104427             1.2169\n",
      "call_function  pow_1                6.77109e-05             0.789042\n",
      "call_function  getattr_1            4.62532e-05             0.538994\n",
      "placeholder    x                    4.55379e-05             0.530659\n",
      "call_method    unsqueeze            4.43459e-05             0.516767\n",
      "call_method    expand               4.43459e-05             0.516767\n",
      "call_function  getitem_1            4.31538e-05             0.502876\n",
      "output         output               4.17233e-05             0.486206\n",
      "call_function  getitem_2            1.66893e-05             0.194482\n"
     ]
    }
   ],
   "source": [
    "interp = ProfilingInterpreter(PowModel2(70))\n",
    "interp.run(torch.ones((4096,100,64)))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 8.481979370117188 ms\n",
      "Op type        Op           Average runtime (s)    Pct total runtime\n",
      "-------------  ---------  ---------------------  -------------------\n",
      "call_function  concat               0.0072372              85.3244\n",
      "call_function  pow_2                0.000499725             5.89161\n",
      "call_function  getitem              0.000110149             1.29863\n",
      "call_function  pow_1                7.31945e-05             0.862941\n",
      "placeholder    x                    4.64916e-05             0.548122\n",
      "call_function  getitem_1            4.45843e-05             0.525635\n",
      "call_method    expand               4.43459e-05             0.522824\n",
      "call_method    unsqueeze            4.05312e-05             0.47785\n",
      "output         output               4.00543e-05             0.472228\n",
      "call_function  getattr_1            3.60012e-05             0.424443\n",
      "call_function  getitem_2            1.5974e-05              0.188329\n"
     ]
    }
   ],
   "source": [
    "interp = ProfilingInterpreter(PowModel2(90))\n",
    "interp.run(torch.ones((4096,100,64)))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_func(x):\n",
    "  y = x + 1\n",
    "  z = x + 2\n",
    "  return y + z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    add = x + 1\n",
      "    add_1 = x + 2;  x = None\n",
      "    add_2 = add + add_1;  add = add_1 = None\n",
      "    return add_2\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "trace = fx.symbolic_trace(test_func)\n",
    "print(trace.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name    target                   args          kwargs\n",
      "-------------  ------  -----------------------  ------------  --------\n",
      "placeholder    x       x                        ()            {}\n",
      "call_function  add     <built-in function add>  (x, 1)        {}\n",
      "call_function  add_1   <built-in function add>  (x, 2)        {}\n",
      "call_function  add_2   <built-in function add>  (add, add_1)  {}\n",
      "output         output  output                   (add_2,)      {}\n"
     ]
    }
   ],
   "source": [
    "trace.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = trace.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = {}\n",
    "for node in graph.nodes:\n",
    "  env[node.name] = node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "modify_node = env['add']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "modify_node.args = (env['x'],114514)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name    target                   args          kwargs\n",
      "-------------  ------  -----------------------  ------------  --------\n",
      "placeholder    x       x                        ()            {}\n",
      "call_function  add     <built-in function add>  (x, 114514)   {}\n",
      "call_function  add_1   <built-in function add>  (x, 2)        {}\n",
      "call_function  add_2   <built-in function add>  (add, add_1)  {}\n",
      "output         output  output                   (add_2,)      {}\n"
     ]
    }
   ],
   "source": [
    "graph.lint()\n",
    "graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "modify_mod = GraphModule(torch.nn.Module(), graph)\n",
    "torch.onnx.export(modify_mod,torch.ones((4096,10,22)),f'modify_mod.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rewrite as rw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducesum_func(x):\n",
    "  return torch.sum(x,dim = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced = fx.symbolic_trace(reducesum_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reducesum_func()\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    sum_1 = torch.sum(x, dim = 1);  x = None\n",
      "    return sum_1\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n"
     ]
    }
   ],
   "source": [
    "print(traced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name    target                                                  args      kwargs\n",
      "-------------  ------  ------------------------------------------------------  --------  ----------\n",
      "placeholder    x       x                                                       ()        {}\n",
      "call_function  sum_1   <built-in method sum of type object at 0x7f09e1978760>  (x,)      {'dim': 1}\n",
      "output         output  output                                                  (sum_1,)  {}\n"
     ]
    }
   ],
   "source": [
    "traced.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = rewrite(traced,(0,slice(None,10,None)),(slice(None,None,None),slice(10,None,None)),'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name       target                                                  args                                                   kwargs\n",
      "-------------  ---------  ------------------------------------------------------  -----------------------------------------------------  ----------\n",
      "placeholder    x          x                                                       ()                                                     {}\n",
      "call_function  getitem    <built-in function getitem>                             (x, (0, slice(None, 10, None)))                        {}\n",
      "call_function  sum_2      <built-in method sum of type object at 0x7f09e1978760>  (getitem,)                                             {'dim': 0}\n",
      "call_function  getitem_1  <built-in function getitem>                             (x, (slice(None, None, None), slice(10, None, None)))  {}\n",
      "call_function  sum_3      <built-in method sum of type object at 0x7f09e1978760>  (getitem_1,)                                           {'dim': 1}\n",
      "call_function  add        <built-in method add of type object at 0x7f09e1978760>  (sum_2, sum_3)                                         {}\n",
      "output         output_1   output                                                  (add,)                                                 {}\n"
     ]
    }
   ],
   "source": [
    "graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced1 = fx.symbolic_trace(reducesum_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "def reducesum_rewrite(traced,redency_part_slice,unredency_part_slice,input_node_name,target_node_name):\n",
    "  graph = traced.graph\n",
    "  env  = utils.get_env(traced)\n",
    "  input_node = env[input_node_name]\n",
    "  target_node = env[target_node_name]\n",
    "  with graph.inserting_before(target_node):\n",
    "    # 冗余数据提取\n",
    "    new_redency_extract_node = graph.call_function(operator.getitem,(input_node,redency_part_slice))\n",
    "    # 非冗余数据提取\n",
    "    new_unredency_extract_node = graph.call_function(operator.getitem,(input_node,unredency_part_slice))\n",
    "    \n",
    "    # 冗余部分计算\n",
    "    new_redency_sum_node = graph.call_function(torch.sum,(new_redency_extract_node,),{'dim':0})\n",
    "    # 非冗余数据计算\n",
    "    new_unredency_sum_node = graph.call_function(torch.sum,(new_unredency_extract_node,),{'dim':1})\n",
    "    # 操作还原\n",
    "    new_add_node = graph.call_function(torch.add,(new_redency_sum_node,new_unredency_sum_node))\n",
    "    utils.replace_use_with(target_node,new_add_node)\n",
    "  # map_dict = get_successors_map(traced)\n",
    "  # successors = map_dict[target_node_name]\n",
    "  # for successor in successors:\n",
    "  #   successor_node = env[successor]\n",
    "  #   arg_tuple = successor_node.args\n",
    "  #   new_tuple = list(arg_tuple)\n",
    "    \n",
    "  # graph.erase_node(env['output'])\n",
    "  # graph.output(new_add_node)\n",
    "  graph.eliminate_dead_code()\n",
    "  graph.lint() \n",
    "  return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph1 = reducesum_rewrite(traced1,(0,slice(None,10,None)),(slice(None,None,None),slice(10,None,None)),'x','sum_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name       target                                                  args                                                   kwargs\n",
      "-------------  ---------  ------------------------------------------------------  -----------------------------------------------------  ----------\n",
      "placeholder    x          x                                                       ()                                                     {}\n",
      "call_function  getitem    <built-in function getitem>                             (x, (0, slice(None, 10, None)))                        {}\n",
      "call_function  getitem_1  <built-in function getitem>                             (x, (slice(None, None, None), slice(10, None, None)))  {}\n",
      "call_function  sum_2      <built-in method sum of type object at 0x7f09e1978760>  (getitem,)                                             {'dim': 0}\n",
      "call_function  sum_3      <built-in method sum of type object at 0x7f09e1978760>  (getitem_1,)                                           {'dim': 1}\n",
      "call_function  add        <built-in method add of type object at 0x7f09e1978760>  (sum_2, sum_3)                                         {}\n",
      "output         output     output                                                  (add,)                                                 {}\n"
     ]
    }
   ],
   "source": [
    "graph1.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducesum_func1(x):\n",
    "  return torch.sum(x,dim = 1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced1 = fx.symbolic_trace(reducesum_func1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reducesum_func1()\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    sum_1 = torch.sum(x, dim = 1);  x = None\n",
      "    add = sum_1 + 1;  sum_1 = None\n",
      "    return add\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n"
     ]
    }
   ],
   "source": [
    "print(traced1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name    target                                                  args        kwargs\n",
      "-------------  ------  ------------------------------------------------------  ----------  ----------\n",
      "placeholder    x       x                                                       ()          {}\n",
      "call_function  sum_1   <built-in method sum of type object at 0x7f2d25674760>  (x,)        {'dim': 1}\n",
      "call_function  add     <built-in function add>                                 (sum_1, 1)  {}\n",
      "output         output  output                                                  (add,)      {}\n"
     ]
    }
   ],
   "source": [
    "traced1.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph1 = rewrite(traced1,(0,slice(None,10,None)),(slice(None,None,None),slice(10,None,None)),'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name       target                                                  args                                                   kwargs\n",
      "-------------  ---------  ------------------------------------------------------  -----------------------------------------------------  ----------\n",
      "placeholder    x          x                                                       ()                                                     {}\n",
      "call_function  getitem    <built-in function getitem>                             (x, (0, slice(None, 10, None)))                        {}\n",
      "call_function  sum_2      <built-in method sum of type object at 0x7f2d25674760>  (getitem,)                                             {'dim': 0}\n",
      "call_function  getitem_1  <built-in function getitem>                             (x, (slice(None, None, None), slice(10, None, None)))  {}\n",
      "call_function  sum_3      <built-in method sum of type object at 0x7f2d25674760>  (getitem_1,)                                           {'dim': 1}\n",
      "call_function  add_1      <built-in method add of type object at 0x7f2d25674760>  (sum_2, sum_3)                                         {}\n",
      "output         output_1   output                                                  (add_1,)                                               {}\n"
     ]
    }
   ],
   "source": [
    "graph1.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_func(x):\n",
    "  l1 = torch.nn.Linear(100,300)\n",
    "  l2 = torch.nn.Linear(300,200)\n",
    "  return l2(l1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel2(torch.nn.Module):\n",
    "  \n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super().__init__()\n",
    "    self.mlp = torch.nn.Linear(input_dim, output_dim)\n",
    "    self.mlp2 = torch.nn.Linear(output_dim,1)\n",
    "    \n",
    "  def forward(self,x):\n",
    "    return self.mlp2(self.mlp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = torch.fx.symbolic_trace(TestModel2(100,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestModel2(\n",
      "  (mlp): Linear(in_features=100, out_features=200, bias=True)\n",
      "  (mlp2): Linear(in_features=200, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    mlp = self.mlp(x);  x = None\n",
      "    mlp2 = self.mlp2(mlp);  mlp = None\n",
      "    return mlp2\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n"
     ]
    }
   ],
   "source": [
    "print(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class TestModel2(torch.nn.Module):\n",
      "    def forward(self, x):\n",
      "        # No stacktrace found for following nodes\n",
      "        mlp = self.mlp(x);  x = None\n",
      "        mlp2 = self.mlp2(mlp);  mlp = None\n",
      "        return mlp2\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'class TestModel2(torch.nn.Module):\\n    def forward(self, x):\\n        # No stacktrace found for following nodes\\n        mlp = self.mlp(x);  x = None\\n        mlp2 = self.mlp2(mlp);  mlp = None\\n        return mlp2\\n        '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace.print_readable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode       name    target    args     kwargs\n",
      "-----------  ------  --------  -------  --------\n",
      "placeholder  x       x         ()       {}\n",
      "call_module  mlp     mlp       (x,)     {}\n",
      "call_module  mlp2    mlp2      (mlp,)   {}\n",
      "output       output  output    (mlp2,)  {}\n"
     ]
    }
   ],
   "source": [
    "trace.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = getattr(trace,'mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_rewrite(traced,redency_part_slice,unredency_part_slice,input_node_name,target_node_name):\n",
    "  graph = traced.graph\n",
    "  env = utils.get_env(traced)\n",
    "  input_node = env[input_node_name]\n",
    "  target_node = env[target_node_name]\n",
    "  target_node_mod = utils.get_target_mod(traced,target_node_name,'_')\n",
    "  target_weight = target_node_mod.weight\n",
    "  target_bias = target_node_mod.bias\n",
    "  \n",
    "  # redency_linear\n",
    "  redency_weight = target_weight[:,redency_part_slice[1]]\n",
    "  redency_linear = torch.nn.Linear(redency_weight.shape[0],redency_weight.shape[1])\n",
    "  redency_linear.weight.data = redency_weight\n",
    "  redency_linear.bias.data = target_bias\n",
    "  \n",
    "  # unredency_linear\n",
    "  unredency_weight = target_weight[:,unredency_part_slice[1]]\n",
    "  unredency_linear = torch.nn.Linear(unredency_weight.shape[0],unredency_weight.shape[1],bias=False)\n",
    "  unredency_linear.weight.data = unredency_weight\n",
    "  \n",
    "  traced.register_module(f\"{target_node_name}_redency\",redency_linear)\n",
    "  traced.register_module(f\"{target_node_name}_unredency\",unredency_linear)\n",
    "  with graph.inserting_before(target_node):\n",
    "    # 冗余数据提取\n",
    "    new_redency_extract_node = graph.call_function(operator.getitem,(input_node,redency_part_slice))\n",
    "    # 非冗余数据提取\n",
    "    new_unredency_extract_node = graph.call_function(operator.getitem,(input_node,unredency_part_slice))\n",
    "\n",
    "    \n",
    "    # 冗余计算\n",
    "    new_redency_compute_node = graph.call_module(f\"{target_node_name}_redency\",(new_redency_extract_node,))\n",
    "    # 非冗余计算\n",
    "    new_unrendency_compute_node = graph.call_module(f\"{target_node_name}_unredency\",(new_unredency_extract_node,))\n",
    "    new_add_node = graph.call_function(torch.add,(new_redency_compute_node,new_unrendency_compute_node))\n",
    "    utils.replace_use_with(target_node,new_add_node)\n",
    "  graph.eliminate_dead_code()\n",
    "  graph.lint() \n",
    "  return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = linear_rewrite(trace,(0,slice(None,10,None)),(slice(None,None,None),slice(10,None,None)),'x','mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name           target                                                  args                                                   kwargs\n",
      "-------------  -------------  ------------------------------------------------------  -----------------------------------------------------  --------\n",
      "placeholder    x              x                                                       ()                                                     {}\n",
      "call_function  getitem        <built-in function getitem>                             (x, (0, slice(None, 10, None)))                        {}\n",
      "call_function  getitem_1      <built-in function getitem>                             (x, (slice(None, None, None), slice(10, None, None)))  {}\n",
      "call_module    mlp_redency    mlp_redency                                             (getitem,)                                             {}\n",
      "call_module    mlp_unredency  mlp_unredency                                           (getitem_1,)                                           {}\n",
      "call_function  add            <built-in method add of type object at 0x7f09e1978760>  (mlp_redency, mlp_unredency)                           {}\n",
      "call_module    mlp2           mlp2                                                    (add,)                                                 {}\n",
      "output         output         output                                                  (mlp2,)                                                {}\n"
     ]
    }
   ],
   "source": [
    "graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "modify_mod = GraphModule(trace, graph)\n",
    "torch.onnx.export(modify_mod,torch.ones((4096,100)),f'modify_mod_ll.onnx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepctr-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
