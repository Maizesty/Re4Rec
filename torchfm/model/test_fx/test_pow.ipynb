{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace success!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import fm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.fx import subgraph_rewriter, symbolic_trace\n",
    "import utils\n",
    "from torch.fx import Proxy, Graph, GraphModule\n",
    "from torch.fx.passes.utils.matcher_utils import SubgraphMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pow(x):\n",
    "  return x ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pow_traced = symbolic_trace(pow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total true time 11.011362075805664 ms\n",
      "total time: 11.199712753295898 ms\n",
      "Op type        Op        Average runtime (ms)    Pct total runtime\n",
      "-------------  ------  ----------------------  -------------------\n",
      "call_function  pow_1               10.9253               97.5498\n",
      "output         output               0.0503063             0.449175\n",
      "placeholder    x                    0.0357628             0.319319\n"
     ]
    }
   ],
   "source": [
    "interp = utils.ProfilingInterpreter(pow_traced)\n",
    "interp.run(torch.randint(low=0, high=88, size=(4096,100,32), dtype=torch.long))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_onnx = 'model_ori.onnx'\n",
    "torch.onnx.export(pow_traced,               # 模型 being run\n",
    "                  torch.randint(low=0, high=88, size=(4096,100,32), dtype=torch.long),                  # 模型输入 (or a tuple for multiple inputs)\n",
    "                  output_onnx,        # where to save the model (can be a file or file-like object)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pow_modify(x):\n",
    "  y = torch.empty((4096,100,32))\n",
    "  y[:,:50,:] = x[0,:50,:] ** 2\n",
    "  y[:,50:,:] = x[:,50:,:] ** 2\n",
    "  return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_onnx = 'model.onnx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pow_modify_traced = symbolic_trace(pow_modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(pow_modify_traced,               # 模型 being run\n",
    "                  torch.randint(low=0, high=88, size=(4096,100,32), dtype=torch.long),                  # 模型输入 (or a tuple for multiple inputs)\n",
    "                  output_onnx,        # where to save the model (can be a file or file-like object)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplified model has been saved to model.onnx\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnxsim import simplify\n",
    "\n",
    "# 加载ONNX模型\n",
    "model_path = output_onnx  # 替换为你的ONNX模型路径\n",
    "original_model = onnx.load(model_path)\n",
    "\n",
    "# 简化模型\n",
    "simplified_model, check = simplify(original_model)\n",
    "\n",
    "# 检查简化是否成功\n",
    "assert check, \"Simplified ONNX model could not be validated\"\n",
    "\n",
    "# 保存简化后的模型\n",
    "simplified_model_path = output_onnx  # 替换为简化后模型的保存路径\n",
    "onnx.save(simplified_model, simplified_model_path)\n",
    "\n",
    "print(f\"Simplified model has been saved to {simplified_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class pow_modify(torch.nn.Module):\n",
      "    def forward(self, x):\n",
      "        # No stacktrace found for following nodes\n",
      "        getitem = x[(0, slice(None, 50, None), slice(None, None, None))]\n",
      "        pow_1 = getitem ** 2;  getitem = None\n",
      "        _tensor_constant0 = self._tensor_constant0\n",
      "        setitem = _tensor_constant0.__setitem__((slice(None, None, None), slice(None, 50, None), slice(None, None, None)), pow_1);  _tensor_constant0 = pow_1 = None\n",
      "        getitem_1 = x[(slice(None, None, None), slice(50, None, None), slice(None, None, None))];  x = None\n",
      "        pow_2 = getitem_1 ** 2;  getitem_1 = None\n",
      "        _tensor_constant0_1 = self._tensor_constant0\n",
      "        setitem_1 = _tensor_constant0_1.__setitem__((slice(None, None, None), slice(50, None, None), slice(None, None, None)), pow_2);  _tensor_constant0_1 = pow_2 = None\n",
      "        _tensor_constant0_2 = self._tensor_constant0\n",
      "        return _tensor_constant0_2\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'class pow_modify(torch.nn.Module):\\n    def forward(self, x):\\n        # No stacktrace found for following nodes\\n        getitem = x[(0, slice(None, 50, None), slice(None, None, None))]\\n        pow_1 = getitem ** 2;  getitem = None\\n        _tensor_constant0 = self._tensor_constant0\\n        setitem = _tensor_constant0.__setitem__((slice(None, None, None), slice(None, 50, None), slice(None, None, None)), pow_1);  _tensor_constant0 = pow_1 = None\\n        getitem_1 = x[(slice(None, None, None), slice(50, None, None), slice(None, None, None))];  x = None\\n        pow_2 = getitem_1 ** 2;  getitem_1 = None\\n        _tensor_constant0_1 = self._tensor_constant0\\n        setitem_1 = _tensor_constant0_1.__setitem__((slice(None, None, None), slice(50, None, None), slice(None, None, None)), pow_2);  _tensor_constant0_1 = pow_2 = None\\n        _tensor_constant0_2 = self._tensor_constant0\\n        return _tensor_constant0_2\\n        '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_modify_traced.print_readable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total true time 7.445096969604492 ms\n",
      "total time: 11.996269226074219 ms\n",
      "Op type        Op                     Average runtime (ms)    Pct total runtime\n",
      "-------------  -------------------  ----------------------  -------------------\n",
      "call_function  pow_2                             5.27978             44.0118\n",
      "call_method    setitem_1                         0.944138             7.87026\n",
      "call_method    setitem                           0.827789             6.90039\n",
      "call_function  getitem                           0.0925064            0.771126\n",
      "call_function  getitem_1                         0.0760555            0.633993\n",
      "call_function  pow_1                             0.0598431            0.498847\n",
      "get_attr       _tensor_constant0_1               0.0522137            0.435249\n",
      "get_attr       _tensor_constant0_2               0.0474453            0.3955\n",
      "placeholder    x                                 0.0348091            0.290166\n",
      "get_attr       _tensor_constant0                 0.020504             0.17092\n",
      "output         output                            0.0100136            0.0834725\n"
     ]
    }
   ],
   "source": [
    "interp = utils.ProfilingInterpreter(pow_modify_traced)\n",
    "interp.run(torch.randint(low=0, high=88, size=(4096,100,32), dtype=torch.long))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pow_modify1(x):\n",
    "  x0 = x[0,:50,:] ** 2\n",
    "  x1 = x[:,50:,:] ** 2\n",
    "  x0 = x0.repeat(4096,1,1)\n",
    "  \n",
    "  return torch.concat([x0,x1], dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pow_modify_traced1 = symbolic_trace(pow_modify1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_onnx = 'model_concat.onnx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(pow_modify_traced1,               # 模型 being run\n",
    "                  torch.randint(low=0, high=88, size=(4096,100,32), dtype=torch.long),                  # 模型输入 (or a tuple for multiple inputs)\n",
    "                  output_onnx,        # where to save the model (can be a file or file-like object)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total true time 18.984079360961914 ms\n",
      "total time: 27.439594268798828 ms\n",
      "Op type        Op           Average runtime (ms)    Pct total runtime\n",
      "-------------  ---------  ----------------------  -------------------\n",
      "call_function  concat                  6.90866              25.1777\n",
      "call_method    repeat                  6.0451               22.0306\n",
      "call_function  pow_2                   5.76925              21.0253\n",
      "call_function  getitem                 0.0889301             0.324094\n",
      "call_function  pow_1                   0.0545979             0.198975\n",
      "output         output                  0.0545979             0.198975\n",
      "placeholder    x                       0.0360012             0.131202\n",
      "call_function  getitem_1               0.0269413             0.098184\n"
     ]
    }
   ],
   "source": [
    "interp = utils.ProfilingInterpreter(pow_modify_traced1)\n",
    "interp.run(torch.randint(low=0, high=88, size=(4096,100,32), dtype=torch.long))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = ort.InferenceSession('model_ori.onnx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183 ms ± 4.06 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 session.run(None,{'x' : np.random.randint(low=0, high=88, size=(4096, 100,32), dtype=np.int64)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = ort.InferenceSession('model.onnx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351 ms ± 13.6 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 session.run(None,{'onnx::Gather_0' : np.random.randint(low=0, high=88, size=(4096, 100,32), dtype=np.int64)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplified model has been saved to model_concat.onnx\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnxsim import simplify\n",
    "\n",
    "# 加载ONNX模型\n",
    "model_path = output_onnx  # 替换为你的ONNX模型路径\n",
    "original_model = onnx.load(model_path)\n",
    "\n",
    "# 简化模型\n",
    "simplified_model, check = simplify(original_model)\n",
    "\n",
    "# 检查简化是否成功\n",
    "assert check, \"Simplified ONNX model could not be validated\"\n",
    "\n",
    "# 保存简化后的模型\n",
    "simplified_model_path = output_onnx  # 替换为简化后模型的保存路径\n",
    "onnx.save(simplified_model, simplified_model_path)\n",
    "\n",
    "print(f\"Simplified model has been saved to {simplified_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = ort.InferenceSession('model_concat.onnx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214 ms ± 17.1 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 30 session.run(None,{'onnx::Gather_0' : np.random.randint(low=0, high=88, size=(4096, 100,32), dtype=np.int64)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testModel(torch.nn.Module):\n",
    "  def __init__(self,):\n",
    "    super().__init__()\n",
    "    self.linear = nn.Linear(in_features=400,out_features=400)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = testModel()\n",
    "torch.onnx.export(model,torch.ones((1024,1,200,400)),'testmodel.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_product(x):\n",
    "  square_of_sum = torch.sum(x, dim=1) ** 2\n",
    "  sum_of_square = torch.sum(x ** 2, dim=1)\n",
    "  ix = square_of_sum - sum_of_square\n",
    "  return 0.5 * ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_product(x):\n",
    "  sum_of_x = torch.sum(x, dim = 1)\n",
    "  square_of_sum = torch.pow(sum_of_x, 2)\n",
    "  square_of_x = torch.pow(x, 2)\n",
    "  sum_of_square = torch.sum(square_of_x, dim = 1)\n",
    "  ix = torch.sub(square_of_sum, sum_of_square)\n",
    "  return torch.mul(ix, 0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepctr-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
