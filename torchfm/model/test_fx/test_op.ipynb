{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace success!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.fx import subgraph_rewriter, symbolic_trace\n",
    "import utils\n",
    "from torch.fx import Proxy, Graph, GraphModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "numbers = list(range(100))\n",
    "random.shuffle(numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeOrder(x):\n",
    "  x = torch.abs(x)\n",
    "  return x[:,numbers,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "changeOrder_model = symbolic_trace(changeOrder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class changeOrder(torch.nn.Module):\n",
      "    def forward(self, x):\n",
      "        # No stacktrace found for following nodes\n",
      "        abs_1 = torch.abs(x);  x = None\n",
      "        getitem = abs_1[(slice(None, None, None), [92, 60, 58, 53, 23, 97, 57, 95, 85, 72, 5, 38, 43, 54, 51, 2, 14, 55, 67, 33, 63, 19, 25, 40, 82, 35, 4, 77, 32, 87, 13, 10, 8, 28, 90, 94, 69, 36, 39, 42, 50, 34, 49, 31, 56, 12, 52, 70, 21, 9, 24, 48, 59, 64, 47, 20, 76, 75, 7, 26, 1, 81, 30, 88, 65, 0, 27, 99, 3, 86, 80, 93, 66, 62, 79, 68, 91, 41, 83, 6, 18, 98, 22, 45, 44, 96, 46, 78, 74, 84, 17, 61, 16, 11, 37, 15, 71, 89, 29, 73], slice(None, None, None))];  abs_1 = None\n",
      "        return getitem\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'class changeOrder(torch.nn.Module):\\n    def forward(self, x):\\n        # No stacktrace found for following nodes\\n        abs_1 = torch.abs(x);  x = None\\n        getitem = abs_1[(slice(None, None, None), [92, 60, 58, 53, 23, 97, 57, 95, 85, 72, 5, 38, 43, 54, 51, 2, 14, 55, 67, 33, 63, 19, 25, 40, 82, 35, 4, 77, 32, 87, 13, 10, 8, 28, 90, 94, 69, 36, 39, 42, 50, 34, 49, 31, 56, 12, 52, 70, 21, 9, 24, 48, 59, 64, 47, 20, 76, 75, 7, 26, 1, 81, 30, 88, 65, 0, 27, 99, 3, 86, 80, 93, 66, 62, 79, 68, 91, 41, 83, 6, 18, 98, 22, 45, 44, 96, 46, 78, 74, 84, 17, 61, 16, 11, 37, 15, 71, 89, 29, 73], slice(None, None, None))];  abs_1 = None\\n        return getitem\\n        '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changeOrder_model.print_readable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total true time 21.66295051574707 ms\n",
      "total time: 30.247211456298828 ms\n",
      "Op type        Op         Average runtime (ms)    Pct total runtime\n",
      "-------------  -------  ----------------------  -------------------\n",
      "call_function  getitem              11.1754               36.9469\n",
      "call_function  abs_1                10.366                34.2708\n",
      "output         output                0.0724792             0.239623\n",
      "placeholder    x                     0.0491142             0.162376\n"
     ]
    }
   ],
   "source": [
    "interp = utils.ProfilingInterpreter(changeOrder_model)\n",
    "interp.run(torch.randint(low=0, high=88, size=(4096,100,32), dtype=torch.long))\n",
    "print(interp.summary(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name     target                       args                                                                   kwargs\n",
      "-------------  -------  ---------------------------  ---------------------------------------------------------------------  --------\n",
      "placeholder    x        x                            ()                                                                     {}\n",
      "call_function  getitem  <built-in function getitem>  (x, (slice(None, None, None), [3, 4, 2, 1], slice(None, None, None)))  {}\n",
      "output         output   output                       (getitem,)                                                             {}\n"
     ]
    }
   ],
   "source": [
    "changeOrder_model.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_func(x):\n",
    "  return x.view(-1,2)\n",
    "\n",
    "def reshape_func(x):\n",
    "  return x.reshape(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_model = fx.symbolic_trace(view_func)\n",
    "reshape_model = fx.symbolic_trace(reshape_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    view = x.view(-1, 2);  x = None\n",
      "    return view\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(view_model.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode       name    target    args        kwargs\n",
      "-----------  ------  --------  ----------  --------\n",
      "placeholder  x       x         ()          {}\n",
      "call_method  view    view      (x, -1, 2)  {}\n",
      "output       output  output    (view,)     {}\n"
     ]
    }
   ],
   "source": [
    "view_model.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    reshape = x.reshape(-1, 2);  x = None\n",
      "    return reshape\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(reshape_model.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode       name     target    args        kwargs\n",
      "-----------  -------  --------  ----------  --------\n",
      "placeholder  x        x         ()          {}\n",
      "call_method  reshape  reshape   (x, -1, 2)  {}\n",
      "output       output   output    (reshape,)  {}\n"
     ]
    }
   ],
   "source": [
    "reshape_model.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat(x):\n",
    "  return x.repeat(4096,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_model = fx.symbolic_trace(repeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    repeat = x.repeat(4096, 1, 1);  x = None\n",
      "    return repeat\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(repeat_model.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode       name    target    args             kwargs\n",
      "-----------  ------  --------  ---------------  --------\n",
      "placeholder  x       x         ()               {}\n",
      "call_method  repeat  repeat    (x, 4096, 1, 1)  {}\n",
      "output       output  output    (repeat,)        {}\n"
     ]
    }
   ],
   "source": [
    "repeat_model.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(11,11,11)\n",
    "\n",
    "x[:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat(x,y):\n",
    "  return x @ y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_model = fx.symbolic_trace(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name    target                      args       kwargs\n",
      "-------------  ------  --------------------------  ---------  --------\n",
      "placeholder    x       x                           ()         {}\n",
      "placeholder    y       y                           ()         {}\n",
      "call_function  matmul  <built-in function matmul>  (x, y)     {}\n",
      "output         output  output                      (matmul,)  {}\n"
     ]
    }
   ],
   "source": [
    "mat_model.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(type):\n",
    "  def mat_func(x,y):\n",
    "    return x @ y\n",
    "  \n",
    "  def add_func(x,y):\n",
    "    return x + y\n",
    "  \n",
    "  if type ==\"mat\":\n",
    "    return mat_func\n",
    "  else:\n",
    "    return add_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_model = fx.symbolic_trace(func(\"mat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class mat_func(torch.nn.Module):\n",
      "    def forward(self, x, y):\n",
      "        # No stacktrace found for following nodes\n",
      "        matmul = x @ y;  x = y = None\n",
      "        return matmul\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'class mat_func(torch.nn.Module):\\n    def forward(self, x, y):\\n        # No stacktrace found for following nodes\\n        matmul = x @ y;  x = y = None\\n        return matmul\\n        '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_model.print_readable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_model = fx.symbolic_trace(func(\"add\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class add_func(torch.nn.Module):\n",
      "    def forward(self, x, y):\n",
      "        # No stacktrace found for following nodes\n",
      "        add = x + y;  x = y = None\n",
      "        return add\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'class add_func(torch.nn.Module):\\n    def forward(self, x, y):\\n        # No stacktrace found for following nodes\\n        add = x + y;  x = y = None\\n        return add\\n        '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_model.print_readable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(op):\n",
    "  def _func(x,y):\n",
    "    return op(x,y)\n",
    "  return _func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_model = fx.symbolic_trace(func(operator.add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class _func(torch.nn.Module):\n",
      "    def forward(self, x, y):\n",
      "        # No stacktrace found for following nodes\n",
      "        add = x + y;  x = y = None\n",
      "        return add\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'class _func(torch.nn.Module):\\n    def forward(self, x, y):\\n        # No stacktrace found for following nodes\\n        add = x + y;  x = y = None\\n        return add\\n        '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_model.print_readable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(a,b):\n",
    "  x = a + b\n",
    "  y = a - b\n",
    "  return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_model = fx.symbolic_trace(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class func(torch.nn.Module):\n",
      "    def forward(self, a, b):\n",
      "        # No stacktrace found for following nodes\n",
      "        add = a + b\n",
      "        sub = a - b;  a = b = None\n",
      "        add_1 = add + sub;  add = sub = None\n",
      "        return add_1\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'class func(torch.nn.Module):\\n    def forward(self, a, b):\\n        # No stacktrace found for following nodes\\n        add = a + b\\n        sub = a - b;  a = b = None\\n        add_1 = add + sub;  add = sub = None\\n        return add_1\\n        '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_model.print_readable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name    target                   args        kwargs\n",
      "-------------  ------  -----------------------  ----------  --------\n",
      "placeholder    a       a                        ()          {}\n",
      "placeholder    b       b                        ()          {}\n",
      "call_function  add     <built-in function add>  (a, b)      {}\n",
      "call_function  sub     <built-in function sub>  (a, b)      {}\n",
      "call_function  add_1   <built-in function add>  (add, sub)  {}\n",
      "output         output  output                   (add_1,)    {}\n"
     ]
    }
   ],
   "source": [
    "func_model.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def origal_pattern(x,y):\n",
    "  return x + y\n",
    "\n",
    "def replace_pattern(x,y):\n",
    "  return x + 2 * y\n",
    "\n",
    "def mathcer(name):\n",
    "  def _match(match,ori,pat):\n",
    "    target_node = None\n",
    "    for node in pat.nodes:\n",
    "      if node.op == \"call_function\" and node.target == operator.add:\n",
    "        target_node = node\n",
    "    return match.nodes_map[target_node].name == name\n",
    "  return _match   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = subgraph_rewriter.replace_pattern_with_filters(func_model, origal_pattern, replace_pattern,[mathcer(\"add\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class func(torch.nn.Module):\n",
      "    def forward(self, a, b):\n",
      "        # No stacktrace found for following nodes\n",
      "        sub = a - b\n",
      "        mul = 2 * b;  b = None\n",
      "        add_2 = a + mul;  a = mul = None\n",
      "        add_1 = add_2 + sub;  add_2 = sub = None\n",
      "        return add_1\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'class func(torch.nn.Module):\\n    def forward(self, a, b):\\n        # No stacktrace found for following nodes\\n        sub = a - b\\n        mul = 2 * b;  b = None\\n        add_2 = a + mul;  a = mul = None\\n        add_1 = add_2 + sub;  add_2 = sub = None\\n        return add_1\\n        '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_model.print_readable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pow_func(x):\n",
    "  return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pow_func_model = symbolic_trace(pow_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name    target                   args      kwargs\n",
      "-------------  ------  -----------------------  --------  --------\n",
      "placeholder    x       x                        ()        {}\n",
      "call_function  pow_1   <built-in function pow>  (x, 3)    {}\n",
      "output         output  output                   (pow_1,)  {}\n"
     ]
    }
   ],
   "source": [
    "pow_func_model.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class expand(torch.nn.Module):\n",
      "    def forward(self, x):\n",
      "        # No stacktrace found for following nodes\n",
      "        expand = x.expand(32, 1, 1);  x = None\n",
      "        return expand\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'class expand(torch.nn.Module):\\n    def forward(self, x):\\n        # No stacktrace found for following nodes\\n        expand = x.expand(32, 1, 1);  x = None\\n        return expand\\n        '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def expand(x):\n",
    "  return x.expand(32,1,1)\n",
    "\n",
    "expand_func_model = symbolic_trace(expand)\n",
    "expand_func_model.print_readable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode       name    target    args           kwargs\n",
      "-----------  ------  --------  -------------  --------\n",
      "placeholder  x       x         ()             {}\n",
      "call_method  expand  expand    (x, 32, 1, 1)  {}\n",
      "output       output  output    (expand,)      {}\n"
     ]
    }
   ],
   "source": [
    "expand_func_model.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "env  = utils.get_env(pow_func_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = env['pow_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<built-in function pow>'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(node.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_map = {\n",
    "  '<built-in function pow>':operator.pow\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pattern_replace_and_matcher_for_single_op(traced,\n",
    "                                                  redency_part_slice,unredency_part_slice,\n",
    "                                                  target_node_name,\n",
    "                                                  batch_size):\n",
    "  env  = utils.get_env(traced)\n",
    "  target_node = env[target_node_name]\n",
    "  target_op = op_map[str(target_node.target)]\n",
    "  \n",
    "  def _match(match,ori,pat):\n",
    "    target_node = None\n",
    "    for node in pat.nodes:\n",
    "      if node.op == \"call_function\" and node.target == target_op:\n",
    "        target_node = node\n",
    "    return match.nodes_map[target_node].name == target_node_name\n",
    "  \n",
    "  def pattern(x,y):\n",
    "    return target_op(x,y)\n",
    "  \n",
    "  def replace(x,y):\n",
    "    redency_part = x[redency_part_slice]\n",
    "    unredency_part = x[unredency_part_slice]\n",
    "    redency_part_result = torch.unsqueeze(target_op(redency_part,y),0).expand(batch_size,-1,-1)\n",
    "    unredency_part_result = target_op(unredency_part,y)\n",
    "    return torch.concat((redency_part_result,unredency_part_result),1)\n",
    "  \n",
    "  return pattern,replace,_match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pow_test_func(x):\n",
    "  x = x ** 2\n",
    "  return x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name    target                   args        kwargs\n",
      "-------------  ------  -----------------------  ----------  --------\n",
      "placeholder    x       x                        ()          {}\n",
      "call_function  pow_1   <built-in function pow>  (x, 2)      {}\n",
      "call_function  add     <built-in function add>  (pow_1, 1)  {}\n",
      "output         output  output                   (add,)      {}\n"
     ]
    }
   ],
   "source": [
    "pow_test_model_func = symbolic_trace(pow_test_func)\n",
    "pow_test_model_func.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "modify_mod = GraphModule(pow_test_model_func, pow_test_model_func.graph)\n",
    "torch.onnx.export(modify_mod,torch.ones((4096,22,8)),f'modify_mod_pow.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern,replace,match = gen_pattern_replace_and_matcher_for_single_op(pow_test_model_func,\n",
    "                                                                      (0,slice(None,10,None)),(slice(None,None,None),slice(10,None,None)),\n",
    "                                                                      \"pow_1\",4096)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = subgraph_rewriter.replace_pattern_with_filters(pow_test_model_func, pattern, replace,[match])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name       target                                                        args                                                   kwargs\n",
      "-------------  ---------  ------------------------------------------------------------  -----------------------------------------------------  --------\n",
      "placeholder    x          x                                                             ()                                                     {}\n",
      "call_function  getitem    <built-in function getitem>                                   (x, (0, slice(None, 10, None)))                        {}\n",
      "call_function  getitem_1  <built-in function getitem>                                   (x, (slice(None, None, None), slice(10, None, None)))  {}\n",
      "call_function  pow_2      <built-in function pow>                                       (getitem, 2)                                           {}\n",
      "call_function  unsqueeze  <built-in method unsqueeze of type object at 0x7f9c7895e760>  (pow_2, 0)                                             {}\n",
      "call_method    expand     expand                                                        (unsqueeze, 4096, -1, -1)                              {}\n",
      "call_function  pow_3      <built-in function pow>                                       (getitem_1, 2)                                         {}\n",
      "call_function  concat     <built-in method concat of type object at 0x7f9c7895e760>     ((expand, pow_3), 1)                                   {}\n",
      "call_function  add        <built-in function add>                                       (concat, 1)                                            {}\n",
      "output         output     output                                                        (add,)                                                 {}\n"
     ]
    }
   ],
   "source": [
    "pow_test_model_func.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "modify_mod = GraphModule(pow_test_model_func, pow_test_model_func.graph)\n",
    "torch.onnx.export(modify_mod,torch.ones((4096,22,8)),f'modify_mod_pow_m.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_func(x):\n",
    "  x = x  + 1\n",
    "  return torch.sum(x,1)\n",
    "\n",
    "reduce_func_model = symbolic_trace(reduce_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name    target                                                  args      kwargs\n",
      "-------------  ------  ------------------------------------------------------  --------  --------\n",
      "placeholder    x       x                                                       ()        {}\n",
      "call_function  add     <built-in function add>                                 (x, 1)    {}\n",
      "call_function  sum_1   <built-in method sum of type object at 0x7f9c7895e760>  (add, 1)  {}\n",
      "output         output  output                                                  (sum_1,)  {}\n"
     ]
    }
   ],
   "source": [
    "reduce_func_model.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern_func(x):\n",
    "  return torch.sum(x,1)\n",
    "\n",
    "def replace_func(x):\n",
    "  x = x * 2\n",
    "  return torch.sum(x,1)\n",
    "\n",
    "matches = subgraph_rewriter.replace_pattern_with_filters(reduce_func_model, pattern_func, replace_func,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name    target                                                  args      kwargs\n",
      "-------------  ------  ------------------------------------------------------  --------  --------\n",
      "placeholder    x       x                                                       ()        {}\n",
      "call_function  add     <built-in function add>                                 (x, 1)    {}\n",
      "call_function  mul     <built-in function mul>                                 (add, 2)  {}\n",
      "call_function  sum_2   <built-in method sum of type object at 0x7f9c7895e760>  (mul, 1)  {}\n",
      "output         output  output                                                  (sum_2,)  {}\n"
     ]
    }
   ],
   "source": [
    "reduce_func_model.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pattern_replace_and_matcher_for_reduce_sum(traced,\n",
    "                                                  redency_part_slice,unredency_part_slice,\n",
    "                                                  target_node_name\n",
    "                                                ):\n",
    "  env  = utils.get_env(traced)\n",
    "  target_node = env[target_node_name]\n",
    "  target_args = target_node.args\n",
    "  target_op = torch.sum\n",
    "  def _match(match,ori,pat):\n",
    "    target_node = None\n",
    "    for node in pat.nodes:\n",
    "      if node.op == \"call_function\" and node.target == target_op:\n",
    "        target_node = node\n",
    "    return match.nodes_map[target_node].name == target_node_name\n",
    "  \n",
    "  def pattern(x):\n",
    "    return target_op(x,target_args[1])\n",
    "  \n",
    "  def replace(x):\n",
    "    redency_part = x[redency_part_slice]\n",
    "    unredency_part = x[unredency_part_slice]\n",
    "    redency_part_result = target_op(torch.unsqueeze(redency_part,0),target_args[1])\n",
    "    unredency_part_result = target_op(unredency_part,target_args[1])\n",
    "    return redency_part_result + unredency_part_result\n",
    "  \n",
    "  return pattern,replace,_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern,replace,match = gen_pattern_replace_and_matcher_for_reduce_sum(reduce_func_model,\n",
    "                                                                      (0,slice(None,10,None)),(slice(None,None,None),slice(10,None,None)),\n",
    "                                                                      \"sum_1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = subgraph_rewriter.replace_pattern_with_filters(reduce_func_model, pattern, replace,[match])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name       target                                                        args                                                     kwargs\n",
      "-------------  ---------  ------------------------------------------------------------  -------------------------------------------------------  --------\n",
      "placeholder    x          x                                                             ()                                                       {}\n",
      "call_function  add        <built-in function add>                                       (x, 1)                                                   {}\n",
      "call_function  getitem    <built-in function getitem>                                   (add, (0, slice(None, 10, None)))                        {}\n",
      "call_function  getitem_1  <built-in function getitem>                                   (add, (slice(None, None, None), slice(10, None, None)))  {}\n",
      "call_function  unsqueeze  <built-in method unsqueeze of type object at 0x7f9c7895e760>  (getitem, 0)                                             {}\n",
      "call_function  sum_2      <built-in method sum of type object at 0x7f9c7895e760>        (unsqueeze, 1)                                           {}\n",
      "call_function  sum_3      <built-in method sum of type object at 0x7f9c7895e760>        (getitem_1, 1)                                           {}\n",
      "call_function  add_1      <built-in function add>                                       (sum_2, sum_3)                                           {}\n",
      "output         output     output                                                        (add_1,)                                                 {}\n"
     ]
    }
   ],
   "source": [
    "reduce_func_model.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pattern_replace_and_matcher_for_linear(traced,\n",
    "                                                  redency_part_slice,unredency_part_slice,\n",
    "                                                  target_node_name\n",
    "                                                ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel(torch.nn.Module):\n",
    "  \n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super().__init__()\n",
    "    self.mlp = torch.nn.Linear(input_dim, output_dim)\n",
    "    self.mlp2 = torch.nn.Linear(output_dim,1)\n",
    "    self.sigmoid = torch.nn.Sigmoid()\n",
    "    self.mlp2.weight.data.copy_(torch.zeros_like(self.mlp2.weight.data))\n",
    "    \n",
    "  def forward(self,x):\n",
    "    return self.sigmoid(self.mlp2(self.mlp(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode       name     target    args        kwargs\n",
      "-----------  -------  --------  ----------  --------\n",
      "placeholder  x        x         ()          {}\n",
      "call_module  mlp      mlp       (x,)        {}\n",
      "call_module  mlp2     mlp2      (mlp,)      {}\n",
      "call_module  sigmoid  sigmoid   (mlp2,)     {}\n",
      "output       output   output    (sigmoid,)  {}\n"
     ]
    }
   ],
   "source": [
    "linear_func_model = symbolic_trace(TestModel(300,100))\n",
    "linear_func_model.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.ones((4096,300))\n",
    "modify_mod = GraphModule(linear_func_model, linear_func_model.graph)\n",
    "\n",
    "torch.onnx.export(modify_mod,sample,f'linear.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2 = utils.get_target_mod(linear_func_model,'mlp2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp2.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatternClass(torch.nn.Module):\n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super().__init__()\n",
    "    self.mlp2 = torch.nn.Linear(input_dim, 1)\n",
    "    # self.mlp2 = torch.nn.Linear(output_dim * 2,1)\n",
    "  def forward(self,x):\n",
    "    return self.mlp2(x)\n",
    "  \n",
    "  \n",
    "class ReplacementClass(torch.nn.Module):\n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super().__init__()\n",
    "    self.mlp1_1 = torch.nn.Linear(input_dim, output_dim)\n",
    "  def forward(self,x):\n",
    "    return self.mlp1_1(x + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Match(anchor=mlp2, nodes_map={mlp2: mlp2, x: mlp})]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subgraph_rewriter.replace_pattern(linear_func_model, PatternClass(300,100), ReplacementClass(300,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__jit_unused_properties__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_deploy__',\n",
       " '__reduce_ex__',\n",
       " '__reduce_package__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_code',\n",
       " '_compiled_call_impl',\n",
       " '_deepcopy_init',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_always_called',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_name',\n",
       " '_graph',\n",
       " '_is_full_backward_hook',\n",
       " '_lineno_map',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replace_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_set_replace_hook',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_tracer_cls',\n",
       " '_tracer_extras',\n",
       " '_version',\n",
       " '_wrapped_call',\n",
       " '_wrapped_call_impl',\n",
       " 'add_module',\n",
       " 'add_submodule',\n",
       " 'apply',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'children',\n",
       " 'code',\n",
       " 'compile',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'delete_all_unused_submodules',\n",
       " 'delete_submodule',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'graph',\n",
       " 'half',\n",
       " 'ipu',\n",
       " 'load_state_dict',\n",
       " 'meta',\n",
       " 'mlp1_1',\n",
       " 'mlp2_1',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'print_readable',\n",
       " 'recompile',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'sigmoid',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'to_folder',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(linear_func_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2 = utils.get_target_mod(linear_func_model,'mlp2_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp2.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name     target                   args        kwargs\n",
      "-------------  -------  -----------------------  ----------  --------\n",
      "placeholder    x        x                        ()          {}\n",
      "call_function  add      <built-in function add>  (x, 1)      {}\n",
      "call_module    mlp1_1   mlp1_1                   (add,)      {}\n",
      "call_module    mlp2     mlp2                     (mlp1_1,)   {}\n",
      "call_module    sigmoid  sigmoid                  (mlp2,)     {}\n",
      "output         output   output                   (sigmoid,)  {}\n"
     ]
    }
   ],
   "source": [
    "linear_func_model.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class TestModel(torch.nn.Module):\n",
      "    def forward(self, x):\n",
      "        # No stacktrace found for following nodes\n",
      "        add = x + 1;  x = None\n",
      "        mlp1_1 = self.mlp1_1(add);  add = None\n",
      "        mlp2_1 = self.mlp2_1(mlp1_1);  mlp1_1 = None\n",
      "        sigmoid = self.sigmoid(mlp2_1);  mlp2_1 = None\n",
      "        return sigmoid\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'class TestModel(torch.nn.Module):\\n    def forward(self, x):\\n        # No stacktrace found for following nodes\\n        add = x + 1;  x = None\\n        mlp1_1 = self.mlp1_1(add);  add = None\\n        mlp2_1 = self.mlp2_1(mlp1_1);  mlp1_1 = None\\n        sigmoid = self.sigmoid(mlp2_1);  mlp2_1 = None\\n        return sigmoid\\n        '"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_func_model.print_readable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2 = utils.get_target_mod(linear_func_model,'mlp2_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 100])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp2.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.ones((4096,300))\n",
    "modify_mod = GraphModule(linear_func_model, linear_func_model.graph)\n",
    "\n",
    "torch.onnx.export(modify_mod,sample,f'linear_m.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class TestModel(torch.nn.Module):\n",
      "    def forward(self, x):\n",
      "        # No stacktrace found for following nodes\n",
      "        mlp1 = self.mlp1(x);  x = None\n",
      "        mlp2 = self.mlp2(mlp1);  mlp1 = None\n",
      "        return mlp2\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'class TestModel(torch.nn.Module):\\n    def forward(self, x):\\n        # No stacktrace found for following nodes\\n        mlp1 = self.mlp1(x);  x = None\\n        mlp2 = self.mlp2(mlp1);  mlp1 = None\\n        return mlp2\\n        '"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestModel(torch.nn.Module):\n",
    "  \n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super().__init__()\n",
    "    self.mlp1 = torch.nn.Linear(input_dim, output_dim)\n",
    "    self.mlp2 = torch.nn.Linear(output_dim,1)\n",
    "    \n",
    "  def forward(self,x):\n",
    "    return self.mlp2(self.mlp1(x))\n",
    "\n",
    "linear_func_model = symbolic_trace(TestModel(300,100))\n",
    "linear_func_model.print_readable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatternClass(torch.nn.Module):\n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super().__init__()\n",
    "    self.mlp1 = torch.nn.Linear(input_dim, 1)\n",
    "  def forward(self,x):\n",
    "    return self.mlp1(x)\n",
    "  \n",
    "  \n",
    "class ReplacementClass(torch.nn.Module):\n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super().__init__()\n",
    "    self.mlp1 = torch.nn.Linear(input_dim, output_dim*2)\n",
    "    self.mlp3 = torch.nn.Linear(output_dim * 2,output_dim)\n",
    "  def forward(self,x):\n",
    "    return self.mlp3(self.mlp1(x + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Match(anchor=mlp1, nodes_map={mlp1: mlp1, x: x})]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subgraph_rewriter.replace_pattern(linear_func_model, PatternClass(300,100), ReplacementClass(300,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class TestModel(torch.nn.Module):\n",
      "    def forward(self, x):\n",
      "        # No stacktrace found for following nodes\n",
      "        add = x + 1;  x = None\n",
      "        mlp1_1 = self.mlp1(add);  add = None\n",
      "        mlp3 = self.mlp3(mlp1_1);  mlp1_1 = None\n",
      "        mlp2 = self.mlp2(mlp3);  mlp3 = None\n",
      "        return mlp2\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'class TestModel(torch.nn.Module):\\n    def forward(self, x):\\n        # No stacktrace found for following nodes\\n        add = x + 1;  x = None\\n        mlp1_1 = self.mlp1(add);  add = None\\n        mlp3 = self.mlp3(mlp1_1);  mlp1_1 = None\\n        mlp2 = self.mlp2(mlp3);  mlp3 = None\\n        return mlp2\\n        '"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_func_model.print_readable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_modlue = utils.get_target_mod(linear_func_model,'mlp2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.linear.Linear"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(target_modlue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.fx import (\n",
    "    Node,\n",
    "    Graph,\n",
    ")\n",
    "from torch.fx.passes.utils.matcher_utils import SubgraphMatcher\n",
    "def new_nodes_are_equal(self, pn: Node, gn: Node) -> bool:\n",
    "    # if exact match for placeholder is not required, then use placeholder as a wildcard\n",
    "    if not self.match_placeholder and pn.op == \"placeholder\":\n",
    "        return True\n",
    "\n",
    "    if pn.op == gn.op:\n",
    "        if pn.op == \"placeholder\" or pn.op == \"output\":\n",
    "            return True\n",
    "        elif pn.op == \"get_attr\":\n",
    "            return self._match_attributes(pn, gn)\n",
    "        elif pn.op == \"call_module\":\n",
    "          pn_module = utils.get_target_mod(pn.graph.owning_module,pn.target)\n",
    "          gn_module = utils.get_target_mod(gn.graph.owning_module,pn.target)\n",
    "          return type(pn_module) == type(gn_module)\n",
    "        return pn.target == gn.target\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_func = SubgraphMatcher._nodes_are_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "SubgraphMatcher._nodes_are_equal = new_nodes_are_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class TestModel(torch.nn.Module):\n",
      "    def forward(self, x):\n",
      "        # No stacktrace found for following nodes\n",
      "        mlp1 = self.mlp1(x);  x = None\n",
      "        mlp2 = self.mlp2(mlp1);  mlp1 = None\n",
      "        return mlp2\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'class TestModel(torch.nn.Module):\\n    def forward(self, x):\\n        # No stacktrace found for following nodes\\n        mlp1 = self.mlp1(x);  x = None\\n        mlp2 = self.mlp2(mlp1);  mlp1 = None\\n        return mlp2\\n        '"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestModel(torch.nn.Module):\n",
    "  \n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super().__init__()\n",
    "    self.mlp1 = torch.nn.Linear(input_dim, output_dim)\n",
    "    self.mlp2 = torch.nn.Linear(output_dim,1)\n",
    "    \n",
    "  def forward(self,x):\n",
    "    return self.mlp2(self.mlp1(x))\n",
    "\n",
    "linear_func_model = symbolic_trace(TestModel(300,100))\n",
    "linear_func_model.print_readable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatternClass(torch.nn.Module):\n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super().__init__()\n",
    "    self.mlp1 = torch.nn.Linear(input_dim, 1)\n",
    "  def forward(self,x):\n",
    "    return self.mlp1(x)\n",
    "  \n",
    "  \n",
    "class ReplacementClass(torch.nn.Module):\n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super().__init__()\n",
    "    self.mlp1 = torch.nn.Linear(input_dim, output_dim*2)\n",
    "    self.mlp3 = torch.nn.Linear(output_dim * 2,output_dim)\n",
    "  def forward(self,x):\n",
    "    return self.mlp3(self.mlp1(x + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Match(anchor=mlp1, nodes_map={mlp1: mlp1, x: x}),\n",
       " Match(anchor=mlp1, nodes_map={mlp1: mlp2, x: mlp3})]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subgraph_rewriter.replace_pattern(linear_func_model, PatternClass(300,100), ReplacementClass(300,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class TestModel(torch.nn.Module):\n",
      "    def forward(self, x):\n",
      "        # No stacktrace found for following nodes\n",
      "        add = x + 1;  x = None\n",
      "        mlp1_1 = self.mlp1(add);  add = None\n",
      "        mlp3 = self.mlp3(mlp1_1);  mlp1_1 = None\n",
      "        add_1 = mlp3 + 1;  mlp3 = None\n",
      "        mlp1_2 = self.mlp1(add_1);  add_1 = None\n",
      "        mlp3_1 = self.mlp3(mlp1_2);  mlp1_2 = None\n",
      "        return mlp3_1\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'class TestModel(torch.nn.Module):\\n    def forward(self, x):\\n        # No stacktrace found for following nodes\\n        add = x + 1;  x = None\\n        mlp1_1 = self.mlp1(add);  add = None\\n        mlp3 = self.mlp3(mlp1_1);  mlp1_1 = None\\n        add_1 = mlp3 + 1;  mlp3 = None\\n        mlp1_2 = self.mlp1(add_1);  add_1 = None\\n        mlp3_1 = self.mlp3(mlp1_2);  mlp1_2 = None\\n        return mlp3_1\\n        '"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_func_model.print_readable()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepctr-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
