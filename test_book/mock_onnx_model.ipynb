{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx import shape_inference\n",
    "import onnx_graphsurgeon as gs\n",
    "import numpy as np\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gs.Graph.register()\n",
    "def add(self, a, b):\n",
    "    return self.layer(op=\"Add\", inputs=[a, b], outputs=[\"add_out_gs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gs.Graph.register()\n",
    "def identity(self, a):\n",
    "    return self.layer(op=\"Identity\", inputs=[a], outputs=[\"identy_out_gs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gs.Graph.register()\n",
    "def identityAdd(self,a,b):\n",
    "  return self.identity(*self.add(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gs.Graph.register()\n",
    "def sub(self, a, b):\n",
    "    return self.layer(op=\"Sub\", inputs=[a, b], outputs=[\"sub_out_gs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gs.Graph.register()\n",
    "def addAndSub(self,a,b,c,d):\n",
    "  ab = self.add(a,b)\n",
    "  cd = self.add(c,d)\n",
    "  return self.sub(*ab,*cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = gs.Graph(opset=13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = gs.Variable(name=\"input\", shape=(1024, 22), dtype=np.int64)\n",
    "\n",
    "graph.inputs = [input]\n",
    "offest = np.ones(shape=(1024, 22), dtype=np.int64)\n",
    "offset2 = np.ones(shape=(1024, 22), dtype=np.int64)\n",
    "graph.outputs = graph.addAndSub(input,offest,input,offset2)\n",
    "for out in graph.outputs:\n",
    "    out.dtype = np.int64\n",
    "model = gs.export_onnx(graph)\n",
    "model = shape_inference.infer_shapes(model)\n",
    "onnx.save(model, \"model2.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mock一个模型，由一个add和一个identity组成，因为对于输出为output的节点的冗余改写复杂，在推荐系统也不存在，\n",
    "# 现在目标是先改写一个输出为非输出节点的add算子\n",
    "input1 = gs.Variable(name=\"input\", shape=(1024, 22), dtype=np.int64)\n",
    "\n",
    "graph.inputs = [input1]\n",
    "offest = np.ones(shape=(1024, 22), dtype=np.int64)\n",
    "graph.outputs = graph.identityAdd(input1,offest)\n",
    "for out in graph.outputs:\n",
    "    out.dtype = np.int64\n",
    "model = gs.export_onnx(graph)\n",
    "model = shape_inference.infer_shapes(model)\n",
    "onnx.save(model, \"../test_model/model_identity.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnxruntime import SessionOptions,ExecutionMode\n",
    "import onnxruntime as ort\n",
    "sess_opt = SessionOptions()\n",
    "sess_opt.execution_mode  = ExecutionMode.ORT_PARALLEL\n",
    "# sess_opt.inter_op_num_threads = 3\n",
    "session = ort.InferenceSession(\"../test_model/model_identity.onnx\",sess_options = sess_opt,providers=[ 'CPUExecutionProvider'])\n",
    "for i in range(10):\n",
    "  random_input1 = np.random.rand(1024,22).astype(np.int64)\n",
    "  out = session.run([],{\"input\":random_input1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gs.Graph.register()\n",
    "def slice2(self, name, input, starts, ends, axes):\n",
    "    \"\"\"\n",
    "    Add Slice operation to the graph which will operate on the input tensor with the value(s) given.\n",
    "    :param op: The ONNX operation to perform, i.e. \"Add\" or \"Mul\".\n",
    "    :param input: The tensor to operate on.\n",
    "    :param name: The name to use for the node.\n",
    "    :param starts: Value at which Slice starts.\n",
    "    :param ends: Value at which Slice ends.\n",
    "    :param axes: Axes on which Slice operation should be performed.\n",
    "    \"\"\"\n",
    "\n",
    "    input_tensor = input if type(input) is gs.Variable else input[0]\n",
    "    const_start = gs.Constant(\n",
    "        name=\"{}_value:0\".format(name), values=np.asarray([starts], dtype=np.int64)\n",
    "    )\n",
    "    const_end = gs.Constant(\n",
    "        name=\"{}_value:1\".format(name), values=np.asarray([ends], dtype=np.int64)\n",
    "    )\n",
    "    const_axes = gs.Constant(\n",
    "        name=\"{}_value:2\".format(name), values=np.asarray([axes], dtype=np.int64)\n",
    "    )\n",
    "    return self.layer(\n",
    "        name=name,\n",
    "        op=\"Slice\",\n",
    "        inputs=[input_tensor],\n",
    "        outputs=[name + \":0\"],\n",
    "        attrs={'axes':axes,'starts':starts,'ends':ends}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = gs.Graph(opset=13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = gs.Variable(name=\"input\", shape=(1024, 22), dtype=np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.inputs = [input]\n",
    "graph.outputs = graph.slice('reSlice',input,0,12,0)\n",
    "for out in graph.outputs:\n",
    "    out.dtype = np.int64\n",
    "model = gs.export_onnx(graph)\n",
    "model = shape_inference.infer_shapes(model)\n",
    "onnx.save(model, \"slicemodel.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[reSlice (Slice)\n",
       " \tInputs: [\n",
       " \t\tVariable (input): (shape=(1024, 22), dtype=<class 'numpy.int64'>)\n",
       " \t\tConstant (reSlice_value:0): (shape=(1,), dtype=int64)\n",
       " \t\tConstant (reSlice_value:1): (shape=(1,), dtype=int64)\n",
       " \t\tConstant (reSlice_value:2): (shape=(1,), dtype=int64)\n",
       " \t]\n",
       " \tOutputs: [\n",
       " \t\tVariable (reSlice:0_0): (shape=None, dtype=<class 'numpy.int64'>)\n",
       " \t]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnxruntime import SessionOptions,ExecutionMode\n",
    "import onnxruntime as ort\n",
    "sess_opt = SessionOptions()\n",
    "sess_opt.execution_mode  = ExecutionMode.ORT_PARALLEL\n",
    "# sess_opt.inter_op_num_threads = 3\n",
    "session = ort.InferenceSession(\"/home/yssun/onnx/enode/slicemodel.onnx\",sess_options = sess_opt,providers=[ 'CPUExecutionProvider'])\n",
    "for i in range(10):\n",
    "  random_input1 = np.random.rand(1024,22).astype(np.int64)\n",
    "  out = session.run([],{\"input\":random_input1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onnxcpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
